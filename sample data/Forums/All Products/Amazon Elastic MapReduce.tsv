label	description
Amazon Elastic MapReduce	"ERMFS consistent view S3 error
Hi,

we have a large ETL process running on an EMR cluster that reads and writes large number of parquet files to into S3 buckets

Here is the code:

//////////////////////////////////////////////////////////////////////

a = spark.read.parquet(path1)
a.registerTempTable('a')
b = spark.read.parquet(path2)
b.registerTempTable('b')
c = spark.read.parquet(path3)
c.registerTempTable('c')

sql = '''
select
   a.col1,
   a.col2,
   b.col1,
   b.col2,
   c.col1,
   c.col2,
   a.dt
from
   a
join 
   b
on
   a.dt = b.dt
join
   c
on
   a.dt = c.dt
''''

df_out = spark.sql(sql)

df_out.repartition('dt').write.parquet( path_out, partitionBy='dt', mode='overwrite')

//////////////////////////////////////////////////////////////////////

We recently had to switch to transient clusters and thus had to start using consistent view. I am positing our ERMFS site setup below:

 {
                    ""fs.s3.enableServerSideEncryption"": ""true"",
                    ""fs.s3.consistent"": ""false"",
                    ""fs.s3.consistent.retryPeriodSeconds"": ""10"",
                    ""fs.s3.serverSideEncryption.kms.keyId"": ""xxxxxx"",
                    ""fs.s3.consistent.retryCount"": ""5"",
                    ""fs.s3.consistent.metadata.tableName"": ""xxxxx"",
                    ""fs.s3.consistent.throwExceptionOnInconsistency"": ""true""
                }

Running the same code wit the same spark configuration - that works on the permanent cluster - on the transient cluster with consistent view enabled results in an error.

...
19/02/25 23:01:23 DEBUG S3NativeFileSystem: getFileStatus could not find key 'xxxxxREDACTEDxxxx'
19/02/25 23:01:23 DEBUG S3NativeFileSystem: Delete called for 'xxxxxREDACTEDxxxx' but file does not exist, so returning false
19/02/25 23:01:23 DEBUG DFSClient: DFSClient writeChunk allocating new packet seqno=465, src=/var/log/spark/apps/application_1551126537652_0003.inprogress, packetSize=65016, chunksPerPacket=126, bytesCurBlock=25074688
19/02/25 23:01:23 DEBUG DFSClient: DFSClient flush(): bytesCurBlock=25081892 lastFlushOffset=25075161 createNewBlock=false
19/02/25 23:01:23 DEBUG DFSClient: Queued packet 465
19/02/25 23:01:23 DEBUG DFSClient: Waiting for ack for: 465
19/02/25 23:01:23 DEBUG DFSClient: DataStreamer block BP-75703405-10.13.32.237-1551126523840:blk_1073741876_1052 sending packet packet seqno: 465 offsetInBlock: 25074688 lastPacketInBlock: false lastByteOffsetInBlock: 25081892
19/02/25 23:01:23 DEBUG DFSClient: DFSClient seqno: 465 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
Traceback (most recent call last):
  File ""xxxxxREDACTEDxxxx"", line 112, in <module>
    main()
  File ""xxxxxREDACTEDxxxx"", line xxxxxREDACTEDxxxx, in main
    xxxxxREDACTEDxxxx
  File ""xxxxxREDACTEDxxxx"", line 70, in main
    partitionBy='dt', mode='overwrite')
  File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py"", line 691, in parquet
  File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__
  File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco
  File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 319, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o232.parquet.
: org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:215)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:173)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:173)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:173)

I suspect that the error is due to the setup of EMRFS but I was not able to find any EMRFS setting that would work. The only thing that results in this error not being thrown while I am running the code above is increasing the number of node to double the normal number. The error also isn't thrown if I decrease the amount of data.

Changing the output commuter and spark speculation does not help either.

Thanks a lot. I will be great full for any ideas / suggestions."
Amazon Elastic MapReduce	"EMR with the postgresql catalog
I am trying to execute PostgreSQL queries using presto-cli. I have configured EMR with the PostgreSQL catalog as described at
https://docs.aws.amazon.com/emr/latest/ReleaseGuide/presto-adding-db-connectors.html

I am able to use the PostgreSQL queries for selecting schema, listing tables etc. But not able to run a select query. Attaching the error screenshot with this post.

The PostgreSQL db reside in another ec2 machine, other than the emr and I am not using the RDS also as that is the requirement."
Amazon Elastic MapReduce	"Provisioning issue with Spark cluster, nginx is missing
Greetings,

I'm having problems with recently created Spark clusters. Starting from Friday last week, 12/7/2018, all new clusters are provisioned without nginx running on master node. This means there is no HTTPS proxy for Livy, port 18888, so Jupyter Notebook cannot access the cluster:

The code failed because of a fatal error:
        Error sending http request and maximum retry encountered..


I dug it down to Puppet logs and I see that nginx installation is being skipped for some reason.

For AWS support, here is Puppet log from a good cluster from early last week:
s3://aws-logs-585894574098-us-west-2/elasticmapreduce/j-27C6BFPFRYSRH/node/i-0bf126943f7111485/provision-node/apps-phase/puppet.log.gz

And here is the bad one:
s3://aws-logs-585894574098-us-west-2/elasticmapreduce/j-3TI2EC16CWI7D/node/i-07a3ec5d3acf6e2a6/provision-node/apps-phase/puppet.log.gz

So far I was able to work this around with custom bootstrap action, but it would be great to have it fixed, or point me where I'm doing something wrong."
Amazon Elastic MapReduce	"Re: Provisioning issue with Spark cluster, nginx is missing
Looks like this is not an issue any longer. Both emr-5.20.0 and emr-5.21.0 are now initializing with Nginx properly configured on master node. Something got fixed, I didn't change anything in my cluster initialization code.

Edited by: vk357745 on Feb 25, 2019 5:53 PM"
Amazon Elastic MapReduce	"(Help) java.io.FileNotFoundException: /stderr (Permission denied)
I've spent days trying to fix this and see if I can get any result, with no success!

here's my aws command (broken down for quick reading):
aws emr create-cluster --name ""<APP_Name>"" --termination-protected --applications Name=Spark --release-label emr-5.19.0 --ec2-attributes 
'{""KeyName"":""emr_ec2_cluster"",""InstanceProfile"":""EMR_EC2_DefaultRole""}' 
--instance-groups '[{""InstanceCount"":1,""InstanceGroupType"":""MASTER"",""InstanceType"":""c5d.xlarge"",""Name"":""Master - 1""},
{""InstanceCount"":10,""EbsConfiguration"":{""EbsBlockDeviceConfigs"":[{""VolumeSpecification"":{""SizeInGB"":32,""VolumeType"":""gp2""},""VolumesPerInstance"":1}]},""InstanceGroupType"":""CORE"",""InstanceType"":""m4.xlarge"",""Name"":""Core - 2""}
,{""InstanceCount"":20,""EbsConfiguration"":{""EbsBlockDeviceConfigs"":[{""VolumeSpecification"":{""SizeInGB"":32,""VolumeType"":""gp2""},""VolumesPerInstance"":1}]},""InstanceGroupType"":""TASK"",""InstanceType"":""m4.large"",""Name"":""Task - 3""}]' 
--auto-terminate --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 10 --service-role EMR_DefaultRole 
--enable-debugging --log-uri 's3://<my-S3-bucket>/' 
--name ""<Name>"" --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region eu-west-2 
--steps '[{""Args"":[""spark-submit"",""--deploy-mode"",""cluster"", ""--conf"", ""spark.driver.extraJavaOptions=-Dlog4j.configuration=s3://<my-S3-bucket>/log4j.properties"",
""--class"",""Work"",""s3://<my-S3-bucket>/Work-assembly-1.0.jar"",""s3://<my-S3-bucket>/output""],
""Type"":""CUSTOM_JAR"",""ActionOnFailure"":""CONTINUE"",""Jar"":""command-runner.jar"",""Properties"":"""",""Name"":""<Application_Name>""}]'


I created an empty spark.log
 file in s3://<my-S3-bucket>/log/spark.log

and here's how the s3://<my-S3-bucket>/log4j.properties
 looks:
log4j.rootLogger=TRACE, stdout, stderr
log4j.appender.file_appender.File=s3://<myS3-bucket>/log/spark.log
# configure stdout
# set the conversion pattern of stdout
# Print the date in ISO 8601 format
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Threshold = TRACE
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern = %-5p %d [%t][%F:%L] : %m%n
log4j.appender.stdout.filter.filter1=org.apache.log4j.varia.LevelRangeFilter
log4j.appender.stdout.filter.filter1.levelMin=TRACE
log4j.appender.stdout.filter.filter1.levelMax=INFO
 
# configure stderr
# set the conversion pattern of stdout
# Print the date in ISO 8601 format
log4j.appender.stderr = org.apache.log4j.ConsoleAppender
log4j.appender.stderr.Threshold = WARN
log4j.appender.stderr.Target = System.err
log4j.appender.stderr.layout = org.apache.log4j.PatternLayout
log4j.appender.stderr.layout.ConversionPattern = %-5p %d [%t][%F:%L] : %m%n


and that fails with this stderr:
log4j:ERROR setFile(null,true) call failed.
java.io.FileNotFoundException: /stderr (Permission denied)
 
/* at ... */
 
log4j:ERROR Either File or DatePattern options are not set for appender [DRFA-stderr].
log4j:ERROR setFile(null,true) call failed.
java.io.FileNotFoundException: /stdout (Permission denied)
 
/* at ... */
 
log4j:ERROR Either File or DatePattern options are not set for appender [DRFA-stdout].
Warning: Skip remote jar s3://<my-S3-bucket>/Work-assembly-1.0.jar.
18/11/24 20:23:54 INFO RMProxy: Connecting to ResourceManager at ip-172-**-**-***.eu-west-2.compute.internal/172.31.47.167:8032
18/11/24 20:23:54 INFO Client: Requesting a new application from cluster with 10 NodeManagers
18/11/24 20:23:54 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)
18/11/24 20:23:54 INFO Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead
18/11/24 20:23:54 INFO Client: Setting up container launch context for our AM
18/11/24 20:23:54 INFO Client: Setting up the launch environment for our AM container
18/11/24 20:23:54 INFO Client: Preparing resources for our AM container
18/11/24 20:23:56 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
18/11/24 20:23:57 INFO Client: Uploading resource file:/mnt/tmp/spark-407ac6a1-09f1-46f5-815e-ca3b454a8274/__spark_libs__3854848073942710726.zip -> hdfs://ip-172-**-**-***.eu-west-2.compute.internal:8020/user/hadoop/.sparkStaging/application_154**********_0001/__spark_libs__3854848073942710726.zip
18/11/24 20:24:00 INFO Client: Uploading resource s3://<my-S3-bucket>/Work-assembly-1.0.jar -> hdfs://ip-172-**-**-***.eu-west-2.compute.internal:8020/user/hadoop/.sparkStaging/application_154**********_0001/Work-assembly-1.0.jar
18/11/24 20:24:00 INFO S3NativeFileSystem: Opening 's3://<my-S3-bucket>/Work-assembly-1.0.jar' for reading
18/11/24 20:24:05 INFO Client: Uploading resource file:/mnt/tmp/spark-407ac6a1-09f1-46f5-815e-ca3b454a8274/__spark_conf__719902015654753080.zip -> hdfs://ip-172-**-**-***.eu-west-2.compute.internal:8020/user/hadoop/.sparkStaging/application_154**********_0001/__spark_conf__.zip
18/11/24 20:24:05 INFO SecurityManager: Changing view acls to: hadoop
18/11/24 20:24:05 INFO SecurityManager: Changing modify acls to: hadoop
18/11/24 20:24:05 INFO SecurityManager: Changing view acls groups to: 
18/11/24 20:24:05 INFO SecurityManager: Changing modify acls groups to: 
18/11/24 20:24:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()
18/11/24 20:24:05 INFO Client: Submitting application application_154**********_0001 to ResourceManager
18/11/24 20:24:05 INFO YarnClientImpl: Submitted application application_154**********_0001
18/11/24 20:24:06 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:06 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1543091045737
	 final status: UNDEFINED
	 tracking URL: http://ip-172-**-**-***.eu-west-2.compute.internal:20888/proxy/application_154**********_0001/
	 user: hadoop
18/11/24 20:24:07 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:08 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:09 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:10 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:11 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:12 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:13 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:14 INFO Client: Application report for application_154**********_0001 (state: RUNNING)
18/11/24 20:24:14 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 172.31.42.105
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1543091045737
	 final status: UNDEFINED
	 tracking URL: http://ip-172-**-**-***.eu-west-2.compute.internal:20888/proxy/application_154**********_0001/
	 user: hadoop
18/11/24 20:24:15 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:15 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1543091045737
	 final status: UNDEFINED
	 tracking URL: http://ip-172-**-**-***.eu-west-2.compute.internal:20888/proxy/application_154**********_0001/
	 user: hadoop
18/11/24 20:24:16 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:17 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:18 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:19 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:20 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:21 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:22 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:23 INFO Client: Application report for application_154**********_0001 (state: ACCEPTED)
18/11/24 20:24:24 INFO Client: Application report for application_154**********_0001 (state: FINISHED)
18/11/24 20:24:24 INFO Client: 
	 client token: N/A
	 diagnostics: User class threw exception: java.lang.ExceptionInInitializerError
	at Work.main(Work.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)
Caused by: java.lang.NullPointerException
	at Work$.javaURL2string(Work.scala:13)
	at Work$.<init>(Work.scala:66)
	at Work$.<clinit>(Work.scala)
	... 6 more
 
	 ApplicationMaster host: 172.31.42.66
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1543091045737
	 final status: FAILED
	 tracking URL: http://ip-172-**-**-***.eu-west-2.compute.internal:20888/proxy/application_154**********_0001/
	 user: hadoop
Exception in thread ""main"" org.apache.spark.SparkException: Application application_154**********_0001 finished with failed status
 
/* at ... */
 
18/11/24 20:24:24 INFO ShutdownHookManager: Shutdown hook called
18/11/24 20:24:24 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-6710b057-c032-46bc-9e29-cc5c9876c04c
18/11/24 20:24:24 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-407ac6a1-09f1-46f5-815e-ca3b454a8274
Command exiting with ret '1'

The cluster id is j-2RRZD00BBIVOH
any help is greatly appreciated.

Edited by: 7kemZmani on Nov 24, 2018 12:54 PM"
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
We have also run into this problem and it is an issue with the `/etc/spark/conf/log4j.properties` file where it defines these DailyRollingFileAppender loggers (DRFA). This file is out of spec when you compare them to the log4j.properties.template file that is sourced from the master spark repo, meaning these are created by AWS for EMR specifically. The problem is that the variable being referenced in these loggers `${spark.yarn.app.container.log.dir}` is evaluating to an empty string, so the path winds up being simply `/stderr` and `/stdout` instead of what you would actually want to see here if that variable evaluated properly like `/mnt/var/log/hadoop-yarn/containers/<app_id>/<container_id>/(stdout|stderr)`.

We need some response from the AWS EMR team as to why they made that change and for what instances it would actually work properly, but it does not appear to work by default on any use-case I've come across while using 5.18 and 5.19 so far.

According to your description, that logger is being used regardless of you using your own spark-submit option. I'm not sure why that is not being respected but I do not have any experience defining the logging using the java args for spark-submit.

Our only solution thus far has been to revert back to the standard template file. In addition, one of the side-effects of AWS choosing to go with a non standard properties file is that we have to manipulate that file post-boot. Our application configuration provided at boot time with the `--configurations` parameter would not be respected once we copy the base template over the AWS-version of the log4j.properties file. Our workaround there has been to use sed on the file and recreate our configurations there. So to put all of that together, we copy a script to the master node and then run that script as a part of the cluster creation process. The script contains a few commands to ""fix"" the log4j config for us so it has what we want. For example, we previously used the configuration for spark-log4j

{
      ""Classification"": ""spark-log4j"",
      ""Properties"": {
        ""log4j.rootCategory"":""ERROR,console""
      }
}


Now, in the script we run this on the master:

sudo cp /etc/spark/conf/log4j.properties.template /etc/spark/conf/log4j.properties
sudo sed -i 's/log4j.rootCategory=INFO, console/log4j.rootCategory=ERROR,console/' /etc/spark/conf/log4j.properties"
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
We are seeing this breaking change as well, after upgrading from 5.17 to 5.19.  Could someone from the EMR team take a look at this issue?  Thanks.

In the meantimes, someone has posted a solution here https://yohei-a.hatenablog.jp/entry/20181123/1542978165

Edited by: yuj on Dec 5, 2018 2:56 PM"
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
yuj wrote:
In the meantimes, someone has posted a solution here https://yohei-a.hatenablog.jp/entry/20181123/1542978165

I believe this sets the log directory statically for logs so you will no longer have organization by app and container IDs if you require those. Removing the DRFA sections does still allow for the app and container log directories to be created as they have in the past."
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
The same issue still happens in the latest EMR release 5.20.0.  Could the EMR team acknowledge this bug and get it fixed asap?  Thanks."
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
I would upvote this rather than adding a ""me too"" but I don't see an up-vote method.
Yes it bit us as well."
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
Hello,

This issue is resolved starting with emr-5.21.0 and later.  The log4j error messaging is ugly, though you should find that the application is still functioning in effected versions.

Thank you
Christopher B"
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
emr-5.21.0 is (currently) not available how did you try this?

Edited by: SteveFosdal on Jan 24, 2019 9:18 AM"
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
Getting the same error. Any resolution for anyone?"
Amazon Elastic MapReduce	"Re: (Help) java.io.FileNotFoundException: /stderr (Permission denied)
This issue indeed seems to be fixed in emr-5.21.0, which was released recently.

Edited by: vk357745 on Feb 25, 2019 5:51 PM"
Amazon Elastic MapReduce	"emr instance type change
can we change the instance type of emr master and core nodes after its spinned up ? similay can we change emr cluster name ?"
Amazon Elastic MapReduce	"Re: emr instance type change
No, at present,  neither is possible."
Amazon Elastic MapReduce	"Re: emr instance type change
Is this possible as of now or not?"
Amazon Elastic MapReduce	"Prevent data exfiltration in EMR clusters
Planning to use the EMR cluster. Can I block all outgoing traffic from my VPC to reduce exfiltration? or there is a list of IPs or URL's that I need to whitelist in my network rules?"
Amazon Elastic MapReduce	"AWS EMR: Terminated by user request ,when trying to create new one
I'm trying to create new / clone existing cluster through AWS console in US West region. Cluster starts to creating but then, after 1 min (or even less), it starts to terminate itself, giving the error :

Terminated by user request.

I tried to choose different region - same problem.

Can it be any restriction / key-pair / security group issue? It worked fine before, and I was able to create clusters without any issues using same key-pair and security group I have right now."
Amazon Elastic MapReduce	"EMR with custom (encrypted) AMI still has unencrypted EBS volumes?
I need to encrypt all EBS instances that are used by our EMR cluster. We don't use any additional EBS volumes, so I only need to encrypt the root EBS volume on each EMR node. (Or so I thought)

The steps I took to accomplished this (per the instructions in AWS EMR documentation):

1. Copy the base AMI that is used by AWS EMR
2. Enable EBS encryption on the copy (By checking the box ""Encrypt target EBS snapshots"")
3. Re-provision the EMR cluster with one new property: CustomAmiId: {myNewAmiId}

It succeeded. However, when I analyze any of my nodes (master or core nodes), I see two EBS volumes. One is encrypted, one is not:

There are 3 entries under EC2 block devices:

1. /dev/xvda (Root device) (Encrypted)
2. /dev/xvda (Block device) (Encrypted) (This is the same volume as #1)
3. /dev/sdb (Block device) (Not encrypted) -- What is this volume?

I want to know: What is this EBS volume that is mapped to /dev/sdb? And how can I encrypt it?

Details:
EMR version: 5.7.0
EC2 hardware: c4.8xlarge

Edited by: jameswierzba2 on Feb 15, 2019 4:56 PM"
Amazon Elastic MapReduce	"HBase High Availability Region Servers
I'm attempting to configure an EMR Cluster with HBase to support region replication for the purposes of having highly available regions in the event a Region Server fails. Ultimately I would like a cluster which is able to scale out over time and be tolerant of region server failure with minimal downtime.

While I am able to support HA reads by enabling Async WAL replication and Timeline consistency, the cluster never recovers to the point where writes can be accepted again for the affected regions.
The Master UI indicates that HBase is attempting to split a log file from the failed region server however this process never completes.

I've tried numerous configurations recommended for a standard HBase installation but have had no success. 
Example:
[
   {
	""Classification"":""hbase-site"",
        ""Properties"": {
           ""hbase.regionserver.handler.count"": ""96"",
           ""zookeeper.session.timeout"": ""45000"",	   
           ""hbase.lease.recovery.dfs.timeout"": ""23000"",
	   ""dfs.client.socket-timeout"": ""10000"",           
           ""hbase.region.replica.replication.enabled"": ""true"",
           ""hbase.region.replica.replication.memstore.enabled"": ""true"",
           ""hbase.master.distributed.log.splitting"": ""true""
        }
    },{
        ""Classification"": ""hdfs-site"",
        ""Properties"": {
            ""dfs.namenode.avoid.read.stale.datanode"": ""true"",
            ""dfs.namenode.avoid.write.stale.datanode"": ""true"",
            ""dfs.namenode.check.stale.datanode"": ""true"",
            ""dfs.namenode.write.stale.datanode.ratio"": ""1.0f"",
            ""dfs.client.socket-timeout"": ""10000"",
            ""dfs.datanode.socket.write.timeout"": ""10000"",
            ""ipc.client.connect.timeout"": ""3000"",
            ""ipc.client.connect.max.retries.on.timeouts"": ""2"",
            ""dfs.namenode.stale.datanode.interval"": ""20000""
        }
    }
 ]


Has anyone been able to get Region Server recover to work and if so, what configurations were required to get it to function?
Thanks!"
Amazon Elastic MapReduce	"Issue - mounting separate volumes to core nodes
I would like to mount my own separately created volumes to be used for the HDFS since EBS provided by EMR does not persist after terminating a cluster. What are the steps to achieve this in a reliable manner through cluster creation and deletion. 

What i tried: 
1. I created separate volumes from the ones provided by EMR (first time only, volumes to then be re-used every time we terminate and re-create a new cluster)
2. I created an EMR cluster with core nodes
3. I attached our separately created volumes to each core instances
4. I stopped hadoop-yarn-nodemanager and hadoop-hdfs-datanode
5. I moved the current /mnt/hdfs directory to /mnt/hdfs_backup
6. I created a directory at /mnt/hdfs
7. I mounted each volume at the /mnt/hdfs level
8. I copied data from /mnt/hdfs_backup to /mnt/hdfs (first time only)
9. I started hadoop-yarn-nodemanager and hadoop-hdfs-datanode

This worked for the first few days when I would terminate a cluster and create a new one using the steps above. No data loss would occur and I would be able to query my data using Spark. Last night however I decided to terminate the cluster and create a new one. I again followed the steps above that has worked but I was unable to get the core nodes to re-connect to the master node post step 9. 

The HDFS Name Node interface showed a last contact of over 300 seconds followed by each core node being marked as ""down"". If I do not stop-start hadoop-yarn-nodemanager and hadoop-hdfs-datanode then the volume is detected as seen in the HDFS Name Node interface. I know that the volume is detected because of the capacity change. However even though my /mnt/hdfs directory clearly shows GB of data when running du -h, running hdfs dfs -ls shows an empty filesystem.

What steps would you recommend to properly mount separately created volumes to be used as part of the HDFS and what might be the reason behind core nodes not being able to be in contact with the master node after starting hadoop-yarn-nodemanager and hadoop-hdfs-datanode."
Amazon Elastic MapReduce	"Unable to write RDD via Spark in Scala with S3A connector
So far I've been playing around with Spark and I can't wrap my head around a recent issue that I've been dealing with...

java.lang.IllegalAccessError: tried to access method org.apache.hadoop.metrics2.lib.MutableCounterLong.<init>(Lorg/apache/hadoop/metrics2/MetricsInfo;J)V from class org.apache.hadoop.fs.s3a.S3AInstrumentation


I've been checking other posts in SO for example, and they seem to coincide in that versions are the root of the issue, but it isn't my case. Running EMR 5.15 all versions seem to be ok with the specs.

val awsSdkV         = ""1.11.333""
val hadoopAwsV      = ""2.8.3""
val sparkV          = ""2.3.0""


Can it be code dependent or its an issue with JARs and such?"
Amazon Elastic MapReduce	"EMR Cluster stuck in 'Waiting Cluster ready after last step completed.'
My cluster id is j-297P3IWLR1DOB

Can someone check why it is stuck for close to 3 hrs now? All i see is this message 'Waiting Cluster ready after last step completed.', but no further details. The instances are up and running, don't see any active steps under 'Steps' tab either. The Setup 'hadoop debugging' shows as completed"
Amazon Elastic MapReduce	"Spark: Upgrade to emr-5.20 release: Some jobs are taking longer.
Recently we upgraded emr release label from emr-5.16.0 to emr-5.20.0, which use Spark 2.4 instead of 2.3.1
At first, it was terrible. Jobs started to take much more than before. 
Finally, we set maximumResourcesAllocation to true (maybe it was true by default in emr-5.16) and things start to look better. 
But some stages are still taking much more than before (while others take less). 
It seems to be related to the number of tasks/partitions.  
In emr-5.16, the number of tasks in a stage was the number of partitions of the RDD, which was the number of tasks of the previous stage, which finally was the number of partitions of the input files.
In emr-5.20, the number of tasks when not reading directly from partitioned input files is the value of the property ""spark.default.parallelism"". 
We tried using repartition and it works for some cases, although it is not a good solution. But in other cases, the repartition causes a big shuffle spill to memory and disk... And the tasks start to fail.

Edited by: peterArg on Feb 13, 2019 5:53 AM"
Amazon Elastic MapReduce	"Hue Dashboard Error
Hello,
Appreciate if you could help us to fix the Hue Dashboard Error. Not able to open the Dashboard from the Hue. Following is the error number.

HTTPConnectionPool(host='ip-10-0-1-238.us-west-1.compute.internal', port=1978): Max retries exceeded with url: /solr/admin/cores?user.name=hue&doAs=ram_m23digibank&wt=json (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x7f867ff20750>: Failed to establish a new connection: https://forums.aws.amazon.com/ Connection refused',))"
Amazon Elastic MapReduce	"Re: Hue Dashboard Error
Going into the [desktop] section of the hue.ini file and blacklisting `search` in the `app_blacklist` variable fixes this issue
You'll need to restart the Hue service however through the `sudo stop hue` `sudo start hue` `sudo reload hue`

Edited by: tnesztler on Feb 8, 2019 9:44 AM

Edited by: tnesztler on Feb 8, 2019 9:44 AM"
Amazon Elastic MapReduce	"AWS EMR provisioning fails when I use custom AMI
**Problem:**
I have an EMR cluster (along with a number of other resources) defined in a cloudformation template. I use the AWS rest api to provision my stack. It works, I can provision the stack successfully.

Then, I made one change: I specified a custom AMI for my EMR cluster. And now the EMR provisioning fails when I provision my stack.

And now my stack creation fails, due to EMR provisioning failing. The only information I can find is an error on the console: null: Error provisioning instances.
. Digging into each instance, I see that the master node failed with error Status: Terminated. Last state change reason:Time out occurred during bootstrap


I have s3 logging configured for my EMR cluster, but there are no logs in the s3 bucket.

**Details:**

I updated my cloudformation script like so:
my_stack.cfn.yaml:
rMyEmrCluster:
  Type: AWS::EMR::Cluster
  ...
  Properties:
    ...
    CustomAmiId: ""ami-xxxxxx"" # <-- I added this



**Custom AMI details:**
I am adding a custom AMI because I need to encrypt the root EBS volume on all of my nodes. 

The steps I took to create my custom AMI:

1. I launched the base AMI that is used by AWS for EMR nodes: emr 5.7.0-ami-roller-27 hvm ebs
 (ID: ""ami-8a5cb8f3"")
2. I created an image from my running instance
3. I created a copy of this image, with EBS root volume encryption enabled"
Amazon Elastic MapReduce	"AppsFailed not incremented when Yarn Application Fails
Hi,

When Yarn application applications are failing, the AppsFailed Cloudwatch metric is not incremented. According to the documentation, it should. What am I doing wrong ?

Yarn Ressource Manager marks apps as failed as expected

EMR monitoring shows Apps* data correctly except for AppsFailed (always 0)

Cloudwatch Apps* metric shows data correctly except for AppsFailed (always 0)

Jobs are scheduled with AWS DataPipeline ShellCommandActivity using a TaskRunner configured as an EMR Step.

The whole setup is incredible, but I am not able to monitor correctly when jobs are failing.

Any hints would be appreciated."
Amazon Elastic MapReduce	"Re: AppsFailed not incremented when Yarn Application Fails
I'm having the same problem, did you ever find a solution to this?"
Amazon Elastic MapReduce	"s3dist-cp failing with multiple ""503 Slow Down"" errors
Hi,
I'm running s3-dist-cp as the final step in a Hadoop job to copy a large amount (~100,000) of files from HDFS to S3, same region.  Multiple ""503 Slow Down"" errors appear in stderr, and the job fails after about 4 minutes, with only about 20% of the files being copied.  The problem seems to be somewhat intermittent - I've occasionally had it complete successfully (particularly on smaller output datasets), but it fails ~80% of the time.  I already tried using -D s3DistCp.copyfiles.mapper.numWorkers=1 to limit the number of workers.

What's up with this?  I'd think that because all code in this step (EMR, S3, and s3-dist-cp) was written by Amazon, it'd have appropriate rate limiting checks to avoid overloading the service.  Does anyone know a way to manually rate-limit requests appropriately?  (I can deal with the s3-dist-cp running slower - it currently completes within minutes, vs. days for the whole job - but I really don't want it to fail outright and drop the output of the whole job.)

Command line invocation:
s3-dist-cp -D s3DistCp.copyfiles.mapper.numWorkers=1 --src /user/hadoop/ --dest s3://https://forums.aws.amazon.com/

Cluster ID: j-1KRKLX3T3G62E
Step ID: s-2LDQWN51E05W5

Stack trace:
Error: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 31B3CAED8BA6D921; S3 Extended Request ID: Uf1G9vG/mnwoI0soxLgxXMSutq/OKrQhB61FtrjNt4bm/uiE+wj/wh7G6hwo1bcka/fMP4zXIz4=), S3 Extended Request ID: Uf1G9vG/mnwoI0soxLgxXMSutq/OKrQhB61FtrjNt4bm/uiE+wj/wh7G6hwo1bcka/fMP4zXIz4=
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1658)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1322)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1072)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:745)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:719)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:701)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:669)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:651)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:515)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4443)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4390)
	at com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1280)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:22)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.call.GetObjectMetadataCall.perform(GetObjectMetadataCall.java:8)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.executor.GlobalS3Executor.execute(GlobalS3Executor.java:91)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.invoke(AmazonS3LiteClient.java:184)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AmazonS3LiteClient.getObjectMetadata(AmazonS3LiteClient.java:96)
	at com.amazon.ws.emr.hadoop.fs.s3.lite.AbstractAmazonS3Lite.getObjectMetadata(AbstractAmazonS3Lite.java:38)
	at com.amazon.ws.emr.hadoop.fs.s3n.Jets3tNativeFileSystemStore.retrieveMetadata(Jets3tNativeFileSystemStore.java:214)
	at com.amazon.ws.emr.hadoop.fs.s3n.S3NativeFileSystem.getFileStatus(S3NativeFileSystem.java:765)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1440)
	at com.amazon.ws.emr.hadoop.fs.EmrFileSystem.exists(EmrFileSystem.java:347)
	at com.amazon.elasticmapreduce.s3distcp.CopyFilesReducer.reduce(CopyFilesReducer.java:213)
	at com.amazon.elasticmapreduce.s3distcp.CopyFilesReducer.reduce(CopyFilesReducer.java:28)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:635)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)"
Amazon Elastic MapReduce	"EMR Notebooks: requirement failed: Session isn't active
I'm training on a 5gb dataset a pyspark ml pipeline with about 20 stages on a 5 node cluster (m5.xlarge). The spark job keeps running but the Jupyter notebook fails after a few minutes with this message in the paragraph output:

An error was encountered:
Invalid status code '400' from https://172.31.81.93:18888/sessions/0/statements/5 with error payload: ""requirement failed: Session isn't active.""

Things I found:


This happens both with EMR Notebooks as well as with JupyterHub
I see this message in the logs from the livy yarn task: Driver terminated or disconnected! Shutting down.
I tried adding these settings: 

},{""classification"":""livy-conf"", ""properties"":{""livy.server.session.timeout-check"":""false"", ""livy.server.session.timeout"":""5h""}, ""configurations"":https://forums.aws.amazon.com/

However it still showed the same message. I'm using EMR 5-20. 

Anyone faced the same issue?

Thanks!

Edited by: maxgz on Jan 29, 2019 12:48 PM"
Amazon Elastic MapReduce	"Severe Bootstrap Issues on EMR 5.20.0 Clusters
Hi there,

We have deployed several EMR 5.20.0 clusters on region sa-east-1 (Brazil) using m1.medium instances. To our surprise, most of the clusters have bootstrap errors about 20 minutes after getting started, while others bootstrap correctly. All clusters use absolutely the same configuration (all basically default options in AWS Console). 
We are deploying our clusters w/ Hadoop, Spark, Livy and Jupyter. The problem is also replicated in other regions (e.g us-east-1).
We have no custom bootstrap actions or extra configuration. We also are using the default security groups, which are correctly set.

The issue seems to be in the master node and right after a curl performed by the EMR's bootstrap scripts. The file provision-nodes/apps-phase/stderr show this error when the cluster fails:

2019-01-28 12:19:28,072 INFO main: setConfig reportdir: /var/log/provision-node/reports/ 
2019-01-28 12:19:30,223 INFO main: Set 1 puppet configs
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
 
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100     9  100     9    0     0   2163      0 --:--:-- --:--:-- --:--:--  3000
2019-01-28 12:28:12,526 ERROR main: Encountered a problem while provisioning
com.amazonaws.emr.node.provisioner.puppet.api.PuppetException: Unable to complete transaction and some changes were applied.
	at com.amazonaws.emr.node.provisioner.puppet.api.ApplyCommand.handleExitcode(ApplyCommand.java:74)
	at com.amazonaws.emr.node.provisioner.puppet.api.ApplyCommand.call(ApplyCommand.java:56)
	at com.amazonaws.emr.node.provisioner.bigtop.BigtopPuppeteer.applyPuppet(BigtopPuppeteer.java:72)
	at com.amazonaws.emr.node.provisioner.bigtop.BigtopDeployer.deploy(BigtopDeployer.java:22)
	at com.amazonaws.emr.node.provisioner.NodeProvisioner.provision(NodeProvisioner.java:25)
	at com.amazonaws.emr.node.provisioner.workflow.NodeProvisionerWorkflow.doWork(NodeProvisionerWorkflow.java:198)
	at com.amazonaws.emr.node.provisioner.workflow.NodeProvisionerWorkflow.work(NodeProvisionerWorkflow.java:99)
	at com.amazonaws.emr.node.provisioner.Program.main(Program.java:23)


However when the cluster bootstraps correctly it shows the following log:

2019-01-28 12:49:31,417 INFO main: setConfig reportdir: /var/log/provision-node/reports/ 
2019-01-28 12:49:32,788 INFO main: Set 1 puppet configs
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
 
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100     9  100     9    0     0   2034      0 --:--:-- --:--:-- --:--:--  2250
2019-01-28 12:58:07,970 INFO main: Applied puppet: Changes were successfully applied.
2019-01-28 12:58:08,049 INFO main: Found latest puppet report file /var/log/provision-node/reports/ip-172-50-84-223.sa-east-1.compute.internal/201901281258.yaml
2019-01-28 12:58:08,052 INFO main: New JSON report will be created at /var/log/provision-node/reports/ip-172-50-84-223.sa-east-1.compute.internal/201901281258.puppetreport.json
2019-01-28 12:58:09,085 INFO main: Successfully wrote JSON report to /var/log/provision-node/reports/ip-172-50-84-223.sa-east-1.compute.internal/201901281258.puppetreport.json


Has anyone seen this erratic behaviour in EMR bootstrapping?

Thanks,"
Amazon Elastic MapReduce	"Re: Severe Bootstrap Issues on EMR 5.20.0 Clusters
For anyone interested in this, we apparently could solve the issue by using an m1.large instance as EMR Master node and keep m1.medium as cores. This is a development cluster, that's why we set it up using less capable instances."
Amazon Elastic MapReduce	"EMR Master IP
Is there a way to get the master IP private address instead of matserpublicDNS (ip-**-**-**-***.us-xxxx-2.compute.internal) in Cloudformation or a way to format matserpublicDNS  to get the IP part only?  we need to use the IP to create A or CNAME  name which will be assigned a host name which can be used internally for developers instead of changing the IP address everyday.

The EMR is created in an automated way using every morning and using the AWS::Route53::Recordset the IP needs to be set to a domain name which will be internally resolved. 

Thank you"
Amazon Elastic MapReduce	"Re: EMR Master IP
Hi BM12,

The ""MasterPublicDnsName"" for an EMR cluster launched in a private subnet is the internal DNS, and will not resolve from the internet, only from within the EC2 network.
I see from your post that the DNS address end with ""compute.internal"", which designates it as an internal address. Public DNS addresses end in ""compute.amazonaws.com"".
As long as you are launching your clusters in a private subnet, you can use the ""MasterPublicDnsName"" in a CNAME record in Route 53. This will resolve correctly, and only within the AWS network.

I have written a short Linux Bash script that you can use to retrieve the private IP address of the master node, if you do not wish to use the private DNS name, as discussed above. I would suggest running this code on the EMR cluster as bootstrap action or step, which won't require you to launch any additional resources. You will need to add additional code to create/ update the Route 53 record set.
You will need to use CloudFormation to pass the cluster ID as an argument to the script.

export CLUSTER_ID=j-xxx
export INSTANCE_GROUP=`aws emr describe-cluster --cluster-id $CLUSTER_ID | jq -r '.[].InstanceGroups | .[] | select(.InstanceGroupType==""MASTER"") | .Id'`
export PRIVATE_IP=`aws emr list-instances --cluster-id $CLUSTER_ID | jq -r '.[] | .[] | select(.InstanceGroupId==""ig-1JAJAN5C7R5JP"") | .PrivateIpAddress'`
echo $PRIVATE_IP


Note that the above commands use the JQ program. JQ is a JSON parsing tool, which can be installed from your default package repository.
 sudo yum install jq 


Useful resources:
How do I create a simple resource record set in Amazon Route 53 using the AWS CLI?
https://aws.amazon.com/premiumsupport/knowledge-center/simple-resource-record-route53-cli/
CloudFormation - Return a value from an attribute of a resource
https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html"
Amazon Elastic MapReduce	"pyspark gets stuck in Running due to import issue
In short: I run a pySpark application on AWS's EMR. When I map an rdd using a custom function that resides in an external module in an external package (shipped inside a .zip file as --py-files) the cluster gets stuck - the Running status is kept while no more log lines appear until I manually terminate it.

What it is not: It is not a proper import exception - as this would have terminated the application upon executing the import lines, raising the appropriate exception, which does not happen. Also, as seen below, calling a function that maps with a similar function as a lambda, when the called function resides in the ""problematic"" module - works.

What it is: Only when the program tries to use a function from that module as a mapping function in a transformation that is written in the main program does the bug occur. Additionally, if I remove the import line highlighted in the external file (the ""problematic"" module) - an import that is never used there in this minimal bug-reproduction context (but in the actual context it is used) - the bug ceases to exist.

Below is the code for the minimal example of the bug, including commenting of 2 important lines, and some technical info. Any help would be appreciated.

Here is the main program:
import spark_context_holder
from reproducing_bugs_external_package import reproducing_bugs_external_file
 
 
sc = spark_context_holder.sc
log = spark_context_holder.log
 
 
def make_nums_rdd():
    return sc.parallelize([1, 2, 3] * 300).map(lambda x: x * x / 1.45)
 
log.warn(""Starting my code!"")
sum = sc.parallelize([1,2,3]*300).map(lambda x: x*x/1.45).sum()
log.warn(""The calculated sum using in-line expression, which doesn't mean anything more than 'succeeded in carrying out the calculation on the cluster', is {}!"".format(sum))
simple_sum_rdd = make_nums_rdd()
log.warn(""The calculated sum using the in-file function, which doesn't mean anything more than 'succeeded in carrying out the calculation on the cluster', is {}!"".format(simple_sum_rdd.sum()))
simple_sum_rdd = reproducing_bugs_external_file.make_nums_rdd(sc)
log.warn(""The calculated sum using the external file's function, which doesn't mean anything more than 'succeeded in carrying out the calculation on the cluster', is {}!"".format(simple_sum_rdd.sum()))
simple_sum_rdd = sc.parallelize([1,2,3]*300).map(reproducing_bugs_external_file.calc_func)
log.warn(""The calculated sum using the external file's mapping function, which doesn't mean anything more than 'succeeded in carrying out the calculation on the cluster', is {}!"".format(simple_sum_rdd.sum()))
# This last line does not get logged, while the others up until this one do. Here the cluster gets stuck on Running status without outputting any more log lines

In the zip file shipped as --py-files I have the following structure:

-spark_context_holde.py
-reproducing_bugs_external_package
  -- __init__.py
  -- reproducing_bugs_external_file.py

And here are their respective contents:

spark_context_holder.py
from pyspark.sql import SparkSession
from pyspark import SparkConf, SparkContext
 
conf = SparkConf().setAppName(""kac_walk_experiment"")
sc = SparkContext(conf=conf)
spark = SparkSession(sc)
log4jLogger = sc._jvm.org.apache.log4j
log = log4jLogger.LogManager.getLogger(""dbg_et"")
 
# sc.setLogLevel(""ALL"")
 
def getParallelismAlternative():
    return int(sc.getConf().get('spark.cores.max'))

__init__.py
from . import reproducing_bugs_external_file
 
__all__ = [reproducing_bugs_external_file]

reproducing_bugs_external_file.py
import numpy
import spark_context_holder  # If this is removed - the bug stops!
 
 
def make_nums_rdd(sc):
    return sc.parallelize([1, 2, 3] * 300).map(lambda x: x * x / 1.45)
 
 
def calc_func(x):
    return x*x/1.45

More technical details:

Release label:emr-5.17.0
Hadoop distribution:Amazon 2.8.4
Applications:Spark 2.3.1
using python3.4 which is the 3 version installed on AWS's machines to date

All this can be seen in SO https://stackoverflow.com/questions/54011119/an-import-issue-gets-pyspark-on-aws-stuck-in-running-status"
Amazon Elastic MapReduce	"Re: pyspark gets stuck in Running due to import issue
I got an answer on SO: https://stackoverflow.com/a/54208443/3836051
Essentially the problem was making the executors run the code that creates a new spark context by importing ""spark_context_holder"" in a module they import and use."
Amazon Elastic MapReduce	"SQL Server table in Glue metastore inaccessible
We have an on-premise SQL Server database connected to Glue via JDBC. When I try to use Glue as a metastore in EMR I receive the following error in Spark

AnalysisException: u'org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table... StorageDescriptor#InputFormat cannot be null for table:... (Service: null; Status Code: 0; Error Code: null; Request ID: null);'

I can can crawl the table and run ETL jobs successfully both in Glue and through dev end point \ SageMaker. I can access glue data pointing to S3. 

I have verified security configuration mentioned at https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-glue.html"
Amazon Elastic MapReduce	"Re: SQL Server table in Glue metastore inaccessible
Error looks like input format is missing in table definition . could you check table definition in glue ?"
Amazon Elastic MapReduce	"EMR Notebooks default python packages?
When running the new EMR notebooks with the PySpark kernel, the typical Anaconda collection of data science packages like pandas matplotlib etc are not installed by default. They are available if you change the kernel to Python (but then no PySpark), but is there not an easy way to make them both available in the same kernel (without performing a customised install through bootstrap action)? It's such a common requirement.

Thanks

Steve"
Amazon Elastic MapReduce	"Re: EMR Notebooks default python packages?
Python runs on docker container where as PySpark (spark magic) runs on master node default on livy server hence you can ssh to master node and run pip command to install required package and try in pyspark kernel"
Amazon Elastic MapReduce	"SparkR on JupyterHub missing
Hi

I have created an EMR v 5.20.0 with Jupyterhub installed, your documentation states that jupyterhub comes with a SparkR kernel by default

https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-jupyterhub.html
"" The default Python 3 kernel for Jupyter is available along with the PySpark 3, PySpark, SparkR, and Spark kernels that are available with Sparkmagic. ""


However I do not see it, while I do see the others

I only see 4 kernels installed by default
1) Pyspark
2) Pyspark3
3) Python
4) Spark (Scala it seems) 

Is this a mistake on the documentation side? 


Regards
Sam"
Amazon Elastic MapReduce	"Re: SparkR on JupyterHub missing
Sorry, that's a miss in our documentation. The SparkR kernel isn't included by default yet. But check out this topic for an example of how to install a kernel.

https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-jupyterhub-install-kernels-libs.html

Sorry for the inconvenience and thanks for reporting it. We'll get the doc's updated, including the topic above."
Amazon Elastic MapReduce	"Re: SparkR on JupyterHub missing
Thanks for confirming this, Do you think you can give me an example shell script on stalling the sparkR kernel?"
Amazon Elastic MapReduce	"Re: SparkR on JupyterHub missing
Hi you can try something like the following from the master node:

% SPARKMAGIC_KERNEL_DIRECTORY=/opt/conda/lib/python3.6/site-packages/sparkmagic/kernels
 
% sudo docker kill jupyterhub 
% sudo docker rm jupyterhub 
% sudo docker run --restart on-failure:5 -it -d \ 
-p 9443:9443 -e GRANT_SUDO=yes --user root \ 
-v /etc/jupyter:/etc/jupyter -v /var/lib/jupyter/home:/home \ 
-v /var/log/jupyter:/var/log/jupyter --privileged --name jupyterhub \ 
emr/jupyter-notebook:5.7.0 /bin/bash 
 
% sudo docker exec jupyterhub jupyter-kernelspec install $SPARKMAGIC_KERNEL_DIRECTORY/sparkrkernel/ 
% sudo docker exec jupyterhub /opt/conda/bin/jupyterhub -f /etc/jupyter/conf/jupyterhub_config.py &"
Amazon Elastic MapReduce	"Re: SparkR on JupyterHub missing
Thanks for this but is there something missing from the last line? seems to be a missing after the last ""&"""
Amazon Elastic MapReduce	"Hue v3.12 on EMR 5.5.0 does not show Oozie actions in workflow jobs
We have an EMR 5.5.0 cluster in which we run several Oozie workflows. We use Hue to monitor these workflow jobs. 

However, when we look into a Oozie workflow job that has completed, and go to the 'Actions' tab, we do not see the actions that the job has completed/run. It just says 'There are no actions to be shown'. 

We have had these same workflows in earlier and later EMR versions and did not have this problem and the workflow actions always showed up fine. 

Is this an issue only with EMR 5.5.0, has any one else noticed this? 

Suresh."
Amazon Elastic MapReduce	"EMR Wrong FS
I've been using EMR for extremely write-heavy operations, we write 80M rows/hr every hour of every day.
Any down time is problematic. EMR seems to run fine most of the time, it has weird hiccups like being unable to resolve the s3 DNS and other things, but mostly recovers after the regionserver restarts itself. We lose some data because of this, but it is acceptable loss.

Now, last night (it's always the night... sigh) really weird things started.
These exceptions started popping up on one regionserver, and basically killed it.
It could not restart, and the msaterserver could not drop it (same error on master and regionserver).
This error (with different file names) keeps coming now and the cluster has been down for maybe 12 hours.
I'm at a loss, I killed the problematic regionserver and EMR tasked another one, but the master is oblivious.
The cluster is s3 backed.

2019-01-08 06:41:58,245 ERROR [split-log-closeStream-2] wal.WALSplitter: Couldn't rename s3://<redacted>/data/default/<tablename>/13c36053b2cc3f48d207bc52b7996103/recovered.edits/0000000000000032481-ip-172-31-34-104.us-east-2.compute.internal%2C16020%2C1546699461542.1546884609941.temp to s3://<redacted>/data/default/<tableName>/13c36053b2cc3f48d207bc52b7996103/recovered.edits/0000000000000032689
java.io.IOException: Cannot get log reader
....
....
....
Caused by: java.lang.IllegalArgumentException: Wrong FS: s3://<bucketName>/data/default/<tableName>/13c36053b2cc3f48d207bc52b7996103/recovered.edits/0000000000000032689, expected: hdfs://ip-172-31-39-88.us-east-2.compute.internal:8020
...
...

What is this error, how do I get rid of it and get my cluster running again?
How can I avoid this in the future.
I looked this up and ALL answers say a custom JAR is messing with EMR, but I have NO custom JARs, this is waht EMR comes with.
The only changes I have made are in the configuration to raise Write Threads, heap size and similar other things.

Edit:
list_deadservers lists it as a dead server (correctly)
hbase(main):010:0> list_deadservers
SERVERNAME                                                                                                                                  
ip-172-31-34-104.us-east-2.compute.internal,16020,1546258042286                                                                             
ip-172-31-34-104.us-east-2.compute.internal,16020,1546699461542                                                                             
2 row(s) in 1546931307.6070 seconds


But I still keep getting these logs, with no end in sight
2019-01-08 07:09:02,846 WARN  [ProcedureExecutor-1] procedure.ServerCrashProcedure: Failed serverName=ip-172-31-34-104.us-east-2.compute.internal,16020,1546699461542, state=SERVER_CRASH_SPLIT_LOGS; retry
java.io.IOException: error or interrupted while splitting logs in [hdfs://ip-172-31-39-88.us-east-2.compute.internal:8020/user/hbase/WAL/WALs/ip-172-31-34-104.us-east-2.compute.internal,16020,1546699461542-splitting] Task = installed = 1 done = 0 error = 1
        at org.apache.hadoop.hbase.master.SplitLogManager.splitLogDistributed(SplitLogManager.java:290)
        at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:433)
        at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:406)
        at org.apache.hadoop.hbase.master.MasterFileSystem.splitLog(MasterFileSystem.java:323)
        at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.splitLogs(ServerCrashProcedure.java:440)
        at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.executeFromState(ServerCrashProcedure.java:253)
        at org.apache.hadoop.hbase.master.procedure.ServerCrashProcedure.executeFromState(ServerCrashProcedure.java:75)
        at org.apache.hadoop.hbase.procedure2.StateMachineProcedure.execute(StateMachineProcedure.java:139)
        at org.apache.hadoop.hbase.procedure2.Procedure.doExecute(Procedure.java:506)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execProcedure(ProcedureExecutor.java:1167)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:955)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.execLoop(ProcedureExecutor.java:908)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor.access$400(ProcedureExecutor.java:77)
        at org.apache.hadoop.hbase.procedure2.ProcedureExecutor$2.run(ProcedureExecutor.java:482)


Edited by: IgniteRD on Jan 7, 2019 11:07 PM"
Amazon Elastic MapReduce	"Missing AWS_DEFAULT_REGION in .bashrc EMR 5.20
The default .bashrc for EMR 5.20 appears to have been modified and no longer sets a default AWS region so many common API calls / awscli commands fail.

Previous:
# Source global definitions
if [ -f /etc/bashrc ]; then
  . /etc/bashrc
fi
 
# set the default region for the AWS CLI
export AWS_DEFAULT_REGION=$(curl --retry 5 --silent --connect-timeout 2 http://169.254.169.254/latest/dynamic/instance-identity/document | grep region | awk -F\"" '{print $4}')
export JAVA_HOME=/etc/alternatives/jre


EMR 5.20 (notice the comment exists but the export is no longer there)
# Source global definitions
if [ -f /etc/bashrc ]; then
  . /etc/bashrc
fi
 
# set the default region for the AWS CLI
export JAVA_HOME=/etc/alternatives/jre
export HOME=/home/hadoop


UPDATE: There is another layer to this problem, I originally ran into the issue because running a simple `aws s3 ls s3://bucket/` was failing with the following error which I thought was strange, if it couldn't access the bucket I would expect a 403 but instead got this message Could not connect to the endpoint URL: ""https://bucket.s3.null.amazonaws.com/?list-type=2&delimiter=%2F&prefix=&encoding-type=url""
 I quickly realized that must mean the ""null"" being seen in that URL was literal and coming from somewhere. Lo and behold, the default /home/hadoop/.aws/config file contained this which is just baffling to me: 
[default]
s3 =
    signature_version = s3v4
region = null


Why in the world is the region being defaulted to ""null""??? The environment variable will override this if set properly in the .bashrc like it used to be, but I am completely confused why this is being set. The modified timestamp on the file is from when the master first starts up which indicates to me it's getting this via puppet or some other startup script.

AWS, please look into this! The quality control for some of the more basic things in the EMR AMI's and puppet modules seems to be rapidly declining lately.

Edited by: sasquatch85 on Dec 28, 2018 2:51 PM"
Amazon Elastic MapReduce	"Re: Missing AWS_DEFAULT_REGION in .bashrc EMR 5.20
sasquatch85,

Thank you for reporting the issue.

This issue occurs when using AWS CLI with emr-5.20.0 in a private subnet.  To mitigate this issue please either set the region in the AWS CLI arguments (--region) or set the region with the command (us-east-1 as an example):
aws configure set default.region us-east-1


This will be fixed in subsequent releases.

Thank you,
Christopher

Edited by: ChristopherB@AWS on Dec 31, 2018 10:58 AM"
Amazon Elastic MapReduce	"Re: Missing AWS_DEFAULT_REGION in .bashrc EMR 5.20
Chris,

Thanks for confirming. I've added this to our startup scripts which we expect to use with 5.20.0 and verify that it does solve this issue."
Amazon Elastic MapReduce	"Fleet: Provisioning Timeout -> Switch On-demand Question
Hi,

I am setting up a task group that will switch to on-demand if spot instances are unavailable for 30 minutes.  If this were actually triggered and instance converted to on-demand, will they also automatically return back to spot instances when they become available again? 

Thanks"
Amazon Elastic MapReduce	"Re: Fleet: Provisioning Timeout -> Switch On-demand Question
Same issue here. Anyone from AWS is going to respond?"
Amazon Elastic MapReduce	"Re: Fleet: Provisioning Timeout -> Switch On-demand Question
Hi there,

Please note that once on-demand instances are provisioned after time-out, they would not switch back to SPOT type. 

The timeout action can either be ""SWITCH_TO_ON_DEMAND' or 'TERMINATE_CLUSTER"" if spot is not provisioned within the timeout duration specified. The cluster won't go back to SPOT based on availability at a later point in time.

-Juhi"
Amazon Elastic MapReduce	"Unknown parameter in [1]: ""AutoScalingPolicy"", must be one of:
I am trying to create an EMR cluster with the auto-scale options. command shown below: 

aws emr create-cluster --name databuck --region us-west-1 --release-label emr-5.16.0 --applications Name=Spark --service-role EMR_DefaultRole --ec2-attributes InstanceProfile=EMR_EC2_DefaultRole --auto-scaling-role EMR_AutoScaling_DefaultRole  --instance-groups Name=MyMasterIG,InstanceGroupType=MASTER,InstanceType=m4.large,InstanceCount=1 'Name=MyCoreIG,InstanceGroupType=CORE,InstanceType=m4.large,InstanceCount=2,AutoScalingPolicy={Constraints={MinCapacity=2,MaxCapacity=10},Rules=[{Name=Default-scale-out,Description=Replicates the default scale-out rule in the console.,Action={SimpleScalingPolicyConfiguration={AdjustmentType=CHANGE_IN_CAPACITY,ScalingAdjustment=1,CoolDown=300}},Trigger={CloudWatchAlarmDefinition={ComparisonOperator=LESS_THAN,EvaluationPeriods=1,MetricName=YARNMemoryAvailablePercentage,Namespace=AWS/ElasticMapReduce,Period=300,Statistic=AVERAGE,Threshold=15,Unit=PERCENT,Dimensions=}' 

I am getting the following error:

Parameter validation failed:
Unknown parameter in [1]: ""AutoScalingPolicy"", must be one of: EbsConfiguration, InstanceGroupType, InstanceCount, Name, BidPrice, InstanceType

I also tried to use the following command: 

aws emr create-cluster --release-label emr-5.16.0 --applications Name=Spark --region us-west-1 --service-role EMR_DefaultRole --auto-scaling-role EMR_AutoScaling_DefaultRole --instance-groups  file://instance-config.json-s 

[
  {
      ""InstanceCount"": 1,
      ""Name"": ""MyMasterIG"",
      ""InstanceGroupType"": ""MASTER"",
      ""InstanceType"": ""m4.large""
  },
  {
      ""InstanceCount"": 2,
      ""Name"": ""MyCoreIG"",
      ""InstanceGroupType"": ""CORE"",
      ""InstanceType"": ""m4.large"",
      ""AutoScalingPolicy"": {
          ""Constraints"": {
              ""MinCapacity"": 1,
              ""MaxCapacity"": 10
          },
          ""Rules"": [
              {
                  ""Name"": ""Default-scale-out"",
                  ""Description"": ""Replicates the default scale-out rule in the console for YARN memory."",
                  ""Action"": {
                      ""SimpleScalingPolicyConfiguration"": {
                          ""AdjustmentType"": ""CHANGE_IN_CAPACITY"",
                          ""ScalingAdjustment"": 1,
                          ""CoolDown"": 300
                      }
                  },
                  ""Trigger"": {
                      ""CloudWatchAlarmDefinition"": {
                          ""ComparisonOperator"": ""LESS_THAN"",
                          ""EvaluationPeriods"": 1,
                          ""MetricName"": ""YARNMemoryAvailablePercentage"",
                          ""Namespace"": ""AWS/ElasticMapReduce"",
                          ""Period"": 300,
                          ""Threshold"": 75,
                          ""Statistic"": ""AVERAGE"",
                          ""Unit"": ""PERCENT"",
                          ""Dimensions"": [
                              {
                                  ""Key"": ""JobFlowId"",
                                  ""Value"": ""${emr.clusterId}""
                              }
                          ]
                      }
                  }
              }
          ]
      }
  }
 ]"
Amazon Elastic MapReduce	"Re: Unknown parameter in [1]: ""AutoScalingPolicy"", must be one of:
Hi there,

We have seen such issues occur when a very old version of AWS CLI is used. If that's the case, you could try upgrading your CLI version using the below command:
sudo pip install --upgrade awscli

Once the upgrade goes through, please retry running the same command to create a cluster.

-Juhi"
Amazon Elastic MapReduce	"Health monitoring of thrift server in Spark EMR?
We use a JDBC to connect to the hive thrift server on our spark EMR cluster. We have had some transient issues of the thrift server crashing and requiring manual restart. 

We are wondering if there is any https://forums.aws.amazon.com/ way for us to monitor the health of the thrift server? At the very least, we would like to get alerted when it goes down. It would also be nice to have other server health metrics."
Amazon Elastic MapReduce	"status ""WaitingCluster ready after last step .""  unable to login to master
Yesterday today I have created or tried to create cluster several times 
everytime cluster status shows
""WaitingCluster ready after last step completed.""
But
 ""Zeppelin, Spark History Server, Ganglia, Resource Manager  hyper links are not enabled and
unable to login to master using key. 
I am running out of money by trying this several times. Can you please advice

My clusterid:j-Y5OI3VQH01UW
master and core status shows "" Running"" 
availablity zone : Availability zone:us-east-1b

error I am getting when I tried to connect master: Network error, unable to login ( used proper host, key and proper user while login)

I have tried to login to master with proper keypair ( each time I created) but I am unable to login to  master or slaves. Why this problem is happening in EMR. I have tried the same exercise 10 times with diff zones but still no use. 
PS: I am a regular EC2 user and connected to several apps/machines with keys several times.

Edited by: suryabhs on Dec 4, 2018 8:04 PM

Edited by: suryabhs on Dec 4, 2018 8:08 PM"
Amazon Elastic MapReduce	"How to autoscale CORE instance group of an existing EMR cluster?
The EMR auto scaling doc here: https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-automatic-scaling.html?shortFooter=true seems to indicate that I can auto scale the core instance group of an existing cluster in the page section labeled ""Using the AWS Management Console to Configure Automatic Scaling"".  However the EMR console UI for the cluster only shows ""Not enabled"" in the ""Auto Scaling"" column of core instance group on the ""Hardware"" tab with no ""pencil icon"" link to configure auto scaling for the instance group.

What gives?

Is auto scaling only available for clusters that were initially configured for auto scaling instance groups at cluster spin up time?  If so, why can't cluster instance groups be configured for auto scaling after cluster spin up?

Even adding a new instance group to an existing cluster does not allow me to configure it for auto scaling in the console UI.  IOW, the new instance group doesn't allow auto scaling configuration in the popup and it gets created with ""Not enabled"" in the ""Auto Scaling"" column of new instance group. 

-Kurt"
Amazon Elastic MapReduce	"Autoscaling/Resizing Presto
Hi - This AWS article mentions new auto-scaling support for Presto but discusses examples based on using YARN metrics. Since Presto does not run on YARN, how would auto-scaling be configured? My understanding is that Presto also has its own graceful shutdown mechanism which is triggered by a direct HTTP call to the child nodes. Would appreciate anymore and clarification with configuring Presto to auto-scale.

https://aws.amazon.com/blogs/big-data/dynamically-scale-applications-on-amazon-emr-with-auto-scaling/

Thanks!"
Amazon Elastic MapReduce	"Re: Autoscaling/Resizing Presto
Hey EMR,

Any answer to this question.  It's been over 2 years of crickets on this customer question!

Thanks,
-Kurt"
Amazon Elastic MapReduce	"Issues deleting underling S3 data when deleting Hive partitions
We are using Hive on EMR (backed by S3) combined with EMRFS (backed by dynamodb) to manage our spark cluster. We are running into an issue where when we drop partitions using SparkSQL they only get removed from hive and not the underlying data from S3 remains. This happens on both internally managed and externally managed tables. To work around this we have been using the S3 API to delete the underlying data after dropping the partition from hive. However EMRFS does not know about this data being dropped via the api so we have to make an EMRFs sync call using emrfs CLI. 

In this workflow we need to take 3 actions to drop a partition:

1. Drop partition using sparkSQL
2. Use S3 API to delete underlying data
3. Shell out an EMRFS sync command to get back in sync

Is this the expected way to drop a partition, or is there an easier and less involved way to drop a partition and the underlying data?

Edited by: AaronGrau on Nov 30, 2018 1:52 PM"
Amazon Elastic MapReduce	"Got a “Error sending http request and maximum retry encountered.”
Got a error saying ""Error sending http request and maximum retry encountered."" when running EMR notebook.

Any idea why?

Edited by: pooh on Nov 28, 2018 8:26 PM"
Amazon Elastic MapReduce	"Hive does not work with Glue as metastore
Hi,
Here is my EMR creation CLI:
aws emr create-cluster --applications Name=Zeppelin Name=Spark Name=Hive --tags 'Name=test' --ec2-attributes '{""KeyName”:”test”,”InstanceProfile"":""EMR_EC2_DefaultRole"",""SubnetId"":""subnet-633de13c"",""EmrManagedSlaveSecurityGroup"":""sg-04e5722a2e35805fd"",""EmrManagedMasterSecurityGroup"":""sg-0048769d8962bff31"",""AdditionalMasterSecurityGroups"":}' --release-label emr-5.18.0 --log-uri 's3n://aws-logs-bxxtest-us-east-1/elasticmapreduce/' --instance-groups '[{""InstanceCount"":1,""EbsConfiguration"":{""EbsBlockDeviceConfigs"":},""InstanceGroupType"":""CORE"",""InstanceType"":""m4.large"",""Name"":""Core - 2""},{""InstanceCount"":1,""EbsConfiguration"":{""EbsBlockDeviceConfigs"":' --configurations '},{""Classification"":""spark-hive-site"",""Properties"":{""hive.metastore.client.factory.class"":""com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory""},""Configurations"":https://forums.aws.amazon.com/' --auto-scaling-role EMR_AutoScaling_DefaultRole --ebs-root-volume-size 10 --service-role EMR_DefaultRole --enable-debugging --name 'My cluster' --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region us-east-1

when I login to master node and try to use hive cli I am getting the below error
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j2.properties Async: true
Exception in thread ""main"" java.lang.RuntimeException: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:632)
	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:549)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:750)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:234)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:148)
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:885)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthenticator(SessionState.java:1479)
	at org.apache.hadoop.hive.ql.session.SessionState.getUserFromAuthenticator(SessionState.java:1150)
	at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.setupSessionAcls(TezSessionState.java:441)
	at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.openInternal(TezSessionState.java:311)
	at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.beginOpen(TezSessionState.java:210)
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:629)
	... 9 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:917)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:877)
	... 15 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:237)
	at org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:390)
	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:333)
	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:313)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:289)
	at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:913)
	... 16 more
Caused by: java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:163)
	at org.apache.hadoop.fs.Path.<init>(Path.java:232)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:133)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:137)
	at org.apache.hadoop.hive.metastore.Warehouse.getWhRoot(Warehouse.java:150)
	at org.apache.hadoop.hive.metastore.Warehouse.getDefaultDatabasePath(Warehouse.java:163)
	at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.createDefaultDatabase(AWSCatalogMetastoreClient.java:262)
	at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.<init>(AWSCatalogMetastoreClient.java:166)
	at com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory.createMetaStoreClient(AWSGlueDataCatalogHiveClientFactory.java:19)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3620)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3688)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3668)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3930)
	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:249)
	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:232)
	... 21 more

Edited by: bshah on Nov 20, 2018 5:42 PM"
Amazon Elastic MapReduce	"Bootstrap Failure on EMR 5.12.x
Over the past 2 weeks, I've been seeing EMR clusters fail to come up in us-east-1 and reporting ""Bootstrap failure"" with a slightly more specific message of ""bootstrap action 1 file could not be found"". Clusters are configured for EMR 5.12.x. It's intermittent and happens across all AZs. I don't have any bootstrap actions set up on these clusters, so it's the vanilla EMR bootstrapping.

Is anyone else seeing something similar? Any thoughts on what could be the cause?"
Amazon Elastic MapReduce	"New user of EMR having 0 EC2 instances quota!!
Hello!
I made an account in aws web services, and it seems like I had to be signed for the free tier account. 
I'm just trying to run a spark application on an EMR cluster that requires (the application) more than the free t2.micro instance type. When I check the limit on my EC2 instance types, I see them all zeroed. 
I requested an increase on the limit on instances of type c5d.2xlarge and I got no response.
My new cluster id: j-2OSVZKO6636X2

what should I do now?

p.s. I'm willing to pay for the service.

Edited by: 7kemZmani on Nov 19, 2018 2:33 AM

Edited by: 7kemZmani on Nov 19, 2018 2:35 AM"
Amazon Elastic MapReduce	"EMRFS - where is Hive Metastore
When selecting EMRFS is the Mysql DB that contains the Hive Metastore saved on S3 or is it still on the Masternode?

thanks"
Amazon Elastic MapReduce	"Re: EMRFS - where is Hive Metastore
The Hive Metastore by default resides in the master node. This means that the hive metadata is lost everytime you terminate the cluster and needs to be re-populated again.

If you want a persistent metastore which lives outside the lifecycle of a cluster, you can configure external metastore such as Glue Catalog or Aurora DB

https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-metastore-external-hive.html"
Amazon Elastic MapReduce	"EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Hi,

Spark and Pyspark's textFile function works well with S3.

In order to have this function work under Zeppelin for Spark

val file = ""s3://bucket/file.csv""
val data = sc.textFile(file)
data.take(10)

I had to change 

export CLASSPATH="":/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*""

for

export CLASSPATH=""/usr/share/aws/aws-java-sdk/*:/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*""

Now, I have the problem under Zeppelin for Pyspark 

%pyspark 
file = ""s3://bucket/file.csv""
data = sc.textFile(file)
data.take(10)

/usr/bin/python: No module named pyspark

It sounds like PYTHONPATH is not correctly set in EMR 4.2.0.

Can you please have a look ? 

Thanks"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Thank you for the note.  This has been fixed, see https://forums.aws.amazon.com/thread.jspa?threadID=220503&tstart=0

Best regards 
ChristopherB"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
No sorry, it does not correct my problem.
Indeed Spark problem is solved. By Pyspark conf is not. 
Here is the error message : 

Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, ip-172-31-12-79.eu-west-1.compute.internal): org.apache.spark.SparkException: 
Error from python worker:
  /usr/bin/python: No module named pyspark
PYTHONPATH was:
  /mnt1/yarn/usercache/zeppelin/filecache/12/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:163)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:86)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:62)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:135)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:101)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:393)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)
	at py4j.Gateway.invoke(Gateway.java:259)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:207)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: 
Error from python worker:
  /usr/bin/python: No module named pyspark
PYTHONPATH was:
  /mnt1/yarn/usercache/zeppelin/filecache/12/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:163)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:86)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:62)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:135)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:101)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	... 1 more

(<class 'py4j.protocol.Py4JJavaError'>, Py4JJavaError(u'An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n', JavaObject id=o69), <traceback object at 0x25778c0>)"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Hello,

A workaround for EMR release 4.2.0 with Zeppelin and PySpark hitting this error is to edit the Zeppelin interpreter to add this property and value:
spark.executorEnv.PYTHONPATH=/usr/lib/spark/python/lib/py4j-0.8.2.1-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.8.2.1-src.zip 


Best regards 
ChristopherB

Edited by: ChristopherB@AWS on Dec 4, 2015 11:46 PM"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Great! Thanks"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Thank you"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Sorry, somehow I had missed your question about the missing pyspark module. We will look into fixing this issue for the next release of EMR. The AWS Java SDK issue has been fixed in emr-4.2.0 though."
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Thanks!"
Amazon Elastic MapReduce	"Re: EMR 4.2.0 Zeppelin configuration for S3 with Pyspark
Hi,
The section :<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-src.zip
 has redundant class path separator. As per https://issues.apache.org/jira/browse/YARN-6554 , <CPS> expands to colon in linux and semi-colon in windows. 

I can see that this setting is baked in to EMR now. The usage of path separator better be standardized to :
 or <CPS>
 for clarity sake."
Amazon Elastic MapReduce	"Why are failed applications not registering on the Apps Failed Metric?
I am trying to set up alerts based on failed applications in EMR. Yesterday I ran 7 applications on a cluster that did not succeed. Six of them say `Failed` in the EMR:Cluster:Application History UI. One says `Undefined`. However, in the Monitoring tab, the Apps Failed graph only counted the 1 Undefined application. It did not count any of the failures. https://forums.aws.amazon.com/. So why do my failed applications count as Completed and not Failed? Or, why are they labeled as failed in the UI if they do not count as true failures?"
Amazon Elastic MapReduce	"HIVE ORC table returns NULLs ( EMR 5.9 Hive 2.3.0 )
I am creating hive external table ORC (ORC file located on S3).

Command

CREATE EXTERNAL TABLE Table1 (Id INT, Name STRING) STORED AS ORC LOCATION 's3://bucket_name'
After running the query:

Select * from Table1;
Result is:

+-------------------------------------+---------------------------------------+
| Table1.id  | Table1.name  |
+-------------------------------------+---------------------------------------+
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
| NULL                                | NULL                                  |
+-------------------------------------+---------------------------------------+
Interesting that the number of returned records 10 and it is correct but all records are NULL. 

I checked is ORC file for validation valid:
-rw-r--r--   1 hadoop hadoop        392 2017-10-25 07:50 /tmp/orc_tester/Country.orc
hive --orcfiledump -d /tmp/orc_tester/
Processing data file hdfs://<my_ip>:8020/tmp/orc_tester/Country.orc https://forums.aws.amazon.com/
{""Id"":1,""Name"":""Singapore""}
{""Id"":2,""Name"":""Malaysia""}
{""Id"":3,""Name"":""India""}
{""Id"":4,""Name"":""Hong Kong""}
{""Id"":5,""Name"":""Macau""}
{""Id"":6,""Name"":""Thailand""}
{""Id"":7,""Name"":""Indonesia""}
{""Id"":8,""Name"":""Philippines""}
{""Id"":9,""Name"":""Dubai""}
{""Id"":10,""Name"":""Vietnam""}

*What is wrong, why query returns only NULLs? I am using EMR instances on AWS. Should I configure/check to support ORC format for hive? I am using default configuration *

ORC file attached
Thanks
Oleg."
Amazon Elastic MapReduce	"Re: HIVE ORC table returns NULLs ( EMR 5.9 Hive 2.3.0 )
Even I'm facing the similar issue, when I query the data from Hive/beeline the query results returns NULL but when I query the same form orcdump or spark-sql I was able to view the data. Does anyone has faced similar issue and has a solution?

Thanks,
Sridhar."
Amazon Elastic MapReduce	"Is there a way to 'STOP' EMR cluster
I know it is possible to stop individual EC2 instances, but what about the EMR cluster?

Is there a way to stop an EMR cluster, so that I don't get billed while all the on-instance data remain intact when I start them?

If I stop all EC2 instances comprising EMR cluster, would I still be billed?"
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
Hello,

At this time there is not a way to STOP and EMR cluster in the same sense you can with EC2 instances.   The EMR cluster uses instance-store volumes and the EC2 start/stop feature relies on the use of EBS volumes which are not appropriate for high-performance, low-latency HDFS utilization.

The best way to simulate this behavior is to store the data in S3 and then just ingest as a start up step of the cluster then save back to S3 when done.

Best regards,
ChristopherB"
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
Hi , 
I am also very interested in saving my EMR cluster data before terminating it so that I can ingest it while starting.

Unlike Redshift cluster, I do not see a 'snapshot' option. What is the most efficient way to store EMR Cluster data before terminating.

Thanks
SJ"
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
But if the EMR instance type says that the Root Device Type is EBS, can one stop the EC2 instance without losing any Data?"
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
No, because EBS attached to EMR is ephemeral. See link below:

http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-storage.html"
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
Hey EMR,

What I think the service it totally missing the boat on here is that many EMR customers NEVER USE HDFS and only persist data to S3.  So the whole ""EMR storage must be ephemerial to get good HDFS performance"" argument is a bogus one.  Please let your customers choose where to persist data.

I use cases where all data is persisted off cluster, like in S3 or another service, then there is no longer any risk to being able to STOP the EC2 instances of an EMR cluster and restart them later. 

In fact, I could make a pretty good argument asking for an EMR cluster with only task nodes and 0 core nodes, i.e. no HDFS, because in many EMR clusters forcing HDFS on all the core node only steals resources from us that we don't need or intend to use.  But alas, that's another topic for another thread..."
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
I also very care about it. I don't find a way to stop rather than terminate the cluster. If would be better  EMR could support stop cluster. Is there any plan in the future?"
Amazon Elastic MapReduce	"Re: Is there a way to 'STOP' EMR cluster
There should be an option to stop a cluster. We would like to stop the cluster when not in use.
This is stopping us from using AWS EMR."
Amazon Elastic MapReduce	"Master instance is not reachable. ""serial8250: too much work for irq4""
We use a persistent EMR cluster to run analytics on our data. It uses EMR cluster fleets and the task nodes have a mix of spot instances. We noticed yesterday that after a node was terminated due to spot capacity it did not come back after being re-requested as they usually do. We also noticed a message in the EMR console ""Master instance is not reachable. Please check your master instance status.""

Looking at the monitoring tab, we saw that the healthchecks/metrics all stopped coming in on the morning of 10/26. We are still able to SSH into the master node and all applications appear to be running as normal, just the scary message on the console and the inability to resize the cluster. 

When we got onto the terminal of the master node and looked at the logs, I noticed that on 10/26 we started to see these messages in /var/log/messages: serial8250: too much work for irq4. A lot of times the messages come in groups of about 5-10, sometimes it's a once off, and follow a pattern of about once every 10-15 minutes.

Searching for that error indicates there might be some sort of issue with the emulation layer for a console port that is being overwhelmed with messages. First guess is that the AWS metrics use that emulated port to scan the master node, the cadence of 10-15 minutes seems to match up with most metric collection in AWS. 

Has anyone else experienced this issue? Is there a way to restart whatever processes the AWS monitoring tools use so we can restore health to this cluster or is it time to look at migration paths to a new cluster?

Edit: For clarity, the EC2 instance level monitoring still appears to be functioning for the master node, but the EMR cluster level monitoring is empty since 10/26. So it appears limited in scope to the EMR cluster monitoring.

Update 10/31: Found this article which gave me some clues as to what might be the root cause. But I was able to restart the instance-controller cleanly (there were some initial issues with service-nanny causing a race condition with the init scripts, had to stop that first) and the issue remains. http://untouchedintellect.blogspot.com/2016/04/i-faced-rare-issue-today.html

Update 11/1: I think I found the root cause of my ""serial8250: too much work for irq4"" messages last night. The instance-state service/scheduled job seems to be overwhelming the console in some way. Console output goes to tty1 but also go to ttyS0 which uses irq4. The output of instance-state is apparently too much to handle for the UART emulation, hence the driver message and error. I backed up the original script and replaced `/usr/bin/dump-instance-state` with a simple ""echo Removed..."" and have not gotten that irq message since then. I'm guessing the instance-state output is also tied to the cluster status which is why it still shows unreachable so the next step is to figure out how to fix that...

Edited to add clarity by: sasquatch85 on Oct 30, 2018 10:55 AM

Edited to update on instance-controller restart: sasquatch85 on Oct 31, 2018 9:46 AM

Edited to update root cause of irq4 error: sasquatch85 on Nov 1, 2018 9:25 AM"
Amazon Elastic MapReduce	"Re: Master instance is not reachable. ""serial8250: too much work for irq4""
As an update, I was never able to figure this out just wanted to close this out in case someone stumbles across it. The problem really seems to be on the cluster manager side of things. There is 0 public documentation on how that actually works beyond this vague line here: https://docs.aws.amazon.com/emr/latest/ManagementGuide/UsingEMR_ViewingMetrics.html ""Amazon EMR pulls metrics from a cluster. If a cluster becomes unreachable, no metrics are reported until the cluster becomes available again.""

I have no idea what metrics it is looking for or how it is polling for them, from my perspective everything seems to be working as intended but without knowledge of what is failing with the CM I'm in the dark. The other cloudwatch metrics for the EC2 instance are working just fine so it's puzzling why the cluster manager decided to start ignoring this host."
Amazon Elastic MapReduce	"How to configure Zeppelin pyspark.python and spark.executorEnv.PYTHONPATH
I would like to change the default python interpreter in Zeppelin to Python3 and add custom paths the the PYTHONPATH library. Right now I do it manually by editing these files:

## /etc/zeppelin/conf/interpreter.json
""interpreterSettings"": {
    ""2ANGGHHMQ"": {
      ""properties"": {
        ""zeppelin.pyspark.python"": ""/usr/bin/python3"",
 
## /etc/zeppelin/conf/zeppelin-env.sh
export SPARK_SUBMIT_OPTIONS=""$SPARK_SUBMIT_OPTIONS --conf 'spark.executorEnv.PYTHONPATH=/usr/lib/spark/python/lib/py4j-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-src.zip' --conf spark.yarn.isPython=true""


Is it possible to specify these as configuration objects?

https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-configure-apps.html"
Amazon Elastic MapReduce	"How to use Athena Data Catlog Service for EMR Hive?
We'd like to be able to configure Hive on an EMR cluster to use the Athena Data Catalog Service instead of using an on cluster Hive Metastore Service (HMS) on the EMR master node.   I believe it's possible to configure an EMR cluster's Hive to use the HMS on a different EMR cluster or an HMS on an Hive instance that we install directly on EC2.  However, we'd like to be able to share the metastore with Athena so that Hive queries executed on the EMR cluster and Athena queries executed by Athena's Presto can share exactly the same metadata declarations for external tables.  We're already sharing the same metastore and external table declarations between Athena queries and Redshift Spectrum queries by declaring Redshift external schema mapping to Athena's Data Catalog.  Bringing Hive queries into the same metastore is the remaining missing piece.

Does anyone know how to do this or give guidance on how to do it?

Thanks,
-Kurt"
Amazon Elastic MapReduce	"Re: How to use Athena Data Catlog Service for EMR Hive?
This is not available yet. Athena doesn't support external HMS to date."
Amazon Elastic MapReduce	"Re: How to use Athena Data Catlog Service for EMR Hive?
The prior response actually answers the opposite of the question I was asking.  The response says that Athena does not support using an external Hive Metastore Service (HMS), presumably on an EMR cluster or installed directly on EC2, instead of using it's own Data Catalog Service (DSC).

I'm looking for help to do the exact opposite. What I'd like to do is configure a Hive instance on an EMR master node to use the Athena Data Catalog Service (DCS) instead of it's own local Hive Metastore Service (HMS) on the EMR master node."
Amazon Elastic MapReduce	"Re: How to use Athena Data Catlog Service for EMR Hive?
My original question is moot now. The way to go is to upgrade the Athena DC to the Glue DC.  EMR now supports using the Glue DC in lieu of the on cluster HMS."
Amazon Elastic MapReduce	"Amazon EMR now supports a public EMR artifact repository for Maven builds
Amazon EMR now supports a public EMR artifacts repository to help developers build applications based on the EMR distribution for Apache Hadoop and Apache Hive using Apache Maven for dependency management.  The EMR artifacts repository hosts the same optimized versions of libraries and dependencies that are available with specific Amazon EMR release versions, ensuring that artifacts used in building applications against the EMR stack are compatible with the runtime libraries on the EMR cluster. Artifacts in the repository correspond to EMR release 5.18.0 and later. Please visit the Amazon EMR documentation for more information about the https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-artifact-repository.html."
Amazon Elastic MapReduce	"EMR 5.11 fails with Hive Metastore on RDS
I am attempting upgrade our EMR clusters from 5.7 to 5.11 but have been unsuccessful so far. The main applications installed are Presto and Hive. The hive metastore is configured to use an external mysql database hosted on RDS, which has worked fine on EMR 5.7 and earlier. The cluster (EMR 5.11 & 5.10) fails when passing in the classification settings below and succeeds without them. Has something changed in the latest version of EMR to break compatibility? 

{""classification"":""hive-site"",""properties"":{""hive.metastore.schema.verification"":""true"",""javax.jdo.option.ConnectionUserName"":""user123"",""javax.jdo.option.ConnectionPassword"":""password"",""javax.jdo.option.ConnectionURL"":""jdbc:mysql://xyz.us-east-1.rds.amazonaws.com:3306/hive?createDatabaseIfNotExist\u003dtrue""}}"
Amazon Elastic MapReduce	"Re: EMR 5.11 fails with Hive Metastore on RDS
I was able to dig out these related errors from the logs.

Error: /usr/lib/hive/bin/schematool -dbType mysql -initSchema -verbose returned 1 instead of one of [0]
Error: /Stagehttps://forums.aws.amazon.com//Hadoop_hive::Init_metastore_schema/Exechttps://forums.aws.amazon.com//returns: change from notrun to 0 failed: /usr/lib/hive/bin/schematool -dbType mysql -initSchema -verbose returned 1 instead of one of [0]
Error: /Stagehttps://forums.aws.amazon.com//Hadoop_hive::Init_metastore_schema/Exechttps://forums.aws.amazon.com/: Failed to call refresh: /usr/lib/hive/bin/schematool -dbType mysql -initSchema -verbose returned 1 instead of one of [0]
Error: /Stagehttps://forums.aws.amazon.com//Hadoop_hive::Init_metastore_schema/Exechttps://forums.aws.amazon.com/: /usr/lib/hive/bin/schematool -dbType mysql -initSchema -verbose returned 1 instead of one of [0]
Warning: /Stagehttps://forums.aws.amazon.com//Hadoop_hive::Server2/Servicehttps://forums.aws.amazon.com/: Skipping because of failed dependencies
Warning: /Stagehttps://forums.aws.amazon.com//Hcatalog::Server/Servicehttps://forums.aws.amazon.com/: Skipping because of failed dependencies
2018-01-16 20:33:27,865 ERROR main: Encountered a problem while provisioning
com.amazonaws.emr.node.provisioner.puppet.api.PuppetException: Unable to complete transaction and some changes were applied.
	at com.amazonaws.emr.node.provisioner.puppet.api.ApplyCommand.handleExitcode(ApplyCommand.java:74)
	at com.amazonaws.emr.node.provisioner.puppet.api.ApplyCommand.call(ApplyCommand.java:56)
	at com.amazonaws.emr.node.provisioner.bigtop.BigtopPuppeteer.applyPuppet(BigtopPuppeteer.java:50)
	at com.amazonaws.emr.node.provisioner.bigtop.BigtopDeployer.deploy(BigtopDeployer.java:21)
	at com.amazonaws.emr.node.provisioner.NodeProvisioner.provision(NodeProvisioner.java:25)
	at com.amazonaws.emr.node.provisioner.phase.PhaseWorkflow.work(PhaseWorkflow.java:56)
	at com.amazonaws.emr.node.provisioner.phase.ProvisionAppsPhase.perform(ProvisionAppsPhase.java:30)
	at com.amazonaws.emr.node.provisioner.Program.main(Program.java:20)"
Amazon Elastic MapReduce	"Re: EMR 5.11 fails with Hive Metastore on RDS
I tried upgrading last year and came across the same error. Here is the fix that I have done:

Step 1: Update version table in hive metastore to the relevant version # (EMR 5.11.0 - Hive version 2.3.2
Step 2: bring up the cluster.
Step 3: Using schema tool command execute the alter scripts for updating hivemeta."
Amazon Elastic MapReduce	"tried to create EMR but got ""Terminated with errors Internal error""
I just used the same way I used before in the aws region ""US West (N. California)"" where I had created EMR succeeded but failed in the aws region ""US East (N. Virginia)"".
Why the same way succeeded in ""US West (N. California)"" but failed in  ""US East (N. Virginia)""?

These are my failed EMR cluster id:
j-3GB812LYRS4UV	
j-2GJRJAPPT75QX	
j-1V98QWAOWCOD7	
j-156GSJCR4FV4Y	
j-IVOJR1081NE3	
j-F3IV9P99BTAA

Please help me!

Edited by: qpan on Nov 4, 2018 10:24 PM

Edited by: qpan on Nov 4, 2018 10:26 PM"
Amazon Elastic MapReduce	"Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
Hey!

I really need some way to run a bootstrap action after hadoop installs to get the environment just right. I believe this was somewhat possible to achieve in the past using hadoop-user-env.sh but this has been deprecated in emr 4. Is there any way to run bootstrap actions after hadoop install on emr 4?

Thanks!"
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
Hi, what is it that you are trying to accomplish with a BA after Hadoop is installed? Based on your mention of hadoop-user-env.sh, it sounds like you might just want to alter the Hadoop environment variables? If so, you may use the Configuration API, as described here: http://docs.aws.amazon.com/ElasticMapReduce/latest/ReleaseGuide/emr-configure-apps.html"
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
I just ran into the same issue.  I have a bootstrap action that depends on hadoop being installed.  What should we do?"
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
What is the goal that you are trying to achieve with this bootstrap action?"
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
I'm sorry to hijack this thread, but I am interested as well. I have a bootstrap action that downloads a .jar file (library) to the nodes into the class path. Is this still possible with the new configurations?

Source of bootstrap action is a bash script:
#!/bin/bash

JAR=json-simple-1.1.1.jar

wget -S -T 10 -t 5 -O /home/hadoop/lib/$JAR http://s3-eu-west-1.amazonaws.com/{bucket-name}/$JAR 
chmod 755 /home/hadoop/lib/$JAR

Edited by: websharecloud on Nov 25, 2015 9:14 AM"
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
Hi, 

At Jampp we use a lot EMR and Presto and we were needed to run some setup scripts after Hadoop and Preso were installed and started. We created a temporary work around until the people from Amazon enable bootstrap actions that can be executed after Hadoop and the other applications are up and running.

We needed yo run some code after Presto was setup so we found out that there is a pid file that indicates that Presto is running in /var/run/presto/presto-presto-server.pid 

So we created a bash script with the following content that we configured as a bootstrap action:

PRESTO_CONFIG_SCRIPT=$(cat <<EOF
while [ ! -f /var/run/presto/presto-presto-server.pid ]
do
  sleep 1
done
#DO stuff you need to do after presto is up and running
exit 0
EOF
)
echo ""${PRESTO_CONFIG_SCRIPT}"" | tee -a /tmp/presto_config.sh
chmod u+x /tmp/presto_config.sh
/tmp/presto_config.sh &
exit 0


This script executes the content of PRESTO_CONFIG_SCRIPT as a bacground process and lets the actual bootstrap action finish successfully. The backgroud script waits for Presto to be installed and started on once the pidfile is present executes the desired logic.

Hope you find this helpfull."
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
In my case I had to configure /etc/krb5.conf, but the EMR install kept overwriting my changes.
I managed to keep my custom configuration by protecting the file with chattr:
cat << 'EOF' > /tmp/krb5.conf
(...)
EOF
 
sudo mv /tmp/krb5.conf /etc/ 
sudo chattr +i /etc/krb5.conf


I hope this can help."
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
Thanks guys it did work !!

Just a brief about my requirement, I want to install Presto UDF's and UDF's can only be installed once the presto setup is done, I have followed the above said approach and it worked perfectly, I even tried verified adding Nodes and bootstrap is working fine on the new nodes as well

PRESTO_CONFIG_SCRIPT=$(cat <<EOF
while http:// ! -f /var/run/presto/presto-server.pid 
do
  sleep 1
done
#DO stuff you need to do after presto is up and running
sudo rm -f /usr/lib/presto/plugin/hive-hadoop2/presto-third-functions-0.5.1-shaded.jar
sudo hadoop fs -copyToLocal s3://xxx/presto/udfs/presto-third-functions-0.5.1-shaded.jar /usr/lib/presto/plugin/hive-hadoop2/presto-third-functions-0.5.1-shaded.jar
sudo chown presto:presto /usr/lib/presto/plugin/hive-hadoop2/presto-third-functions-0.5.1-shaded.jar
sudo stop presto-server
sleep 15
sudo start presto-server
#End Presto Stuff
exit 0
EOF
)
echo ""${PRESTO_CONFIG_SCRIPT}"" | tee -a /tmp/presto_config.sh
chmod u+x /tmp/presto_config.sh
/tmp/presto_config.sh &
exit 0

Edited by: RajivChodisetti on Jan 15, 2018 11:09 PM"
Amazon Elastic MapReduce	"Re: Run bootstrap action after hadoop install on emr-4.1.0/hadoop-2.6.0
I like this answer, but relying on the pid file seems potentially flaky. I attempted to run your code on a recent EMR version and the pid has actually changed. However much the same thing can be achieved with:

while [[ $(status presto-server) != *running* ]]
do
  sleep 10
done"
