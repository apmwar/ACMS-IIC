label	description
AWS Step Functions	"How to know whats going on with State machine?
Hi all,
In my use case, I am calling step function in three different way:

1. It is associated with method in API Gateway, so end user can invoke step function simply by clicking button on the web page.

2. State machine is also called in response to S3 event, so end user can upload file from web page, and thus invoke SF.

3. Finally, I am calling SM from another Lambda.

Now, the problem is - how to inform end user what is going on? 

Except in case 3. where I can periodically call DescribeExecution (and thus paying double - for Lambda that wait for SM to finish, AND for SM itself), I have no idea how to inform end user what happens? Was there an error? Did the action end successfully? Because of, all I am getting as output is ""executionARN"" and ""startDate"". State machine runs asynchronously, and thus completely out of my control.

Also, is there a way to get output from State Machine?"
AWS Step Functions	"Re: How to know whats going on with State machine?
Any help?"
AWS Step Functions	"Re: How to know whats going on with State machine?
Have you tried using iterator here?

https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-create-iterate-pattern-section.html"
AWS Step Functions	"Cannot trap lambda TooManyRequestsException
I am trying to properly handle a TooManyRequestsException thrown by a lambda function in my retry logic for a task, by appropriately setting a value in the ""ErrorEquals"" array.  I am unable to trap the error with anything other than using a type of ""States.ALL"".  I have tried ""States.Runtime"", ""UnhandledError"", ""HandledError"".  Could someone direct me to the appropriate value I should use to capture this error state?

Example of the error from lambda as reported in the Step Functions admin panel:
error: States.Runtime
cause: TooManyRequestsException: Rate Exceeded. (Service: AWSLambda; Status Code: 429; Error Code: TooManyRequestsException; Request ID: 66e83b98-e424-11e6-ae0c-416ccd2c66a3)

Example Step Functions Task Setup:
""Task1"": {
  ""Type"": ""Task"",
  ""Resource"": ""lambda_arn_here"",
  ""End"": true,
  ""TimeoutSeconds"": 300,
  ""Retry"": [{
    ""ErrorEquals"": ,
    ""IntervalSeconds"": 1,
    ""BackoffRate"": 1.5,
    ""MaxAttempts"": 10
  }]
}"
AWS Step Functions	"Re: Cannot trap lambda TooManyRequestsException
I think you need Lambda.TooManyRequestsException

Edited by: simbamford on Feb 21, 2019 1:23 AM"
AWS Step Functions	"State Machine for summing two numbers
Hi all,

Trivial scenario: the web application user enters two numbers on the web page, and press Submit button. The summing is done by State machine. The question is - how to take result and return it as HTTP response to the end user?
OR, if that is not possible in the same request/response sequence, how to take and push result to the user who called the operation?

P.S. Anyone experienced """"Your message quota has been reached. Please try again later"" when posting more than one thread per day here? Cannot believe that my quota is only one msg/day? Is there any way to increase that?

Edited by: Cvele on Feb 17, 2019 3:26 AM

Edited by: Cvele on Feb 17, 2019 3:28 AM"
AWS Step Functions	"Re: State Machine for summing two numbers
Anyone?"
AWS Step Functions	"Ability to time out executions waiting at a particular step for too long
It would be great if I could set a timeout for executions in an activity step that were never picked up by a worker.  Maybe all my workers went down or are busy, I would like to fail the execution after an amount of time less than the default 1 year."
AWS Step Functions	"Manual approvals using lambda functions made easy in Guflow
Latest release of Guflow: https://github.com/gurmitteotia/guflow will now let you easily implement support for manual approvals using serverless lambda functions. Here is a very simple example showing ""WaitForAnySignal"" API:
    [WorkflowDescription(""1.0"")]
    public class ExpenseWorkflow : Workflow
    {
        public ExpenseWorkflow()
        {
            ScheduleLambda(""ApproveExpense"")
              .OnCompletion(e=>e.WaitForAnySignal(""Accepted"", ""Rejected""))
              .WithInput(_=>new{Id});  //Send workflow id to lambda functions to send signals to this workflow.
            ScheduleLambda(""SubmitToAccount"").AfterLambda(""ApproveExpense"")
              .When(_=>Signal(""Accepted"").IsTriggered());
            ScheduleLambda(""SendRejectEmail"").AfterLambda(""ApproveExpense"")
              .When(_=>Signal(""Accepted"").IsTriggered());
        }
    }

Other APIs that you can use for waiting for signals are: WaitForAllSignals and WaitForSignal. These APIs will help you to move your workers from activities to serverless lambda functions. 

You can call these APIs anywhere in workflow e.g. in the following example ""ApproveExpense"" is a child workflow:
    [WorkflowDescription(""1.0"")]
    public class ExpenseWorkflow : Workflow
    {
        public ExpenseWorkflow()
        {
            ScheduleChildWorkflow<ApproveExpense>()
              .OnCompletion(e=>e.WaitForAnySignal(""Accepted"", ""Rejected""));
            ScheduleLambda(""SubmitToAccount"").AfterLambda(""ApproveExpense"")
              .When(_=>Signal(""Accepted"").IsTriggered());
            ScheduleLambda(""SendRejectEmail"").AfterLambda(""ApproveExpense"")
              .When(_=>Signal(""Accepted"").IsTriggered());
        }
    }

You can find the detailed document about signal supports in Guflow here: https://github.com/gurmitteotia/guflow/wiki/Workflow-signals

Other interesting examples of manual approvals using lambda functions can be found here: https://github.com/gurmitteotia/guflow-samples/tree/master/ServerlessManualApproval

Edited by: Gurmit S. on Feb 7, 2019 4:30 AM"
AWS Step Functions	"Can we increase the size limit of input parameter?
We received the following error while executing the step function:
“An error occurred (ValidationException) when calling the StartExecution operation: 1 validation error detected: Value at 'input' failed to satisfy constraint: Member must have length less than or equal to 32768: ClientError”

Is it possible to increase the limit of 32,768?"
AWS Step Functions	"Use StringEquals to compare to null?
Hi Team,

Would it be possible to enable support for comparison of a string value to null? Currently, if I specify the condition as ""StringEquals"": null, the state machine fails to be created, and statelint says that ""StringEquals should be non-null"". There are some situations where null comparison is useful. Are there any workarounds for that at the moment?

Thanks"
AWS Step Functions	"Re: Use StringEquals to compare to null?
+1  I'm running into the same situation.  Sometimes I want to check for the existence of NULL with a Choice."
AWS Step Functions	"Re: Use StringEquals to compare to null?
+1, I am also badly required for validating null. We have many integrations and having dynamic behavior , expect null values and during the case I need to drive the flows."
AWS Step Functions	"Re: Use StringEquals to compare to null?
+1 I am in a similar situation and it does not make sense to send the request to a lambda function to do the check required

Edited by: danishsaj on Jan 23, 2019 3:21 PM"
AWS Step Functions	"Declaring Comment on And/Or Choice object throws internal error
While testing a Choice state I attempted to declare a Comment field on an And object and found that the Step Function engine throws a ""States.Runtime Internal Error"" immediately upon execution (regardless of where this Choice declaration exists in the state machine definition). 

The documentation for States says that a Comment field may placed on any State object, however it does not explicitly say that it may be used on Choice objects. In practice placing a Comment field on a simple Choice object works, while placing it on an And or Or object creates this internal failure.

https://docs.aws.amazon.com/step-functions/latest/dg/concepts-states.html

The following State Machine definition will pass editor validation, but fail execution, every time. Removing the ""Comment"" field from the ""And"" Choice object will allow it to execute.

{
  ""Comment"": ""My step function."",
  ""StartAt"": ""Validate Input"",
  ""States"": {
    ""Validate Input"": {
      ""Type"": ""Choice"",
      ""Choices"": [
        {
          ""Comment"": ""Comment for this choice."",
          ""Variable"": ""$.value1"",
          ""BooleanEquals"": true,
          ""Next"": ""Complete""
        },
        {
          ""Comment"": ""Comment for this other choice"",
          ""And"": [
            {
              ""Variable"": ""$.value1"",
              ""BooleanEquals"": false
            },
            {
              ""Variable"": ""$.value2"",
              ""BooleanEquals"": true
            }
          ],
          ""Next"": ""Complete""
        }
      ]
    },
    ""Complete"": {
      ""Type"": ""Succeed""
    }
  }
}


Sample payload:

{
   ""value1"": false,
   ""value2"": true
}


Edited by: ntaylor on Jan 23, 2019 9:41 AM"
AWS Step Functions	"Multiple retriers on an async lambda task, error type always aggregate exc
I have a lambda task in my step function that executes asynchronously. I would like to retry a different number of times based on the inner exception type, however, since it's async the exception returned is always an aggregate exception. 

I've considered converting to synchronous, but I'm concerned that will make it too slow and it seems extreme just for handling retries.

I've also considered catching all the exceptions and converting them to a return as a result instead, but I'd rather not mask the exception and have to write a custom retry when there's already one built in.

Any other ideas?"
AWS Step Functions	"Step functions documentation
When I googled, I came across variable like $.stepId being used in stepfunction. But I dont find these in AWS stepfunctions documentation. Where can I find the documentation on these. How are people finding and using these variables if AWS haven't documented

Edited by: Chandra-aws on Jan 16, 2019 3:46 AM"
AWS Step Functions	"Parallel State
How do i make my state machine to wait for the execution of all branches in my parallel state machine? This sample state machine has two branches; pass and fail. The ""fail"" branch sleeps for 5 sec before raising an exception. I'd like to trigger ""Notify failure"" once the fail branch fails but in my existing set up, the since the pass branch immediately passes, the control goes over to Notify Failure right away and fail branch shows up as running forever. What am I doing wrong?
{
  ""Comment"": ""Parallel Example."",
  ""StartAt"": ""Parallel Task1"",
  ""TimeoutSeconds"": 120,
  ""States"": {
    ""Parallel Task1"": {
      ""Type"": ""Parallel"",
      ""Branches"": [
       {
         ""StartAt"": ""pass"",
         ""States"": {
           ""pass"": {
             ""Type"": ""Task"",
             ""Resource"":""arn:aws:lambda:us-west-2:xxxxxxxxx:function:passfunction"",
             ""End"": true
           }
         }
       },
       {
         ""StartAt"": ""fail"",
         ""States"": {
           ""fail"": {
             ""Type"": ""Task"",
             ""Resource"":""arn:aws:lambda:us-west-2:xxxxxxxxxx:function:failfunction"",
             ""End"": true
           }
         }
       } 
      ],
      ""Catch"": [
        {
          ""ErrorEquals"": [""States.TaskFailed""],
          ""Next"": ""Notify Failure""
        }
      ],
      ""Next"": ""Notify Success""
    },
    ""Notify Failure"": {
      ""Type"": ""Pass"",
      ""Result"": ""This is a fallback from a task failure"",
      ""End"": true
    },
     ""Notify Success"": {
      ""Type"": ""Pass"",
      ""Result"": ""This is a fallback from a task success"",
      ""End"": true
    } 
    }
  }"
AWS Step Functions	"Re: Parallel State
I would create a new pass step and make it the next step of both parallel steps.  when error occurs let lambda indicate that in the output. After the pass step create a choice step and depending on the value returned by lambda notify the error."
AWS Step Functions	"Retrieving input varibles
Hello,
I have a complex step function with complex json input calling different lambdas depending on the input.  I have an activity task in the function.   when the worker program invokes ""send_task_success"" it sends tasktoken and nothing else.  So the next state input is noting but task token. I would like the next state to have the input that is passed to statemachine. 

Is there anyway to retain/retrieve the input passed to stepfunction into the state after activity. In the below statemachine I would like to have the input that is passed to Step initially. But what I get is the return value of ""arn:aws:states:us-east-1:AccountID:activity:MyTeam-subteam-raw"" in the state wait-for-response. Is there a way to retrieve the input passed to execution in the continueStep.

{
  ""StartAt"": ""invoke-delta"",
  ""Comment"": ""Raw to stage step - v0.2"",
  ""States"": {
    ""invoke-delta"": {
      ""Type"": ""Task"",
      ""Resource"": ""arn:aws:lambda:us-east-1:AccountID:function:Myapplicationdelta-load-dispatcher"",
      ""Next"": ""create-activity""
    },
      ""create-activity"": {
      ""Type"": ""Pass"",
      ""Result"": {
        ""activityArn"": ""arn:aws:states:us-east-1:AccountID:activity:MyTeam-subteam-raw"",
        ""stepMachineArn"" : ""arn:aws:states:us-east-1:AccountID:stateMachine:MyTeam-usi-subteam-raw-to-stage""
      },
      ""ResultPath"": ""$.ARN"",
      ""Next"": ""notify-worker""
    },
      ""notify-worker"": {
      ""Type"": ""Task"",
      ""Resource"": ""arn:aws:lambda:us-east-1:AccountID:function:Myapplicationtrigger-activity"",
      ""Next"": ""wait-for-response""
    },
    ""wait-for-response"": {
      ""Type"": ""Task"",
      ""Resource"": ""arn:aws:states:us-east-1:AccountID:activity:MyTeam-subteam-raw"",
      ""Next"": ""ContinueStep""
    },
    ""ContinueStep"": {
      ""Type"": ""Task"",
      ""Resource"":""arn:aws:lambda:us-east-1:AccountID:function:Myapplicationiicsreqs"",
      ""Next"": ""raw-to-stage-close""
    },
     ""raw-to-stage-close"": {
      ""Type"": ""Task"",
      ""Resource"": ""arn:aws:lambda:us-east-1:AccountID:function:Myapplicationraw-to-stage-job-close"",
      ""End"": true
    }
  }
}

Edited by: Chandra-aws on Jan 15, 2019 6:03 PM"
AWS Step Functions	"Delayed execution of ECS task
I'm hoping someone could shed some light on an issue that I've encountered running a state machine with an ECS task. My task in the state machine executes in 2-3 seconds, but the same task run from the ECS console takes only ~500ms. Is this within range of normal execution time for a Step Functions' ECS task?"
AWS Step Functions	"Re: Delayed execution of ECS task
The latency is normal.

After your ECS task completes, ECS publishes an event to CloudWatch Events. There may be a bit of delay between your task completing, and ECS sending the event to CWE.

When CloudWatch gets your event, it goes through multiple internal services, gets matched against the Managed Rule we have registered in CloudWatch Events, and get sent to Step Function's queue (routing). The delivery of the event from the time it is received by CloudWatch Events to the time it gets into Step Function's queue takes additional time.

Lastly, Step Functions needs to poll its queue and process the events one by one, figure out which execution it came from, and change the state of your execution to TaskSucceeded or TaskFailed, which also takes additional time.

All together these latency may add up to few seconds, and that is completely normal."
AWS Step Functions	"Re: Delayed execution of ECS task
Thank you for the explanation, it was very informative. Would there be a more optimal approach I can take to reduce latency? Perhaps using activities?"
AWS Step Functions	"Step Function integration Parameters
I'm using Step Function new feature to send message directly to SQS (or SNS). While it's easy to send simple test message or string value from the input, sending JSON is not possible.
If I have the input JSON 
{""foo"": ""fooval"", ""bar"": ""barval""}

and the ASL is
{
    ""Comment"": ""A Hello World example of the Amazon States Language using a Pass state"",
    ""StartAt"": ""Send to SQS"",
    ""States"": {
      ""Send to SQS"": {
     ""Type"": ""Task"",
     ""Resource"": ""arn:aws:states:::sqs:sendMessage"",
     ""Parameters"": {
       ""QueueUrl"": ""https://sqs.us-west-2.amazonaws.com/........."",
       ""MessageBody.$"": ""$""
     },
     ""End"": true
    }
    }
  }

i getting the error 
{
  ""error"": ""States.Runtime"",
  ""cause"": ""An error occurred while executing the state 'Send to SQS' (entered at the event id #2). The Parameters '{\""QueueUrl\"":\""https://sqs.us-west-2.amazonaws.com/478582646844/itero-caas-test-callback-sqs\"",\""MessageBody\"":{\""foo\"":\""fooval\"",\""bar\"":\""barval\""}}' could not be used to start the Task: [The field 'foo' is not supported by Step Functions, The field 'bar' is not supported by Step Functions]""
}

I cannot find the solution how to convert JSON to the string using ASL and JSONPath."
AWS Step Functions	"Re: Step Function integration Parameters
We have whitelisted four fields to accept JSON Objects and Arrays. This should solve your problem:
SQS: MessageBody and StringValue
SNS: Message and StringValue

{
    ""StartAt"": ""Send to SQS"",
    ""States"": {
      ""Send to SQS"": {
        ""Type"": ""Task"",
        ""Resource"": ""arn:aws:states:::sqs:sendMessage"",
        ""Parameters"": {
          ""QueueUrl"": ""https://sqs.us-west-2.amazonaws.com/........."",
          ""MessageBody"": {
            ""foo"" : ""bar""
          }
        },
        ""End"": true
      }
    }
  }

should work.

{
    ""StartAt"": ""Send to SQS"",
    ""States"": {
      ""Send to SQS"": {
        ""Type"": ""Task"",
        ""Resource"": ""arn:aws:states:::sqs:sendMessage"",
        ""Parameters"": {
          ""QueueUrl"": ""https://sqs.us-west-2.amazonaws.com/........."",
          ""MessageBody"": [
            1, 2, 3, 4
          ]
        },
        ""End"": true
      }
    }
  }

should work.

The JSONPath versions of them (your ask) should be working as well. Please verify that is the case."
AWS Step Functions	"Meaning of "".$"" construct in task parameters
Since the new integrations were added, the documentation contains several examples where a parameter key has .$ appended to it. I cannot find an explanation nor do I have any intuition for its meaning.

For instance, when sending an SNS message in a task, some examples specify the message parameter as, ""Message.$"": ""..."", while other examples specify it as, ""Message"": ""..."" .

What does the .$ construct mean, exactly? When do I need to use it?"
AWS Step Functions	"Re: Meaning of "".$"" construct in task parameters
.$ at the end of a key tells Step Functions that it must interpret the value associated with the key as a JSONPath.

""Message"": ""Hi""
sends the message Hi verbatim to SNS.

""Message"": ""$.Hi""
sends the message $.Hi verbatim to SNS.

""Message.$"": ""$.Hi""
tells Step Functions $.Hi needs to be interpreted before anything is sent to SNS. Step Functions looks at the effective input, and tries to resolve the JSONPath $.Hi. If the effective input contains a key called Hi, its value will be sent as a message to SNS. For example
input : {""Hi"": ""Oh my!""}
results in Oh my! being sent to SNS.

This applies to all the keywords support by the Parameters field.

Edited by: alibaghani on Jan 14, 2019 1:58 PM"
AWS Step Functions	"Step Function Integrations Clobbering Input Object
Loving the new Step Function integrations with other services, specifically I'm using Batch and Glue integrations. However I'm running into the issue where the output from the integrations is clobbering my initial object. Example, my input object to the step function might be,
{
  ""tableName"": ""table1""
}
Then the first step could be to run a Batch Job, the output of that step is the result object from the batch job and my input object from above is gone. This prevents me from passing configuration parameters to the next step. I have several Lambda's that do setup, then run Batch, Glue and a final lambda that needs to do some cleanup but the lambda does not have any context because each step clobbers the previous step's output. How can I ensure that objects are pass through each step?

Thanks!"
AWS Step Functions	"Re: Step Function Integrations Clobbering Input Object
You should use the ""ResultPath"" to mix input and output of a state.

From: https://states-language.net/spec.html
The value of “ResultPath” MUST be a Reference Path, which specifies the raw input’s combination with or replacement by the state’s result.

For example usage, you can take a look at the Sample Project on the Step Functions console that reads data from a DynamoDB table and sends them as messages to SQS."
AWS Step Functions	"Return the result of AWS Fargate Task back to Step function
When Step function invokes AWS Fargate tasks, is there a way for the running container to send the result of it's execution back to the Step Function ? 

The only way I have figured out so far is to call the endpoint that I found in one of the environment variables (ECS_CONTAINER_METADATA_URI) to get the Task ARN and then stop the ECS task with my intended result inside the ""Reason"" property."
AWS Step Functions	"Step Functions Timeout 400 in previously working code
I had a piece of java code that was working fine for months. One good day, without changing anything on my side, I started getting the following error.
Service: AWSStepFunctions; Status Code: 400; Error Code: TaskTimedOut

It has been about a month now and I am still getting the error. It causes my step function to time out as the program can never report success to it.
Any ideas?"
AWS Step Functions	"Re: Step Functions Timeout 400 in previously working code
Just wanted to add that the program (a java program that runs daily on EC2) has no problem sending the heartbeat to the step function. It also has no problem with any other task that requires an internet connection.

Trying to report success to the step function always returns a timeout. No other exception is ever thrown. I have confirmed that the step function is live and running, waiting for the program to report success or failure (which never happens).

There is no documentation as to what might be causing the timeout. I suspect something is crashing on the server side iof step functions. 

Edited by: JOHN TSIOKOS on Dec 7, 2018 12:32 AM

Edited by: JOHN TSIOKOS on Dec 7, 2018 12:33 AM"
AWS Step Functions	"Re: Step Functions Timeout 400 in previously working code
Turns out I had misunderstood the ""TimeoutSeconds"" parameter inside the step functions defintion. The timeout will happen even if the program continues to send heartbeats, which is, of course, the desired behavior.

My program's running time just grew longer than the timeout so when the program would try to report success to step functions, step functions had already timed out and there was no answer. It might have been easier to debug this if a more specific exception was thrown by AWS (rather than a java method timeout)."
AWS Step Functions	"TaskTimedOutException when trying to complete a task twice
If you try to complete a task with the same task token twice, the second completion will throw an exception with error code:

(Service: AWSStepFunctions; Status Code: 400; Error Code: TaskTimedOut; Request ID: 5a421435-e826-11e6-aafb-8b939fb54c73)


There should probably be a unique error thrown when applications try to complete the task twice."
AWS Step Functions	"Re: TaskTimedOutException when trying to complete a task twice
I think there is a bug on the Amazon server side. I had a piece of java code that was working fine for months. One good day, without changing anything on my side, I started getting the following error.
Service: AWSStepFunctions; Status Code: 400; Error Code: TaskTimedOut

It has been about a month now and I am still getting the error. It causes my step function to time out as the program can never report success to it. AWS hsould look into this asap."
AWS Step Functions	"Add input in Step Functions state
Is it possible to append input in a Step Functions state?

For example, I have a lambda that looks for input that is not present in the initial input and runs a different code path depending on that input. This way I can write one lambda and use it in multiple ways.

Can input be appended in a Step Functions state?"
AWS Step Functions	"Re: Add input in Step Functions state
The Pass state lets you append constants into state. 

Whatever is specified in the 'Result' property will be placed at the path in the 'ResultPath' property, as in https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-pass-state.html.

We use a Pass state immediately before a generic Lambda to set up args to configure the function."
AWS Step Functions	"Re: Add input in Step Functions state
Thanks!"
AWS Step Functions	"Re: Add input in Step Functions state
Step Functions just added support for a ""Parameters"" field. It provides more flexible input processing capabilities. Please try it out. 

You may not need an extra pass state anymore with the ""Parameters""."
AWS Step Functions	"Use variable in Result item in Pass state
Is it possible to use variable in ""Result"" item in ""Pass"" state ?

My case:
I have three states work in sequence as below:
1. Get one record from table A (with original input json data).
2. Parse the output of Step1, build up the new input argument for next step.
3. Call anther lambda function with input json data built at step2 above.

The question is:
In step2, I need to build the input json data for next step. Some of fields are const, while, some others are from the output of step1. So I do this in step2 in a ""Pass"" state, I use ""Result"" item to build up the new json structure. However, based on my testing, the ""Result"" doesn't support variable. For example, if set it as ""Result"": {""id"": ""$.resultFromStep1.body.id""}, then the id value is the string ""$.resultFromStep1.body.id"", it is not replaced by the value of the variable $.resultFromStep1.body.id I got from step1. Can I use such kind of variable in ""Result"" item ?

Appreciate for your help !

Regards,
Fanchao"
AWS Step Functions	"Re: Use variable in Result item in Pass state
Could someone from AWS please respond to problems like this.
The limited input & output processing is probably one of the most annoying problems with step functions right now.
But for some reason, I don't see AWS comment about this problem.
Why is this?"
AWS Step Functions	"Re: Use variable in Result item in Pass state
Step Functions just added support for a ""Parameters"" field. It provides more flexible input processing capabilities. Please try it out."
AWS Step Functions	"Replace JsonPath with Jmespath to transform data
I've been evaluating if Step Functions can simplify one of my projects and so far it's looking good. I specially think the Path options in the states language are a simple yet powerful feature, but I was wondering about the choice of using JsonPath. Jmespath http://jmespath.org/ is more feature-complete and would add way more flexibility at not too much of a cost.

I ask about JmesPath because I've seen it used in other AWS products, but if I had a choice, I'd use jq  https://github.com/eiiches/jackson-jq.

An example shortcoming of JsonPath can be seen at https://github.com/jayway/JsonPath/issues/272

Do you think adding a parameter for the path interpreter fits in your vision of Step Functions? Thanks!"
AWS Step Functions	"Re: Replace JsonPath with Jmespath to transform data
+1

I need to be able to use a simple formatting or string concatenation in Pass tasks. Check the path example  below:
""Read Members"": {
    ""Type"": ""Pass"",
        ""Result"": {
            ""store"": ""$.group"",
            ""path"": ""/v1.0/groups/"" + ""$.group"" + ""/members""
          },
    ""ResultPath"": ""$.config"",
    ""Next"": ""Get Members""
},"
AWS Step Functions	"Re: Replace JsonPath with Jmespath to transform data
+1 I need that too. JQ is the way to go. Please add support."
AWS Step Functions	"Re: Replace JsonPath with Jmespath to transform data
Step Functions just added support for a ""Parameters"" field. It may not be as versatile as what has been suggested in this post, yet provides more flexible input processing capabilities. Please try it out."
AWS Step Functions	"JSONPath interpolation in Pass Result field
I am finding the Pass state very helpful as mentioned in the guide, to help create a state machine and debugging. I am able to create the entire state machine and have all states as Pass, and add the expected output.

As I build out larger state machines, I find myself having to run a lambda function Task before running the actual Task, which manipulates the state ready for the next Task.

What would be awesome is if in the Pass `Result` field, I could interpolate values from the input state to add in other fields in the output state, for example...

{
  ""Type"": ""Pass"",
  ""Result"": ""output_folder/$.input_file"",
  ""ResultPath"": ""$.output"",
  ""Next"": ""DownloadFile""
}


I could then replace these ""preparation"" type lambda tasks with a simple Pass state.

The alternative solution I have is to just support the various state input as it is in each Task, however this would then start to tie activities into a one-to-one relationship with state machines, as opposed to one-to-many.

Thanks!

Edited by: BillSham on Dec 5, 2016 5:22 AM

Edited by: BillSham on Dec 5, 2016 5:27 AM"
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
As a general rule, we don't comment on the future direction of the service. Thank you for sharing this feature request!"
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
+1 for this feature. Allowing Pass state to use input data in order to generate the Result data would be very useful.
Similar to Mapping Templates in API Gateway it would offers a very powerful tool to model inputs between tasks.

Edited by: koxonbif on Dec 16, 2016 1:37 AM"
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
Another +1, this would really simplify things avoiding the need to create extra lambda functions just to restructure the inputs to the next task state, instead simply being able to perform this in a Pass state's Result field would be nice."
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
Another +1

We are not using Step Functions just because this functionality is missing. For now it's easier to create our workflow in single Lambda function than migrating to Step Functions.

Basically I want to invoke Lambda functions with custom transformed JSON event based on previous Input."
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
I think Step Functions could really use App Sync's mapping templates.
They allow for much more flexibility with makes decompiling your service way easier.
Please include this."
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
Step Functions just added support for a ""Parameters"" field. It provides more flexible input processing capabilities. Please try it out."
AWS Step Functions	"Re: JSONPath interpolation in Pass Result field
Thank you sooo much!!! Have already started to use it!"
AWS Step Functions	"Place the raw input in the context of another json object
I understand how ""ResultPath"" allows you to insert the ""Result"" into the raw input. But a lot of times what we need is the opposite: to define a new object and insert the raw input into it.

For example, if I have a lambda called ""ProcessData"", that expects input of the form:
{data: ...json data to process, options: {compact: Boolean}}


And I would like to use that lambda in a task to process the output of a previous state:
{
   ...,
   ""GetData"": {
     ""Type"": ""Pass"", // using Pass for brevity sake, in practice this would be task calling a lambda that produces the result and should not be burdened with formatting it for some other lambda
     ""Result"": {...some data to process...}
   },
   ""Process"": {
     ""Type"": ""Task"",
     ""resource"": ""arn:...lambda...:ProcessData""
   },
   ...
}


There's currently no way to transform my raw input from:
{...some data to process...}

To:
{data: {...some data to process...}, options: {compact: true}}

Which is what the lambda expects. 

There's no easy way to ""wrap"" the input, only select a single subset of it, which is very limiting.

This could be easily achieved if the path language used was more powerful, like what the `jq` tool uses:
""OutputPath"": ""{data: ., options: {compact: true}}""


It would also allow you to extract multiple paths out of the raw input and build a new object.

This feature would make it step functions SO much more usable. The only work around at the moment for us is to structure the initial input in a way that might work as input to any of the later lambdas, and/or create a bunch of lambdas that all they that just do some basic json massaging of the data.

Thanks.

Edited by: alvaro_c1 on Aug 15, 2017 10:20 AM"
AWS Step Functions	"Re: Place the raw input in the context of another json object
+1"
AWS Step Functions	"Re: Place the raw input in the context of another json object
Step Functions just added support for a ""Parameters"" field. It provides more flexible input processing capabilities. Please try it out."
AWS Step Functions	"Why do we have extremely limited input & output processing?
I think Step Functions could really use App Sync's mapping templates.
One of the most frustrating problems with Step Function is how limited the input & output processing is.
App Sync, for example, allows for much more flexibility to do very powerful input & output processing.
With Step Functions, I now need to decide if I wanna put a lambda in between every state or make my services less decoupled.
Can anyone tell me if this issue is getting addressed anytime soon?
I'm at the point of pulling my hair out.

Edited by: Ivands on Aug 27, 2018 8:14 AM"
AWS Step Functions	"Re: Why do we have extremely limited input & output processing?
Step Functions just added support for a ""Parameters"" field. It provides more flexible input processing capabilities. Please try it out."
AWS Step Functions	"Guflow now supports all the features of Amazon SWF
Guflow now supports all the relevant features of Amazon SWF. The latest releases now fully supports scheduling of child workflows. I have created a simple example-https://github.com/gurmitteotia/guflow-samples/tree/master/ChildWorkflow, to show scheduling of a child workflow and coordination using signals. A few lines of code handle many concurrent situations elegantly.

Feature highlights:
-Supports all relevant features of Amazon SWF
-Allows creation of complex workflows with ease
-Supports fork/join and parallel execution of workflow branches
-Supports activity throttling
-Allows async/sync methods for activity
-Powerful query APIs to parse event history (very useful in making custom decisions)
-Supported by behavioural unit tests and integration tests. Even the small improvements released to the community.

There are many nice features in the pipeline and it is open to the contributions from community.
Guflow, hosted on github-https://github.com/gurmitteotia/guflow,  is a C#.Net open source library to program Amazon SWF.

Gurmit"
AWS Step Functions	"CloudFormation template with State Machines fails silently
I'm not sure this is the right place to ask this question, so if I should bump it over to the CloudFormation threads please let me know.

I have been working on a stack for a while now, iterating and growing the complexity.  The stack includes what has become a large-ish state machine.  Now, when trying to update the stack using Visual Studio it fails.  I've confirmed the template and state machine definition string are well formed.  The error occurs before the change set has been created (probably while trying to create the change set).

When I switch to the CLI I can create the change set successfully, but the stack fails to update.  In the events, there is no record of even trying to create the state machine.  Ultimately, the change set times-out and is rolled-back. This is why I'm posting here -- it seems like the issue is something to do with the CloudFormation communication with Step Functions. 

I'm sure I'm bumping-up against some limit here, but after trying a bunch of different simplifications I still can only get it to work with a version that's ~43K.  A different version that's 52K fails with:

Error creating CloudFormation change set: Error unmarshalling response back from AWS. Request ID: 9f39ff5c-0864-11e8-9f45-178404ae6591, Response Body: <ErrorResponse xmlns=""http://cloudformation.amazonaws.com/doc/2010-05-15/"">

Help?"
AWS Step Functions	"Re: CloudFormation template with State Machines fails silently
I found that this was because the maximum payload size that can be sent to the VerifyTemplate API is 42K, and that's the API the Visual Studio tools uses.  The workaround is to use the CLI and S3 URLs for the template rather than posting the template body in the request.

This is painful and silly, but it works."
AWS Step Functions	"Wait for signal from external system
When would it support ""Wait for signal from external system via API call""?
For BPM this is very important feature.
Thanks!"
AWS Step Functions	"Re: Wait for signal from external system
As a general rule, we don't comment on the future direction of the service, but we'd be interested in hearing the details of your use case. We have heard from customers on interest in support for handling external signals/events."
AWS Step Functions	"Re: Wait for signal from external system
Use case is ecommerce related amd applicable to any long running state machine. Basically to support external signal/event step. Also human step and tasklist. Thanks!"
AWS Step Functions	"Re: Wait for signal from external system
I have a similar need, was considering the use of activities in the short term.

https://docs.aws.amazon.com/step-functions/latest/dg/activity-tutorial.html"
AWS Step Functions	"Re: Wait for signal from external system
I was thinking about using Step Functions to implement a chatbot. In that use case, the state machine would transition when a user message is received through API Gateway. It could be forwarded to Step Functions via an SNS topic, or just by a direct API call from Lambda. It would just be necessary to set the state machine to a generic ""waiting for input"" state that can be waken up.

It seems to me that this way, a custom DynamoDB (or other database) state implementation could be avoided. The state would be maintained by Step Functions and modified whenever user messages are received.

It would probably be useful for the ""waiting for input"" state to support custom timeouts, so that user sessions would expire e.g. after 1 hour of idle time."
AWS Step Functions	"Re: Wait for signal from external system
We have utilized activities.  The issue is that activities behave somewhat like an SQS queue, and once they are popped off they either need to timeout back on, or be handled.

We resolved this by having a poller that grabs them, and a DB to store the taskToken and payload.  This allows exposing a Query pattern to ""find"" the activity you want, and letting a human/bot then complete the task.

Attached is a markdown describing it, as well as how we wished it would look in an ideal AWS future.

Cheers"
AWS Step Functions	"Re: Wait for signal from external system
Thanks for the markdown describing your workaround. It helped a lot.
We have a similar use case where we want to execute a BPM which has human interactions. Step functions do not look like a proper fit for this use case as it does not allow to query for a specific activity of a specfic execution via Execution Arn. Looking at the way you solved this problem using poller. It looks like a good workaround, but, looking at how much hack you needed to put in, it feels like step function is a force fit for use cases requiring human interaction.
What do you think? Should we try to look at some other option? Maybe AWS SWF?"
AWS Step Functions	"Re: Wait for signal from external system
A perfect use case for this is as follows:

Send email to user, wait for response
User clicks on link in email which triggers next step

This is a VERY common scenario that mature workflow engines can easily handle.  It could be implemented as a HTTP POST WAIT STATE that will wait indefinitely or by some timeout period.  Then, it will wait for an HTTP POST to a specific URL which the user (or external system) would POST to.  This would trigger the workflow to continue to next step.

This functionality would elevate Step Functions to a whole new level of usefulness."
AWS Step Functions	"Re: Wait for signal from external system
+1 - definitely a required feature for us before we can start considering step functions as a platform for BPEL/BPMN style processes.

Franck"
AWS Step Functions	"Re: Wait for signal from external system
You may be interested in this blog on manual approval steps. https://aws.amazon.com/blogs/compute/implementing-serverless-manual-approval-steps-in-aws-step-functions-and-amazon-api-gateway/"
AWS Step Functions	"Re: Wait for signal from external system
Thank you!!!!"
AWS Step Functions	"Re: Wait for signal from external system
It would still be nicer if we didn't have to poll. Having a Lambda running 24/7 just to poll for a rare event seems to go against event-driven philosophy and accumulates avoidable costs. In addition, it gets harder to handle many requests in parallel. We can do so in a single Lambda up to a limit, but for higher rates we'd still have to schedule multiple Lambdas in parallel (each one in turn handling multiple pollers).

Would it be possible to instead ""tell"" Step Functions to resume execution of a state machine (without idle waiting on behalf of Lambda or EC2)?

One workaround is to split each Activity task into 2 Lambda steps, and then periodically check for some condition in the second step. This is still polling, albeit reduced. And it bloats the template for the state machine.

Another trick could be to start the poller Lambda at the start of the execution, and stop it at the end. That at least avoids running it 24/7, and decouples concurrent executions. But the costs may get steeper for higher rates of execution.

Edited by: denvlad on Feb 16, 2017 7:25 PM"
AWS Step Functions	"Re: Wait for signal from external system
Perhaps you (or I) am misunderstanding this but I don't think you have to setup a Lambda to poll 24/7 to wait for the event.  I think this happens automatically behind the scenes so why does it matter?

Update:  It appears I'm wrong.  Ok, so I think this is quite a shortcoming of the system.  It requires us to setup a long polling resource of some type, be it Lambda or EC2.  What I don't like about the lambda route is the potential cost impact of having a veryear long running process and that Cloudwatch will only schedule in one minute increments.  This is too long to wait.  The alternative is to setup an EC2 instance that processes these external events but that means it's no longer serverless.

What I was REALLY hoping for was AWS providing a truly serverless option without having to setup some external long polling resource, for which we have to both pay for and manage.  But, I guess this is better than nothing.

Edited by: softwareguy74 on Feb 16, 2017 8:47 PM"
AWS Step Functions	"Re: Wait for signal from external system
Exactly! It ""feels"" counter-productive for ""serverless"" applications. When I started working with AWS, we were planning to run this logic on EC2 with SWF, and it seems we're coming back to square one, just in a simpler package.

As to the costs, it's relatively minor - one Lambda with 128 MB RAM would come around ~$5/month, or ~$0.007/hr, which is not a lot compared to other instances (slightly more than a t2.nano).

The main question is (if we stick to this model), how well does it scale? I'm hoping to run a few tests to estimate how many parallel queries would fit in that amount of resources. If it's hundreds, then this is not bad at all. Scaling beyond that would mean just adding more memory and more copies of that Lambda.

Edited by: denvlad on Feb 17, 2017 1:15 AM"
AWS Step Functions	"Re: Wait for signal from external system
What if instead of having that polling function triggered by a CloudWatch schedule, it's triggered by a StepFunction task parallel to the human activity task? That way, the lambda fn that calls GetActivityTask only runs when there's an execution waiting and it runs as soon as there's an execution waiting for that activity.

The downside is you have to create a second lambdafn whose only purpose is to invoke the first lambdafn that actually calls GetActivityTask. 

https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html"
AWS Step Functions	"Re: Wait for signal from external system
Figured I'd add a use case. Data processing by external resources.

1. Data is sent in to the step function entry point
2. One of the steps sends data to an external API, asking to copy and alter data in 3-4 different ways, giving a callback URL when finished. This could take an hour, two, ten, etc.
3. That external API hits that callback URL when finished, possibly with data, signaling complete.
4. Step functions pick up where it left off. 

This works in SWF with Signals just fine now, and would be nice if it was a little more seamless with step functions.

I'm trying the solution in the link above ( https://aws.amazon.com/blogs/compute/implementing-serverless-manual-approval-steps-in-aws-step-functions-and-amazon-api-gateway/ )"
AWS Step Functions	"Re: Wait for signal from external system
Hi,
I just came across your post when looking for a solution myself. I appreciate it's a long time ago since you posted this but I was wondering if you implemented your suggestion or found another way to go about this?

Regards,
Lars"
AWS Step Functions	"Retry Execution
Is there a way to retry an execution arn? It'd be great to retry failed executions, or to just run the same execution for updates. It seems that now you have to create a new execution, with a new name, new ARN, and thus you have to increment the name in order to retry."
AWS Step Functions	"Re: Retry Execution
I work on the Step Functions service.

Could you expand a bit on what you're trying to do?  You can certainly retry states in a state machine, see https://states-language.net/spec.html#errors

You can also start a state machine executing as many times as you want through the API or console.  But I think you're asking for something else."
AWS Step Functions	"Re: Retry Execution
I'm not referring to retries in the state logic, but retrying an execution. For example, I create a state machine with a few steps. I then create an execution passing input. Whether it fails or succeeds, I'd like to be able to run that exact same execution again, with same inputs. Right now I have to create a new execution, with a name like 'v2', and run it again. The execution retry would in essence be a new execution as well, but it'd copy the original input and name over, so you wouldn't need to increment execution names."
AWS Step Functions	"Re: Retry Execution
While what you're describing is not supported today, it could become a new feature on our roadmap. Could you elaborate on your use case? Would you like the execution to automatically retry, or just have the ability to have the start state machines with the same execution name and version numbers associated with each individual execution?"
AWS Step Functions	"Re: Retry Execution
Not automatically, but manually or through SDK. Versioned would be fine. We're using Step Functions to process NFL data. We create a state machine as our pipeline to get all the necessary data and do some transformations. First lambda grabs game stats, second lambda grabs play level stats, third lambda does some aggregations, etc. It works great run once, but often stats are updated and we need to rerun our pipeline to process new stats. Thus, it'd be nice just rerun an existing execution ARN. Right now we're manually creating new executions and versioning, as you mentioned."
AWS Step Functions	"Re: Retry Execution
Is the re-execution of the failed step supported now with Step Functions?
I am in similar situation where I just need to restart a failed step in my logic.  Currently I use Java Spring Batch,  however since client is moving to AWS, I am exploring the Step Functions to move from Java Spring Batch.  
AWS Batch is not supported in GOV Cloud, so I cannot use it.

Edited by: Kayur on Oct 25, 2018 8:36 AM"
AWS Step Functions	"AWS Step Functions with batch processing limitations
Scenario: A bunch of records (like 10k, maybe more) of small size (average of 50 Bytes each) must be processed. The processing must be done in parallel or any other way to improve performance (remember, we have a lot of records to go through). Also, the processing itself it is a very simple task (that's one of the why's for using AWS Lambda). Although it's simplicity, some processing may end before/after others, so that's another reason why those records are independent of each other and the order of processing does not matter.

So far, Step Functions looks like the way to go.

I can define the RecordsRetrieval as one task. After that, those records will be processed in parallel by the tasks ProcessRecords-Task-1, ProcessRecords-Task-2 and ProcessRecords-Task-3. By the looks of it, all fine and dandy, right? wrong!

First Problem: Dynamic Scaling
If i want to have dynamic scaling of those tasks (let's say... 10, 100, 5k or 10k), taking in consideration the amount of records to be processed, i would have to dynamic build the json to achieve that (not a very elegant solution, but it might work). I am very confident that the number of tasks have a limit, so i cannot rely on that. It would be way better if the scaling heavy-lifting is handled by the infra structure and not by me.

Either way, for a well defined set of parallel tasks like: GetAddress, GetPhoneNumber, GetWhatever... is great! Works like a charm!

Second Problem: Payload Dispatch
After the RecordsRetrieval task, i need that each one of those records to be processed individually. With Step Functions i did not see any way of accomplishing that. Once the RecordsRetrieval task pass along it's payload (in this case those records), all the parallel tasks will be handling the same payload.

Again, just like i said in the first problem, for a well defined set of parallel tasks it will be a perfect fit.

Conclusion
I think that, probably, AWS Step Functions is not the solution for my scenario. This is a summary of my knowledge about it, so feel free to comment if i did miss something.

I am digging with the microservice approach for many reasons (scalability, serverless, simplicity and so forth).

I know that it is possible to retrieve those records and send one by one to another lambda, but again, not a very elegant solution.

I also know that this is a batch job and AWS has the Batch service. What i am trying to do is to keep the microservice approach without depending on AWS Batch/EC2.

What are your thoughts about it? Feel free to comment. Any suggestions will be appreciated."
AWS Step Functions	"Re: AWS Step Functions with batch processing limitations
FFR: Some responses on StackOverflow, but no complete solution, see: https://stackoverflow.com/questions/48724666/aws-step-functions-with-batch-processing-limitations/52937158#52937158"
AWS Step Functions	"Dynamic number of parallel tasks
First off, this is a seriously awesome product, thank you!

One user case that I don't think is quite supported at the moment is being able to fan out to a dynamic number of parallel tasks based upon the output of the previous task.

An example of this is that you want to first, run a task that gets the number of frames in a video, and then run a task for each frame in parallel, and then have another task that does something with the results once all frames have been completed. Problem here is that you don't know how many tasks you need to run in parallel before execution, and the number of tasks differ for each execution.

Is there any plans on supporting this user case? Thanks

Edited by: BillSham on Dec 3, 2016 7:30 AM

Just reading up about aws batch (still awaiting preview access  ), maybe this could help us where by we have a step function that triggers aws batch job, and either that same task can wait for the result, or have another task that pulls the result from aws batch (we could wrap the result fetch job with a liberal try catch)."
AWS Step Functions	"Re: Dynamic number of parallel tasks
Hello and thanks for the compliment!  I'm the Product Manager for AWS Batch and will share this with the team.

As announced in Werners' keynote and Jeff Barr's blog post, we intend to add support for Array Jobs and AWS Batch Jobs that are executed as Lambda functions.  Array jobs allow you to execute many copies of a job against an array of elements or parameters and would be the ideal way to approach the problem that you described.  

For now, we recommend that you use either a Lambda function or an AWS Batch job to perform the first step of scanning the video to determine the number of frames and then submit AWS Batch Jobs for each frame or group of frames - perhaps using a hashing algorithm to determine the frames that should be processed by each job.  You could then submit another job that is dependent upon the completion of all of Jobs performing the second step in your pipeline.

We would also recommend having the first Job write a DynamoDB record for each frame.  As the second stage jobs begin their work, they can quickly check with DynamoDB to determine which of their assigned frames still need to be processed. As they complete each frame, the second stage job would then update the corresponding DynamoDB record.  This mechanism would allow you to take advantage of AWS Batch automated retry capabilities, making this workload an even better fit for EC2 Spot.

Finally, your thoughts regarding the use of Amazon Step Functions is spot on.  Step Functions would be a great way to design the pipeline of commands and branching logic.  You could then use Step Functions to invoke the AWS Batch ""submit-job"" command."
AWS Step Functions	"Re: Dynamic number of parallel tasks
Thanks Jamie for the detailed response! I'll move forward with some of your suggestions and look forward to using AWS Batch!"
AWS Step Functions	"Re: Dynamic number of parallel tasks
Hi - I work on the Step Functions service.  We already have a Parallel state, where the same data gets processed by a bunch of different code branches.  The converse - where an array (or equivalent) of data items all get processed by the same code branch - is an obvious thing to think about; thanks for the suggestion, and you'll be happy to hear you're not alone in wanting this.  I'll make sure the this gets consideration for our roadmap."
AWS Step Functions	"Re: Dynamic number of parallel tasks
It would be nice to define a new state type for dynamic parallel jobs.  Think of it like a map function in python or javascript where map(function, array) will call function for each item in the array.

Suppose a state machine starts with an input value of:
{
  ""somekey"": ""someval"",
  ""jobs"": \[""input1"", ""input2"", ""input3""\]
}


Suppose we define a new MAP state type:

""ProcessList"": {
  ""Type"": ""Map"", 
  ""Iterable"": ""$.jobs
  ""Next"": ""ProcessFunction"",
}


The system should iterate over $.jobs and generate 3 parallel calls to ProcessFunction:  ProcessFunction(input1), ProcessFunction(input2), ProcessFunction(input3).  

The items in the iterable would be passed as parameters to the next task.  Perhaps these could be JSON objects or just value types.

This would be helpful in building out Genome/Exome/RNA processing pipelines, particularly if AWS BATCH was implemented as a Task or State type.

Thanks,

Gary"
AWS Step Functions	"Re: Dynamic number of parallel tasks
@awstb -

We have shimmed this with a Parallel-Each abstraction.  I could post the code of the poller if anyone is interested.  

We use a pass to send the instructions into an activity, and then we poll the activity and add it to a database and create an internalToken.  

We created some internal SendTaskFailure/SendTaskSuccess lambdas which are contract compatible to the step equivalents but operate on the internalToken and contain the ""Promise.all"" style logic of the Parallel Branches, they invoke the actual SendTaskFailure/SendTaskSuccess endpoints with the real taskToken.  Full writeup is attached.  

(This builds on the abstraction we wrote to enable ""Sub Step Tasks"")."
AWS Step Functions	"Re: Dynamic number of parallel tasks
Second that use case for genomic and other scientific computing workloads. I think 'array' jobs in Batch will be a killer feature that enables it out of the box (at least, using just one auxiliary Lambda).

Edited by: denvlad on Jan 3, 2017 11:57 PM"
AWS Step Functions	"Re: Dynamic number of parallel tasks
One user case that I don't think is quite supported at the moment is being able to fan out to a dynamic number of parallel tasks based upon the output of the previous task.

An example of this is that you want to first, run a task that gets the number of frames in a video, and then run a task for each frame in parallel, and then have another task that does something with the results once all frames have been completed.

Interesting.  I'm currently exploring a way to do something like this for coordinating large batch import workflows, where we can only fetch 5000 records at a time, page by page.  Each page of records needs to be fetched/processed/supplemented/delivered, so I'm setting up a step-function workflow to handle these tasks for each page of records, and using a standalone lambda to invoke the workflows in parallel for each page. (We're able to ping the source API to determine how many records need to be retrieved in advance and we can then request each page w/ the appropriate paging parameters in parallel.)

However, I guess the key difference from your use case is that we don't need to re-assemble the pages at some final step.  We do need to aggregate & persist some summary results counts once they've all been delivered, so I'm currently trying to do some creative caching w/ elasticache to persist intermediate results and track the overall state.

If anyone sees issues w/ this approach or has suggestions for a better way to do it, do let me know!"
AWS Step Functions	"Re: Dynamic number of parallel tasks
Hey awstb!

Any luck with parallel actitivities?

I lead a team from Russia and currently we're moving away from SWF (for which we've implemented a sophisticate SDK for Parallel Workflows, activities etc.) to Step Functions and it seems pretty nice (and a 

little bit user-hostile - still much better than SWF).

We definitely need some dynamic parallel activity to apply the same logic for each element of incoming JSON array.

Current solution would be run the same State Machines in AWS Lambda's foreach loop.

But the orchestration features of Step Functions is a huge advantage and we hope some day Parallel Activities would be here."
AWS Step Functions	"Re: Dynamic number of parallel tasks
This would be extremely useful for scientific use cases like HCS image analysis. I have an upcoming project and would like to simplify things a lot with Step + Batch if we had this. 

Fingers crossed it is released soon so I wont have to implement this dynamic number of parallel jobs myself"
AWS Step Functions	"Re: Dynamic number of parallel tasks
an array (or equivalent) of data items all get processed by the same code branch 

+1 this would be very useful

my use case:
. use lambda for processing
. want to process files in as S3 bucket at once in parallel: mostly for the speed (since the cost would be roughly the same sequential/parallel).

It would be nice to have this under the same workflow;  to keep track of errors, progress, etc.

p.s. currently am just starting multiple workflows (one for each file to be processed).

Edited by: neil-z2 on Apr 7, 2017 8:01 PM"
AWS Step Functions	"Re: Dynamic number of parallel tasks
I have a similar use case, we are processing large xml files and inserting records into a database. I created an ""iterator"" concept which creates a kinesis stream, streams all of the elements into the stream then iterates over the stream in small batches until the entires stream has been read. I could go into more details if anyone is interested...

But frankly this should just be a native construct in step functions. In my opinion it should essentially be a step function api where you would stream records into it something like this:

let inputStream = s3.getRecord(params).createReadStream()
let sf = new StepFunctions()
let params = {
  Output: 'item-stream'
}
let outputStream = sf.createOutputStream(params)
inputStream
  .pipe(xml(config))
  .pipe(outputStream) // uploads elements into an output stream, aka ephemerial kinesis stream


Then in the step function there should be a node type which knows how to iterate over the stream in configurable batch sizes and call a worker lambda for each batch, in parallel, and aggregate results:

IterateItemStream:
  Type: Iterator
  InputStream: item-stream
  BatchSize: 10 # ten items from the stream per call to the lambda
  Parallel: true # it can launch multiple workers to process items in parallel
  Worker: # This is similar to Branches for parallel steps
    - ProcessXmlItem:
        Type: Task
        Resource: itemProcessor
        End: True
  Reducer: # a series of steps called with the output of two or more Workers
    - ReduceResults:
        Type: Task
        Resource: results
        End: True
  Next: Done
Done:
   Type: Pass
   End: True


The Worker steps would be called with the batched items from the output stream, the Reducer would be called with the results of two worker lambdas, reducing them to the reducers output, in the form of a standard reduce algorithm.

The final output of the Iterator step would be the final reduced result of all invocations of worker.

Behind the scenes the step function API would create a kinesis stream for us and manage its reference by the name provided in the call to `createOutputStream(params)`. And most importantly, it would also manage the tear down of the stream at the end of the step function. Meaning regardless of the reason why the step function exited, be it error, timeout or success, the ephemeral output streams would be destroyed at the end of the step function.

Edited by: justinmchase on Apr 24, 2017 10:05 AM

Edited by: justinmchase on Apr 24, 2017 10:09 AM"
AWS Step Functions	"Re: Dynamic number of parallel tasks
+1, completely agree this would be a great feature for step functions.
Is there anywhere we can monitor to see it on a roadmap?"
AWS Step Functions	"Re: Dynamic number of parallel tasks
I agree an parallel array function would be ideal.  One workaround I've tried is to use a Parallel step composed of N Choice steps.  Each choice step is passed a 'jobCount' variable which can be used to either 'do work' or 'bypass work' via the choice.  The result is a dynamic number of parallel tasks.   The downside is you have to define N jobs upfront based on your max N.   Depending on your max N, this might work for many applications."
AWS Step Functions	"Re: Dynamic number of parallel tasks
+1 awesome product 
+1 For this feature"
AWS Step Functions	"Re: Dynamic number of parallel tasks
Late to the party here, but I'd be interested to see the poller code you referred to in your post, if you're still offering!
Thanks, 
Conrad."
AWS Step Functions	"Re: Dynamic number of parallel tasks
Any update on the Array jobs feature/product?"
AWS Step Functions	"Re: Dynamic number of parallel tasks
Latest updates on this please? This feature will be really useful for multiple usecases in our company.

It would be useful to know the Roadmap of when this is going be released."
AWS Step Functions	"Re: Dynamic number of parallel tasks
Any update on array jobs?"
AWS Step Functions	"Re: Dynamic number of parallel tasks
+1 for Array jobs in Step Functions.

-bp"
AWS Step Functions	"Re: Dynamic number of parallel tasks
+1... I'd also be interested in this being added to Step Functions"
AWS Step Functions	"Re: Dynamic number of parallel tasks
+1 this would be useful for use-cases we have with financial calculations too.  For example, we have use-cases to run calculations on portfolios of financial instruments, where initial steps could break this down into independent calculations to run in parallel, then subsequent steps to combine the results, etc."
AWS Step Functions	"Re: Dynamic number of parallel tasks
Was hoping Step Functions had this feature already. Would be a great addition!"
AWS Step Functions	"Re: Dynamic number of parallel tasks
+1 ... any updates?"
AWS Step Functions	"Re: Dynamic number of parallel tasks
Adding our +1 for support of dynamic parallel tasks in Step Functions -- this would be very useful for several of our use cases. Any updates on support or on best practices in the meantime? Thanks and amazing job with these products!"
AWS Step Functions	"AWS Step Functions Availability in Beijing
Hi,  

When will the Step Functions available in Beijing Region?
And, is there any alternate service to Step functions?

Our use case scenario involves calling a sequence of Lambda functions using Step functions.
We need an alternate solution since we don't have Step functions in Beijing region.

Thanks in advance!"
AWS Step Functions	"Use step functions to have 2 lambdas triggered from the same bucket event
I have an s3 bucket and I’m setting up a lambda function to be triggered when a new object is uploaded. (it works fine). Then I want to create a separate lambda function on the same bucket, that gets triggered when an object is uploaded as well. When I try to set up the last one, it complains because of Configurations overlap. Configurations on the same bucket cannot share a common event type.

Is this a good usecase to use step functions? Will step functions help me get around that?"
AWS Step Functions	"Re: Use step functions to have 2 lambdas triggered from the same bucket event
Have you use parallel step ?"
AWS Step Functions	"Re: Use step functions to have 2 lambdas triggered from the same bucket event
I used SNS. I have a topic that fans out a message to all the different lambda subscribers. 

Now the problem I'm trying to solve is that, I want to know when all those different lambda functions have finished. I'm not sure how to do that with SNS itself, but i'm thinking using stepfunctions would allow me to do that?"
AWS Step Functions	"Re: Use step functions to have 2 lambdas triggered from the same bucket event
I'm not sure all your requirements but you can invoke lambdas from other lambdas. 

Have 1 lambda as event source for S3 events and it could invoke the two lambdas. You could wait for the result of each invoked lambda."
AWS Step Functions	"Global error handling
Hello, 

I have some questions regarding error handling. As I have read there is no catch state at main level on the step function, so , Is it a good design in terms of performance to have a parallel task to catch any error that happens inside my step function and in that case I can centralize the error handling in just one lambda/state?"
AWS Step Functions	"What would state change if AWS server shut down or crashed?
I had an execution, and the state of execution was in a wait state. And it would jump to next step after waiting for 2 hours. What would state change if AWS server crashed or shut down when I was waiting for 2 hours ? Did it execute next step on time if the AWS server was repaired in 2 hours ? Or it needed to wait longer than 2 hours ?"
AWS Step Functions	"Please add functionality to delete execution and reuse execution name
Execution that already finish executed is sometimes unnecessary to keep in the list. We may export all of it as a log into database and so all those old state is hamper with the UI when we want to keep track of the still running executions 

And sometimes we want to specify the name of execution with ID of data so we can pair the execution with the data to check its executing state. When it failed and we need to restart, there are no way to restart it or create new execution with the same ID

So I think aws should have a function to delete the ended execution"
AWS Step Functions	"Re: Please add functionality to delete execution and reuse execution name
Execution names are idempotent for 90 days following the close of the execution. After that you can reuse the names. Please see http://docs.aws.amazon.com/step-functions/latest/apireference/API_StartExecution.html for more detail.

Would adding a filter to the UI, so that you list only open executions help?"
AWS Step Functions	"Re: Please add functionality to delete execution and reuse execution name
Not help at all

There are so many use case that would be better if it can delete at will. It far more easier to just delete unnecessary and filter only recently fail for example. I might query for the failed with cron, handle it and delete it. So I could decide to reset the fail execution. But the lack of ability to delete make a whole mess of useless executed list

I already know about 90 days but it not enough. And actually is a drawback that we have no control of the list that we would like to manage. We should be able to manage it ourselves what necessary and whatnot"
AWS Step Functions	"Re: Please add functionality to delete execution and reuse execution name
@AndyKaAWS How is this feature progress? Actually are there any feature progressed for step function at all?"
AWS Step Functions	"Re: Please add functionality to delete execution and reuse execution name
Bumping"
AWS Step Functions	"Making another execution as Task
In additional to activity and lambda. I think step function should be able to invoke new execution in any state machine and just wait till that sub-execution end

So we could write many step function module and orchestrate it easily instead of copying it"
AWS Step Functions	"Re: Making another execution as Task
+1"
AWS Step Functions	"Re: Making another execution as Task
dig up"
AWS Step Functions	"Re: Making another execution as Task
bumping"
AWS Step Functions	"Push feature to be notified of Step Functions executions state changes?
Could there be a feature that would allow to know when an execution changes its state? I am interested in knowing about when a non-running state is achieved. Regular API polling is one way but it seems wasteful and not useful for long running workflows.

CloudWatch events for SFN support calls via Cloudtrail ( https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/Create-CloudWatch-Events-CloudTrail-Rule.html )  but SFN doesn't log Execution status changes to Cloudtrail ( https://docs.aws.amazon.com/step-functions/latest/dg/procedure-cloud-trail.html ). 

These threads are related:
https://forums.aws.amazon.com/thread.jspa?messageID=848996
https://forums.aws.amazon.com/thread.jspa?messageID=827276"
AWS Step Functions	"Will AWS Console show failed and running executions before succeeded ones?
Hi!

We've read up on the Limits concerning Step Functions, and have a question regarding the limit on ""Maximum executions displayed in Step Functions console"", which is 1000.

What if we start many (e.g. 400.000) executions of which say 10 fail. Will we see those 10 executions? Or is that chance / is the application of the 1000 executions visiblity limit ""random"" with regard to execution status?

We know we can use the API and CLI to view all activities but in practice we only want to look at and inspect failures and it is convenient to use the Step Functions console for that. Saves us writing custom code to interact with the API/CLI (and we like the console).

Thanks
Otto"
AWS Step Functions	"Re: Will AWS Console show failed and running executions before succeeded ones?
We started playing around with this and found that the 1000 rows limit is only applied on the state machine front page, where you see the total number of succeed, running, failed, ..., per state machine.

If we navigate to the executions of a state machine, we are able to see all executions we started in our test (more than 40,000 so far). Also filtering on state works fine.

And of the executions we are able to see all history details (like output and errors).

So it seems all our requirements are met, but the documentation on AWS Step Functions Limits can certainly be made more clear ...

Edited by: pi-team on Aug 16, 2018 5:15 AM"
AWS Step Functions	"Guflow now fully supports scheduling of AWS Lambda functions
I have released the next version of Guflow and it now fully supports the scheduling of AWS lambda functions. You will find Guflow, built up on Amazon SWF, to be an alternative to Amazon Step Functions and the FlowFramework. It is hosted on github- https://github.com/gurmitteotia/guflow.

Here is a simple Iterator example to compare:
 1. Amazon Step Functions took approax 41 lines to implement. https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-create-iterate-pattern-section.html
 2. Guflow took 5 lines to implement. https://github.com/gurmitteotia/guflow-samples/blob/master/StepFunctions/Iterator/ProcessLogWorkflow.cs

I'm looking forward to adding more real life examples. Please feel free to provide links to any real life examples you would like to see implemented. 

Guflow brings both simplicity and flexibility in one place. Some of the highlights are:
 - Guflow lets you make use of all SWF features*.
 - Allows to schedule Lambdas, Activities and Timers seamlessly.
 - Allows parallel branches in the workflow.

 *Support for child workflows coming next.

Guflow is supported by documentation, tutorials and examples.
Any feedback from the community will help greatly in improving this library."
AWS Step Functions	"StepFunctions with Apigateway: apostrophe results in HTTP Error 400
Hello,

i use StepFunctions with an HTTP ApiGateway Endpoint and figure out that an apostrophe always results in a 
{""__type"":""com.amazon.coral.service#SerializationException""}

an example:

curl -D - -XPOST -H ""Content-Type: application/json; charset=utf-8"" https://apigateway -d ""{\""name\"":\""Palatto d'Inv\""}""


My API Gateway Mapping Template is default:
#set( $body = $util.escapeJavaScript($input.json('$')) ) 
 
{""input"": ""$body"",""name"": ""$context.requestId"",""stateMachineArn"":""stepFunction""}

I hope someone has an idea.

Thanks

Edited by: belayus on Aug 5, 2018 12:43 PM"
AWS Step Functions	"Re: StepFunctions with Apigateway: apostrophe results in HTTP Error 400
It looks like a serverless framework issue: https://github.com/serverless/serverless/pull/2993/files

Edited by: belayus on Aug 5, 2018 1:19 PM"
AWS Step Functions	"Filter input with InputPath not working as expected
I have a state machine that looks like this:
{
  ""StartAt"": ""Task1"",
  ""States"": 
    {
      ""Task1"": {
        ""Type"": ""Task"",
        ""Resource"": ""arn:someActivity1"",
        ""ResultPath"": ""$.output"",
        ""Next"": ""Test2""
      }, 
      ""Task2"": {
        ""Type"": ""Task"",
        ""Resource"": ""arn:someActivity2"",
        ""InputPath"": ""$.input"",
        ""End"": true
      }
  }
}

My input Json on execution start looks like this
{
    ""input"": ""InputExample""
}

Right now my output from Task1 and the input for Task2 both look like this
{
  ""input"": ""InputExample"",
  ""output"": {
    ""Result"": ""Success""
  }
}

But I want the input for Task2 to look like the input from Task1.
So basically to take only ""input"" field and pass it as input to Task2.

When I check the documentation for filtering the input, I don't see any difference from what I am doing.
https://docs.aws.amazon.com/step-functions/latest/dg/input-output-paths.html
What do I need to do to remove the output portion of Task1 from the input of Task2?"
AWS Step Functions	"Can we pass state build its result with a value from it's input?
Can we pass state build its result with a value from it's input? for eg.
{
""input"": ""mydata""
}

""passstate"":{ ""Type"": ""Pass"",
""Result"": ""$.input""
""ResultPath"": ""$.mynewdata""
""Next"": ""nextstate""}

In this the result comes back as ""$.input"" and not ""mydata"".

Thanks"
AWS Step Functions	"Re: Can we pass state build its result with a value from it's input?
No.
THe Result data is literal, not evaluated. You can specify where it gets placed but not change its contents.

Yes.  I was mistaken, it is not at all obvious.
If you omit the Result value then the input 'passes through' as if it were a task and the ResultPath can be used to change it and merge it back in.
""Step"" : {
  ""Type"" : ""Pass"" , 
   ""InputPath"" : ""$.someInput.value"" ,
   ""ResultPath"" : ""$.newplace""
  }
 
 
Given 
{  ""someinput"" : { ""value"" : ""somevalue"" } } 
Produces
{   ""someinput"" : { ""value"" : ""somevalue"" } , ""newplace"" : ""somevalue"" } 

Adding a ""OutputPath"" will affect as well.

Edited by: DLEEDAL on Jul 21, 2018 11:59 PM

Corrected mistake.  
Edited by: DLEEDAL on Jul 22, 2018 12:02 AM"
AWS Step Functions	"JsonPath evaluation problems/questions - What implementation of JsonPath?
Im having a hard time figuring out the exact capabilities/features/limits/bugs of the JsonPath implementation for InputPath,OutputPath and ResultPath.  The docs reference a standard JsonPath web page  exceptions indicate a different implementation and trial & error conforms to neither.
```
Example:
Input:    { ""files"" : , ""request"": { ""auth"" : ""password"" } }

JsonPath:   $[files,'request' ]

AWS: { ""request"" : ... }
Others tested accept unquoted 'files' and produce full results

JsonPath:  ""$['files','files']""
AWS: 1 copy of files
Others: 2 copies of 'files'
```
Many more difference such as what expression language is used.
Is there any chance of being able to see the code for JsonPath usage so I/we can reverse engineer the missing docs ?
Right now its a painful trial and error process -- taken me several days so far to just get this much information.  (almost as hard as trying to reverse engineer the POST text box to figure out what the escape syntax is so it doesn't nuke the text - I thought 'plain text' meant 'plain text' )

Edited by: DLEEDAL on Jul 21, 2018 12:17 PM"
AWS Step Functions	"Step Function Resource as String Variable
Hello!

I'm looking to create a flexible state machine that can process jobs in parallel given json that contains the lambdas necessary to do work, as well as the data those lambda will process. The problem I'm running into is I can't pass the resource arn is as a string. Is this intended? If so, is there any way I can dynamically choose a lambda I wish to use in a step function?


Here is the code for reference:

""ConfigureEnvironment"": {
      ""Type"": ""Task"",
      ""Resource"": ""arn:aws:lambda:us-east-1:1234567890:function:FlexChunkerConfig_test"",
      ""ResultPath"": ""$.configure"",
      ""Next"": ""ConfigureJob""
    },
    ""ConfigureJob"": {
      ""Type"": ""Task"",
      ""Resource"": ""$.configure.configLambda"",
      ""ResultPath"": ""$.job"",
      ""Next"": ""Done""
    }


Here is the JSON for configure when it gets passed to ""ConfigureJob"":

""configure"": {
    ""configLambda"": ""arn:aws:lambda:us-east-1:1234567890:function:WorkerSNSLambda_test"",
    ""workPackage"": {
      ""DummyData"": ""Garland"",
      ""DummyData2"": ""Pirate""
    }
  }


Finally, here is the error I receive when I try to run the Step Function:

{
  ""error"": ""States.Runtime"",
  ""cause"": ""An error occurred while scheduling the state 'ConfigureJob'. The provided ARN '$.configure.configLambda' is invalid.""
}"
AWS Step Functions	"Re: Step Function Resource as String Variable
I wanted to post an update I received from Amazon for any one else that may be looking for this information.

Per the Amazon contact for the company I work for: ""... the Resource Type is static currently, meaning it does not get pass the JSON path so it will have to be the actual ARN.""

I'm going to leave this question as unanswered in case any one else finds a work around, but for now this seems like something that is not possible."
AWS Step Functions	"Re: Step Function Resource as String Variable
The workaround is to pass this JSON data to your own 'generic' lambda function which in turn invokes a lambda."
AWS Step Functions	"What is the maximum number of step function executions?
I am thinking of using step functions to make API calls at pre specified times. E.g.Create a step function now that will execute after 2 hours and 30 minutes. This step function will use the wait state template to sleep for 2 hours and 30 minutes and then make the API call and then end. 

Due to the number of users, I am estimating at a given time there can be upto a million such executions in progress.

Can this run into any kind of issues with limits, performance or cost?

I am assuming that when the step function is stuck in wait state it is not going to be consuming any resources.

Thanks,
Gary

Edited by: garyg on Jul 12, 2018 11:18 AM"
AWS Step Functions	"add execution start time filter option to ""list executions api""
I expect to be able to specify the period of execution start time as a filter condition of ""list execution"" api."
AWS Step Functions	"How long to expect for deletion? Is action required?
How long should one expect a state machine to be in ""status"": ""DELETING"" ?

I've tried deleting one 5 hours ago, and it's still listed as ""status"": ""DELETING"".  I'm wondering if that's normal?  What is the expected range of time deletion should take?

The docs say ""After all executions have completed or been deleted, the state machine itself will be deleted."" (http://docs.aws.amazon.com/step-functions/latest/apireference/API_DeleteStateMachine.html)

The machine in question has no running executions, just multiple failed executions.  The last ""stopDate"" was 6 hours ago (1480986774.833).

Is there some other action I need to take after deleting the state machine to force it to delete?

thanks!"
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Same issue here.  3 State Machines have been ""DELETING"" overnight but haven't actually deleted.

This will make iterative development a complete pain:

1) You can't update the state machine code so you have to delete it and create again.
2) It doesn't actually delete (at least not quickly) so you have to give your updated state machine a new name.

This means deploying even minor changes will be a headache.

They really need versions and aliases like Lambda functions."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Having same problem. I delete step function and it disappears from UI, but when I reload page, it is still there. I also tried to delete from sdk and command goes through with no error, but function doesn't actually get deleted."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Mine have finally gone - seems to be 24 hours.

Can't see how I can do any serious development work with this if every minor change needs a new state machine.

Is there any way of running step functions in a development environment like you can run Lambda functions in any nodejs environment?"
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
It should not take 24 hours to delete a state machine, we have resolved the issue in the system causing the delays. Please let us know if you the time to delete continues to be high."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
I still have the issue, any of my state machines can't be deleted."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
I'm also still seeing state machines fail to delete after extended (1 hr+) and multiple attempts. Coupled with the inability to edit state machines once created, this is a pretty massive inconvenience."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Some state machines are still persisting after a delete state machine call. We've applied a fix that resolved some cases, but not all. We are investigating and will post an update when we know more."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Perhaps this is related: I was able to delete a machine, and after a few minutes it was gone from the console. I created the machine again with the same name.

Now I have really inconsistent results on the machine: refreshing the console either shows no executions or some. Running `describe-execution` from the CLI returns `Execution does not exist` in most cases, but sometimes (once in 4-5 tries) returns the result -- and then doesn't again. It's a phantom.

Maybe my state machine wasn't fully deleted when I recreated it and created executions?

This is us-west-2."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
We found and resolved a bug preventing some customers from deleting state machines. State machine deletion now functions as expected. Please let us know if you encounter this issue again. Thank you for your patience!"
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
I still can't delete my state machines.
All status columns are set to 'throttling'... what does this mean?
I couldn't even run the 'hello world' state machine from the getting started:
http://docs.aws.amazon.com/step-functions/latest/dg/hello.html
When pressing the ""New Execution"" nothing happens... and the Dashboard page include another throttled state machine..

See attached image."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
I am having this same problem with my state machines in eu-west-1. All delete operations are stuck in ""Deleting"" and nothing seems to be happening. Some have finished executions and some are empty. I used the https://github.com/horike37/serverless-step-functions plugin to deploy the state machines."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Now all my state machine deletions have completed, more or less simultaneously. It seems to have taken maybe an hour. A bit much for development, if you have to every time delete the previous state machine in order to update it.

I am now able to delete state machines with almost no delay. The problem seems to have disappeared for now.

Edited by: kennu on Dec 31, 2016 3:36 AM"
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
Encountering the same issue on us-east-1, deletions taking about an hour. 

There seems to be an eventual consistency issue going on, as refreshing the Step Functions dashboard displays an inconsistent state between loads. 

At times it shows some of the deleted state machines as if they are still in existence, another refresh and they appear in ""deleting"" mode again."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
There are specific types of State Machines definitions that cause processing errors that prevent the execution from completing. Since State Machines cannot be deleted until all executions complete, the are not deletable. We are aware of the issues and are working on addressing them after which you will be be able to complete the state machine deletion."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
This continues to be an issue here as well. Normally it would take ~5-10 sec to delete, but occasionally a new machine with the same definition would take much longer."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
I'm finding deletion very hit or miss. Sometimes it takes effect immediately in both the backend and visually in the console. Sometimes it takes effect visually but I cannot re-create a state machine of the same name for hours (or maybe ever?). Sometimes it just sits in the console visually as ""trying to delete"" and stays that way without feedback on why.

To my knowledge, in all these cases there are no outstanding executions for the machine trying to be deleted."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
+1 i'm experiencing this as well still. Executions are all listed as succeeded but machine has been stuck in deleting for several days."
AWS Step Functions	"Re: How long to expect for deletion? Is action required?
I am getting the same error. 
It's been 1 hour but the stack was usually deleted in a minute or two.

Best"
AWS Step Functions	"[feature-request?] - Can we have a link to the Lambda specific log files?
Dear AWS-ers,

I am currently debugging some Step Function series for which a specific Lambda invocation has crashed. Underneath each Step Function run there are interesting specs, like runtime, input/output and the time of Lambda execution. In addition, a link to the CloudWatch is provided.

However, this link is generic a brings us to the overall Lambda function cloudwatch. I could then use the time of execution to zoom in but I sometimes have many simultaneous invocations which makes it a tedious task of clicking each cloudwatch entry to finally find my relevant log.

Isn't it possible to provide run specific lambda log files so that we end up in the concerned cloudwatch log directly?"
AWS Step Functions	"When will we be able to trigger a Step Function from an S3 event directly?
Right now, it's sorta hacky.  You have to either first trigger a Lambda to then start a Step Function, or use CloudTrail and CloudWatch on the S3 event to trigger a Step Function.

It would be so much nicer to be able to just specify a Step Function to trigger directly from an S3 event.  

Any word on when this might be available?"
