{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to scrape each forumID for threads and store it into a TSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising some global variables first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = []               # contains all the thread IDs \n",
    "messages = []          # stores all the message contents\n",
    "subjects = []          # stores the subjects of the messages \n",
    "forumIDs = []          # stores the forumIDs from the scraped csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load the scraped CSV file containing the forum IDs and store it into forumIDs array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the scraped csv file, get the details of the various products and store it into forumIDs\n",
    "\n",
    "def loadcsv():\n",
    "    with open('ForumID.csv', 'r') as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        for row in reader:\n",
    "            forumIDs.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to scrape all the thread IDs present within the forumID, store it into the variable tid\n",
    "#### Input: the forum URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    }\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    soup.prettify()\n",
    "\n",
    "    # all threadIDs have the following id\n",
    "    \n",
    "    hrefs = soup.find_all(\"a\", {\"id\": \"jive-thread-0\"})\n",
    "\n",
    "    for href in hrefs:\n",
    "        href = str(href)\n",
    "        href = href.split('href=\"')[1].split(\"&\")[0]\n",
    "        \n",
    "        # href of form threads.jspa?threadID=xxx\n",
    "        tid.append(href)\n",
    "    return tid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch all the messages inside each thread and store it into the final TSV file with tag as the name of the product\n",
    "\n",
    "#### Input: The thread URL and the target file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url, fname):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    }\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    soup.prettify()\n",
    "    \n",
    "    # all messages have the following subject class\n",
    "    \n",
    "    subs = soup.find_all(\"span\", {\"class\": \"jive-subject\"})\n",
    "    \n",
    "    for line in subs:\n",
    "        subjects.append(line.text.strip())\n",
    "    \n",
    "    # all messages have the following body class\n",
    "    \n",
    "    msgs = soup.find_all(\"div\", {\"class\": \"jive-message-body\"})\n",
    "    \n",
    "    for line in msgs:\n",
    "        msg = line.text.strip()\n",
    "        messages.append(msg)\n",
    "        \n",
    "        with open(fname + '.tsv', 'w', encoding='utf-8') as tsvfile:\n",
    "            writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "            writer.writerow([\"label\", \"description\"])\n",
    "            for i, j in zip(subjects, messages):\n",
    "                writer.writerow([fname, i + \"\\n\" + j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following is the code to execute the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the follow function if the scraping should be automatic\n",
    "\n",
    "loadcsv()\n",
    "\n",
    "# value of ID is the target forumID cell in the csv\n",
    "# value of limit is number of threads you want to extract from each service\n",
    "\n",
    "id = 73\n",
    "limit = 14\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i <= limit:\n",
    "    url = \"https://forums.aws.amazon.com/forum.jspa?\"+forumIDs[id-1][1]+\"&start=\"+str(i)\n",
    "    tid = connect(url)\n",
    "    i = i + 25\n",
    "    \n",
    "for thread in tid:\n",
    "    fetch(\"https://forums.aws.amazon.com/\" + thread, forumIDs[id-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
