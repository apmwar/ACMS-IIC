label	description
Amazon Neptune	"Connect to Neptune SPARQL Endpoint from local machine
Hello,

Is it possible to connect to the Neptune SPARQL endpoint straight from a local machine? Currently, I can only send SPARQL queries to my endpoint from my EC2 via SSH, which is not really convenient as I would like to automatize SPARQL querying from an external service (not in AWS).

Thanks,

MT"
Amazon Neptune	"Re: Connect to Neptune SPARQL Endpoint from local machine
Hi MT,

The reference architectures has some options for connecting from outside of the VPC:  https://github.com/aws-samples/aws-dbs-refarch-graph/tree/master/src/connecting-using-a-load-balancer. These approaches use a reverse proxy or API Gateway to connect to your Neptune instance from within the VPC.

For client access, you can also look at VPC peering or VPC VPN client options.

Thanks, --Brad

Edited by: bradbataws on Jan 24, 2019 8:22 AM"
Amazon Neptune	"Re: Connect to Neptune SPARQL Endpoint from local machine
bradbataws wrote:
The reference architectures has some options for connecting from outside of the VPC:  https://github.com/aws-samples/aws-dbs-refarch-graph/tree/master/src/connecting-using-a-load-balancer. These approaches use a reverse proxy or API Gateway to connect to your Neptune instance from within the VPC.

Still quite impractical for development/casual use cases… Anything quicker to set up using a single instance? Maybe using Internet/VPC gateways?"
Amazon Neptune	"Re: Connect to Neptune SPARQL Endpoint from local machine
If you have an EC2 host within your VPC, one approach that I use is to configure ssh port forwarding for local machine access.

Edited by: bradbataws on Feb 27, 2019 4:00 AM"
Amazon Neptune	"Tagging AWS  Neptune Snapshot through UI
I have a lambda which captures a snapshot of the current status of our Neptune cluster and it tags the snapshot. I went through the ui to see if the tags were there and correct, but the tags section of the snapshot page was stuck loading. I tried to add a tag via UI and it responded with the following 
Unable to find a snapshot matching the resource name: arn:aws:rds:us-east-1:$accountnumber$:snapshot:snapshot-20190205 (Service: AmazonRDS; Status Code: 400; Error Code: InvalidParameterValue; Request ID: $request-id-uuid$)


When I use the cli to inspect the tags, they are all present. 
aws neptune list-tags-for-resource --resource-name arn:aws:rds:us-east-1:$accountnumber$:cluster-snapshot:snapshot-20190205


Is this an account specific bug or are there plans to fix this?"
Amazon Neptune	"Re: Tagging AWS  Neptune Snapshot through UI
This seems to have been fixed."
Amazon Neptune	"Neptune Gremlin CSV, Load and Vertex Property Cardinality
I am currently loading Gremlin CSV data into Neptune and on query I am running into an issue where multiple vertex properties are returned when I expect only one. Does the CSV header not inform the loader what the property cardinality should be?

Here is data that is has the same structure as what I am loading:

~id,~label,personName:String,height:Int
person-406005,person,John,70

If we load another CSV such as

~id,~label,personName:String,height:Int
person-406005,person,John,69

Then I find that the person-406005 vertex ends up having two properties for height and personName.

As a backup I could set the fields with gremlin but would prefer to use the S3 -> neptune loader path. Any advice on how I can specify the correct property cardinality would be appreciated. 

Thanks,

Martin"
Amazon Neptune	"Re: Neptune Gremlin CSV, Load and Vertex Property Cardinality
Hi Martin,
We currently do not support bulk-loading with single-cardinality for Vertex properties in Neptune. 

Thanks,
Yigit"
Amazon Neptune	"Re: Neptune Gremlin CSV, Load and Vertex Property Cardinality
Is there any plan to implement this or does there have to be essentially an application to clean up the properties to single cardinality?"
Amazon Neptune	"Re: Neptune Gremlin CSV, Load and Vertex Property Cardinality
We are looking at this as a future feature, but don't yet have firm plans. Currently, you can load or create single cardinality properties using the Gremlin interface directly rather than the bulk loader."
Amazon Neptune	"Re: Neptune Gremlin CSV, Load and Vertex Property Cardinality
If you need to load large amounts of data transactionally in order to meet your property cardinality constraints, you may want to look at using the reference architecture that we've developed that leverages Kinesis and Lambda to write data to Neptune.  This will still give you high throughput, and will allow you to load the data using Gremlin transactionally.

https://github.com/aws-samples/aws-dbs-refarch-graph/tree/master/src/writing-from-amazon-kinesis-data-streams"
Amazon Neptune	"Defining unique constraint on schema for AWS Neptune.
We are doing a POC on Neptune. In our use case we will be receiving data through stream which can duplicate vertices and edges. In graph we need to maintain the data sanity and have only one vertex against the unique id that we have.

Approaches tried: 

1. Through Gremlin API using fold() and coalesce() methods, but there was significant performance hit and it taking more than 5 sec to persist single vertex.
The CPU usage was high too (found a issue logged against it in neptune: https://forums.aws.amazon.com/thread.jspa?threadID=294780&tstart=0 ) 
g.V().has(GraphConstants.METRIC_VERTEX_LABEL, GraphConstants.DOC_FIELD_QNAME,
                ""1.1.1.1"").
                fold().coalesce(unfold(), addV(GraphConstants.METRIC_VERTEX_LABEL)
                .property(GraphConstants.DOC_FIELD_QNAME, ""1.1.1.1""))
                .next();


2. Through define ""id"" property in addV() method, though this didn't resulted in unique vertices and there were duplicate nodes against the same id.
 g.addV(GraphConstants.MOB_VERTEX_LABEL)
            .property(""id"",
                ""1.1.1.1"")).next();


Please let us know if there is a way we can achieve uniqueness with Neptune either by defining a constraint or unique index on a property of a vertex/edge."
Amazon Neptune	"Re: Defining unique constraint on schema for AWS Neptune.
Is it possible for you to define the id of the vertex as your unique value? If so, it should be more performant, rather than scanning for a certain value in the properties. 

Also, I do not believe you can set an index or constraint yourself.

g.V(""1.1.1.1"")
  .fold()
  .coalesce(
    unfold(),
    addV(GraphConstants.METRIC_VERTEX_LABEL).property(T.id,""1.1.1.1""))
  .next()"
Amazon Neptune	"Re: Defining unique constraint on schema for AWS Neptune.
What version of Neptune are you running? We have made significant improvements to the .fold().coalesce(unfold(), <mutate>()) pattern recently and this query should not be taking 5 seconds to run."
Amazon Neptune	"Query orderBy performance degrading over time
Problem
We have a query that contains an oderBy clause, which orders a set of vertices / edges that accumulates over time. We use gremlin to access Neptune.

We accumulate about 2000 nodes of the particular type in the graph over a week and the query seems to accumulate about 200ms on average. I suspect the performance impact that we see is due to the nature of the index that Neptune is created. ie: It might not be a sorted index on the filed that we use for orderBy.

Questions
1. What would be the cause for the degrading performance?
2. Is there a way to

sample query (in gremlin-scala):

Query
 graph.V(vertex.id)
          .hasLabel(Parent)
          .in()
          .hasLabel(Child)
          .has(End)
          .order(By(End, Order.decr))
          .take(5)


Stats:
Engine: Neptune 1.0.1.0
total vertices:  ~12000
vertex of type Parent: 7
vertex of type Child: ~12000
vertices selected in (Parent) --> (Child) : ~12000/7  = ~1700
Query time at 95th percentile: 250ms

Tried running a gremlin profile query but all I see is:
Step                             Count  Traversers       Time (ms)    % Dur
============================================================================
NeptuneGraphQueryStep(Edge)         5           5       237.165   100.00
          TOTAL                     -           -       237.165        -


Edited by: paul-vital on Jan 20, 2019 1:47 PM"
Amazon Neptune	"Re: Query orderBy performance degrading over time
Hi Paul,

Thank you for reaching out to the Amazon Neptune team.

In general, orderBy queries will take longer the more items there are to sort. 

That being said, could you open a support ticket via AWS console so we can provide support over a secure communications channel? This is a public forum and we'd advise against posting potentially sensitive info such as your instance ID, s3 bucket name, arns, etc.

We'd be happy to further investigate this case with you. Thanks!

-Rahul"
Amazon Neptune	"Re: Query orderBy performance degrading over time
Thanks Rahul, created a support ticket from console."
Amazon Neptune	"Mix-up between Neptune APIs to RDS APIs
Hi
I had been posting this with all possible forums and no one can answer this. maybe here I'll get clear answer.

How come calling RDS describeDBClusters returns Neptune DBClusters?
The same goes for all RDS/Neptune types (e.g. Neptune DBInstance and RDS DBInstance)

Is this expected? 
Can I use RDS apis to discover all Neptune assets? 
and if so, why having Neptune API at all!"
Amazon Neptune	"Re: Mix-up between Neptune APIs to RDS APIs
Hi,

Please see the  https://aws.amazon.com/neptune/faqs/ Amazon Neptune FAQ on ""Why are Amazon RDS permissions and resources required to use Amazon Neptune?"". The Amazon Neptune APIs are the officially supported ones.

Thanks, --Brad"
Amazon Neptune	"Re: Mix-up between Neptune APIs to RDS APIs
Hi
I'm sorry but this still not clearing the confusion why RDS API returns the same as Neptune APIs
I want to have one code that discover (describe) RDS & Neptune at the same time. And now I get things twice
What I'm trying to figure out, can I just use the RDS API to get both RDS & Neptune assets, and assume this will remain the situation at the future?"
Amazon Neptune	"Re: Mix-up between Neptune APIs to RDS APIs
The ""why"" is that because of sharing infrastructure the instance information is kept in a common database. Both APIs read from that database and, at least at present, they don't filter out instances of the wrong type. I don't know why they currently don't filter, but suspect that there were internal things that would have broken and they just haven't had time to clean all those up yet. I expect that in the future they will do the filtering (or other internal changes will have the same effect), with the RDS API only returning RDS instances and the Neptune API only returning Neptune instances."
Amazon Neptune	"On-demand (serverless) Neptune or smaller instance for development?
Hi, do you have plans for Neptune to be provided as serverless, or with a smaller instance?
GraphDB is our hot topic but the current instance size is too pricey for development purpose, as a result, we're setting up the near identical stack with EC2 + EBS.

It would be great if we could start developing with micro/nano instance, and it's awesome if you provide as serverless with the pay-per-request pricing model."
Amazon Neptune	"Re: On-demand (serverless) Neptune or smaller instance for development?
Do you mind providing us with some info on the size of graph that you're looking to use and the number of transactions/second?  It would be good for us to understand the use-case/pattern to see what type of resources may be needed to run this type of workload.

Also, if you're workload is periodic in nature, you can take advantage of the fact that Neptune clusters have decoupled compute and storage.  Via the Neptune API, you can create a cluster with zero compute instances (only storage) and add/remove instances to the cluster when you need to process queries/traversals."
Amazon Neptune	"Gremlin coalesce resulting 100% cpu usage
Hi,

Recently, we monitored that the query that's using coalesce (example below written in python-grem lin) cause AWS Neptune to consume 100% CPU. 

g.V().hasLabel('Brand').coalesce(__.identity()).V().profile().next()


Below are our AWS Neptune details:

Engine Version: Neptune 1.0.1.0
DB Instance Class: b.r4.large

Reference
1. Coalesce Step:http://tinkerpop.apache.org/docs/current/reference/#coalesce-step

Edited by: hishammuddin-sani on Dec 7, 2018 1:51 AM

Edited by: hishammuddin-sani on Dec 7, 2018 1:53 AM"
Amazon Neptune	"Re: Gremlin coalesce resulting 100% cpu usage
Hi there, happy to try and help.

Could you say a little more about what you are trying to achieve ? I ask as that query is going to find every vertex in the graph that has a 'Brand' label and then that number of times return every Vertex in the entire graph. So this will return a huge amount of data for a large graph and spawn a huge number of traversers which is why you are seeing it take a long time most likely.

If you could say a little more about the query you are trying to write I can try to help change the Gremlin a bit.

Here is an example from one of my graphs that I hope shows the massive fan out that this query will cause:

gremlin> :> g.V().count()
==>3664
gremlin> :> g.V().hasLabel('airport').coalesce(__.identity()).limit(5).V().count()
==>18320
gremlin> 3664*5
==>18320


Cheers
Kelvin

Edited by: Kelvin-AWS on Dec 7, 2018 10:45 AM

Edited by: Kelvin-AWS on Dec 7, 2018 10:49 AM"
Amazon Neptune	"Re: Gremlin coalesce resulting 100% cpu usage
Hi,

We use coalesce to create a node if it's not already created and just return the node if it's already there (using fold().coalesce(unfold())). Recently we realised that this query (using V().has(predicate)) traverse all vertices after we use coalesce. Sorry I dont have any gremlin query profiling screenshotted before the problem arise but here is the recent profiling done

The profiling result when we use coalesce can be found at attachment with-coalesce.png and without coalesce at without-coalesce.png. 

I hope the attachment can explain more

Edited by: hishammuddin-sani on Dec 7, 2018 4:24 PM"
Amazon Neptune	"Re: Gremlin coalesce resulting 100% cpu usage
Hi again, 

The coalesce is not really doing anything useful for you in that query but it will cause a lot more work to take place.

Are you eventually planning to use it to do an upsert in a way like this...

g.V().has('Tag','name','quality).fold().coalesce(unfold(),addV()...)


If so could you perhaps profile that pattern. You should see that that pattern generates improved results.

Cheers
Kelvin"
Amazon Neptune	"Re: Gremlin coalesce resulting 100% cpu usage
Hi hishammuddin-sani,

Just checking in to see if you had any followups on this thread. Let us know!

Karthik"
Amazon Neptune	"Creating a cluster using the console hangs forever
Hello,

I am trying to create a new cluster using the AWS Console. After filling in all the information, I click 'Create Database' and nothing happens. There are some errors in the browser console, but can't identify if they are the main cause.

Checking the console in another tab shows no new resources either."
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
Hi,

I tried on my console and it looks good to me. I can create a Neptune instance successfully. Would you mind open the developer tools and tell me the error message you get? also, if you can provide more information, like what you change for creating a instance, it will be really helpful for me to understand which part of our console has issue.

Thanks!"
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
Hello, 

I'm, having the exact same problem. I can't create a new neptune instance via AWS console. What would you suggest?"
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
Update: I've managed to create a neptune in us-east-2. I couldn't get us-east-1 to work."
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
Hi there, glad you are up and running in us-east-2

When you tried in us-east-1 did you get any specific error message(s) ?

Cheers,
Kelvin"
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
No messages.

There is a button ""Create database"" that has a loader. Initially it is orange. When I click it, it dims to grey, and a loader animation appears inside.

The loader never stops, it's been 30 minutes."
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
Hi,

It maybe an issue with Chrome, can you please give Firefox a try? We have seen this issue before but have not been able to reproduce it yet."
Amazon Neptune	"Re: Creating a cluster using the console hangs forever
Hi all,

Just checking in on this to see if you are still seeing the issue in the console. I've tried creating new instances and similar to many others, I am not able to reproduce the errors described here.

For future reference, if you end up getting blocked on creating instances via console, do try spinning up your cluster using the aws cli. ""aws neptune help"" should give you the full list of apis. 

Do let us know!
Thanks."
Amazon Neptune	"CloudFormation throwing error for Neptune
Hi,
  I am trying to setup AWS Neptune using cloudformation stack. But currently I am blocked with below error -
Invalid master password (Service: AmazonNeptune; Status Code: 400; Error Code: InvalidParameterValue; Request ID: 918baea3-13e3-4b88-bfb1-15efdc7a83a9) 

""TestNeptuneDbinstance"": {
      ""Type"": ""AWS::Neptune::DBInstance"",
      ""Properties"": {
        ""DBInstanceClass"": ""db.r4.large"",
        ""DBInstanceIdentifier"": ""test""
      }
 }

I tried to include MasterUser and MasterUserPassword butt it again lead to the error that these properties are not defined. Can you please help me in right properties to use for creating Neptune DB instance"
Amazon Neptune	"Re: CloudFormation throwing error for Neptune
Hi there,

I've encountered this before.  It's a little misleading, because if you create a Neptune instance in the console, you don't have to create a cluster beforehand.  If the instance is the first in a cluster, it will create the cluster for you.  However, if you're creating a new Neptune instance programmatically via API or Cloudformation, you'll need to create the cluster first.  Try this:

Resources:
  TestNeptuneDbcluster:
    Type: AWS::Neptune::DBCluster
  TestNeptuneDbinstance:
    Type: AWS::Neptune::DBInstance
    Properties:
      DBClusterIdentifier:
        !Ref TestNeptuneDbcluster
      DBInstanceClass: ""db.r4.large""


Edited by: Kelvin-AWS on Dec 5, 2018 7:10 AM"
Amazon Neptune	"Re: CloudFormation throwing error for Neptune
Thanks.. After . setting Neptune cluster with subnetgroup, was able to create stack"
Amazon Neptune	"Performance regression after recent update
Hey forums,

I upgraded my neptune cluster today to what I believe is engine version 1.0.1.0.200264.0 and now most of our mutation traversals timeout (regardless of instance size). I suspect that it's due to this change as the affected queries are using the same pattern: 

Improved Gremlin performance for conditional mutations, such as the fold().coalesce(unfold(), …) pattern, when used with addV(), addE(), and property() steps.

We've run hundreds of millions of traversals through previous engine versions this month without issue, so I highly suspect that the engine update is what is causing the issues for us.

Please let me what other information I can provide that will be of assistance."
Amazon Neptune	"Re: Performance regression after recent update
Hi there,

If you are still seeing the issues are you able to open a trouble ticket  including your account and Neptune instance details so that we can take a look on the server side?

It would also be helpful if you could share an example of the exact query that you are experiencing issues with.

Cheers
Kelvin"
Amazon Neptune	"Re: Performance regression after recent update
Hi Kevin,

I have been working with Ling through private messages for the past week, though I haven't been able to contact them for the past couple of days. Someone on AWS side has been able to recreate the issue against our instance and were working on it, but I'm not sure about the current status.

Please PM me for more information if necessary.

Thanks,
Darren Kopp"
Amazon Neptune	"Re: Performance regression after recent update
Thanks Darren. Just wanted to make sure we had not left you hanging 

Cheers
Kelvin"
Amazon Neptune	"duplicate insert to neptune, no response or error code
hi, I have a strange issue with neptune using python 3.7 (gremlinpython==3.3.4),

when running the following code for the first time it succeeding to add the edges and the nodes
when running it second time the process just stuck with no response or any timeout

p.s. I have an ssh tunnel from ""127.0.0.1:8882"" to Neptune via EC2

    g = Graph().traversal().withRemote(
        DriverRemoteConnection('ws://{}:{}/gremlin'.format(""127.0.0.1"", ""8882""), 'g'))
 
 
    def run_query(query):
        try:
            print(""running query {}"".format(str(query)))
            query.next()
        except Exception as e:
            print(e)
 
 
    run_query(g.addV(""node"").property(T.id, ""vertex1""))
    run_query(g.addV(""node"").property(T.id, ""vertex2""))
    run_query(g.V(""vertex1"").as_('to').V(""vertex2"").addE(""edge"").to('to').property(T.id, ""edge1""))
    run_query(g.V(""vertex1"").as_('to').V(""vertex2"").addE(""edge"").to('to').property(T.id, ""edge2""))
    run_query(g.V(""vertex1"").as_('to').V(""vertex2"").addE(""edge"").to('to').property(T.id, ""edge4""))
    run_query(g.V(""vertex1"").as_('to').V(""vertex2"").addE(""edge"").to('to').property(T.id, ""edge5""))


response 1
running query [['addV', 'node'], ['property', <T.id: 1>, 'vertex1']]
running query [['addV', 'node'], ['property', <T.id: 1>, 'vertex2']]
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge1']]
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge2']]
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge4']]
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge5']]
 
Process finished with exit code 0

response 2
running query [['addV', 'node'], ['property', <T.id: 1>, 'vertex1']]
499: {""requestId"":""ab08bc04-9add-4a96-90c5-13572c96d6c1"",""code"":""ConstraintViolationException"",""detailedMessage"":""Vertex with id already exists: vertex1""}
running query [['addV', 'node'], ['property', <T.id: 1>, 'vertex2']]
499: {""requestId"":""a39da6ba-046e-4980-ba05-ffe0c2a748c9"",""code"":""ConstraintViolationException"",""detailedMessage"":""Vertex with id already exists: vertex2""}
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge1']]
499: {""requestId"":""ddd33d10-ed62-4df7-a0e9-66be1da077e5"",""code"":""ConstraintViolationException"",""detailedMessage"":""Edge with id already exists: edge1""}
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge2']]
499: {""requestId"":""f99961ff-5f10-4c4e-b66b-cda9523dec55"",""code"":""ConstraintViolationException"",""detailedMessage"":""Edge with id already exists: edge2""}
running query [['V', 'vertex1'], ['as', 'to'], ['V', 'vertex2'], ['addE', 'edge'], ['to', 'to'], ['property', <T.id: 1>, 'edge4']]


the last query does not return anything and always just stuck

I did try to restart the Neptune instance and it did not helped
also 
curl -G ""http://****.neptune.amazonaws.com:8182/status

returned
{""status"":""healthy""}


Edited by: abragsimplex on Nov 26, 2018 6:12 PM

Edited by: abragsimplex on Nov 26, 2018 6:13 PM"
Amazon Neptune	"Re: duplicate insert to neptune, no response or error code
Hi abragsimplex,

We looked into this issue and it appears to be a bug in the gremlin-python driver. This happens when the query response from the server contains an exception, the driver does not put the connection back in the connection pool which leads to no more connections being available after some number of failed queries. In your case it is 4 failed queries because the default connection pool size is 4. 

We have opened a jira: https://issues.apache.org/jira/browse/TINKERPOP-2105 with the tinkerpop community. You could try the workaround mentioned in jira .

Thanks,
Kunal"
Amazon Neptune	"Dev / Staging / Testing Env, Recommend Practice for AWS Neptune
Hi,

Great news about Neptune being Generally Available today, Congrats! 

I was wondering what the best practice was for Dev/Staging envs?

Ideally I'd create a dev/staging database server to develop on, and would leave the production db/server untouched.

Is there an localhost or low-cost version of Neptune (or similar API) for dev/staging/testing or what is the best practice for this?

Thanks!

Edited by: quang on May 31, 2018 2:16 PM"
Amazon Neptune	"Re: Dev / Staging / Testing Env, Recommend Practice for AWS Neptune
Hi,

Thanks! Neptune does support both Apache TinkerPop 3.3.2 and SPARQL 1.1, so you can use a local copy of a tool that supports those APIs and then migrate to Neptune. For Gremlin, the Neptune-specific implementation features are at https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-differences.html.

You can also setup Neptune instances that run within AWS CodeDeploy for continuous integration use cases.

We are also looking at supporting a wider range of instance types, some of which would be targeted for development and non-production usage.

Thanks!"
Amazon Neptune	"Re: Dev / Staging / Testing Env, Recommend Practice for AWS Neptune
bradbataws wrote:
supporting a wider range of instance types, some of which would be targeted for development and non-production usage.

Yeah, that'll be great!

you can use a local copy of a tool that supports those APIs

Is there a recommend one for RDF/SPARQL?

Thanks!"
Amazon Neptune	"Re: Dev / Staging / Testing Env, Recommend Practice for AWS Neptune
you can use a local copy of a tool that supports those APIs and then migrate to Neptune. For >Gremlin, the Neptune-specific implementation features are at >https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-differences.html.

Is there any Gremlin local tool that is close or matching with gremlin difference Neptune is having that you can recommend as well?

We don't want to run into migration surprises after developing locally."
Amazon Neptune	"Re: Dev / Staging / Testing Env, Recommend Practice for AWS Neptune
Unfortunately, we don't have anything which emulate Neptune locally."
Amazon Neptune	"Re: Dev / Staging / Testing Env, Recommend Practice for AWS Neptune
We use AWS Code deploy for all our deployments. 

You can also setup Neptune instances that run within AWS CodeDeploy for continuous integration use cases.

Is there any documentation around this?

Edited by: Srimathi on Nov 27, 2018 3:16 AM"
Amazon Neptune	"CURL call via lambda for insertion of data into neptune
Respected team, 
I have written the below code which does work however the expected output and the  actual output differ. Can you please throw some light on this issue. 
Expected Output:
{
    ""status"" : ""200 OK"",
    ""payload"" : {
        ""loadId"" : ""ef478d76-d9da-4d94-8ff1-08d9d4863aa5""
    }
}
Actual output:
Response:
7

Request ID:
""1c3dc9b7-e409-11e8-a1a9-cf26454bfeca""

Function Logs:
START RequestId: 1c3dc9b7-e409-11e8-a1a9-cf26454bfeca Version: $LATEST
END RequestId: 1c3dc9b7-e409-11e8-a1a9-cf26454bfeca
REPORT RequestId: 1c3dc9b7-e409-11e8-a1a9-cf26454bfeca       Duration: 130412.25 ms Billed Duration: 130500 ms                 Memory Size: 128 MB    Max Memory Used: 23 MB          

CODE:
import subprocess

def lambda_handler(event, context):

    cmd1='{ ""source"" : ""s3://uploadingmate/lambda"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""FALSE""}'
   #result = subprocess.call(""curl - http://november5thcluster.cluster-ro-csjhb1wvf1px.us-west-2.neptune.amazonaws.com"", shell=True)
    result = subprocess.call(""curl -X POST \-H 'Content-Type: application/json' \
http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader -d cmd1"", shell=True)
    return result
    '''
    result1=subprocess.call(""curl -G 'http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182:8182/loader/05650e04-e408-11e8-928d-49c2732915ed'"")
    return result1
    '''

Also, whenever I run the commented part it gives me back ""FILE NOT FOUND EXCEPTION"".
Hope there is a solution for this thing. 

Thanking you. 
Apurva Lodha

Edited by: APU on Nov 9, 2018 4:25 AM"
Amazon Neptune	"Re: CURL call via lambda for insertion of data into neptune
Hi,

Are you talking about this part?

result1=subprocess.call(""curl -G 'http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182:8182/loader/05650e04-e408-11e8-928d-49c2732915ed'"")
return result1

Just noticing there's "":8182:8182"" in the URL?"
Amazon Neptune	"Re: CURL call via lambda for insertion of data into neptune
Respected Team, 

There are two questions of mine
1) why is my actual output different from the expected one ?
Expected Output:
{
""status"" : ""200 OK"",
""payload"" : {
""loadId"" : ""ef478d76-d9da-4d94-8ff1-08d9d4863aa5""
}
}
Actual output:
Response:
7

Request ID:
""1c3dc9b7-e409-11e8-a1a9-cf26454bfeca""

2) Why is my result1 giving me back file not found exception ? 

Attaching the code below for reference:
import subprocess

def lambda_handler(event, context):

   ''' 
    cmd1='{ ""source"" : ""s3://uploadingmate/lambda"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""FALSE""}'
   #result = subprocess.call(""curl - http://november5thcluster.cluster-ro-csjhb1wvf1px.us-west-2.neptune.amazonaws.com"", shell=True)
    result = subprocess.call(""curl -X POST \-H 'Content-Type: application/json' \
http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader -d cmd1"", shell=True)
    return result
    '''
    result1=subprocess.call(""curl -G 'http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader/0a228d96-e4aa-11e8-8a3c-19f8fce377ef'"")
    return result1


Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: CURL call via lambda for insertion of data into neptune
Resolved via support case."
Amazon Neptune	"Inserting data from s3 to Neptune via Lambda
Can you please provide the steps of copying data from S3 and inserting to Neptune db instance via lambda ( excluding the EC2 part completely). There exist no such sample code or example so it would be quite helpful if you could provide an appropriate link or sample code for it."
Amazon Neptune	"Re: Inserting data from s3 to Neptune via Lambda
Hello,

Are you wanting to use the Bulk Load API or instead perhaps have a Lambda that responds to events triggered by new data arriving in an S3 bucket? What programming language are you using to create your Lambda function ?

If you can provide a little more information I can provide some suggestions.

Cheers,
Kelvin"
Amazon Neptune	"Re: Inserting data from s3 to Neptune via Lambda
Respected team, 

I am using python language for building my lambda. I prefer my lambda gets triggered by new data arriving in bucket. However, I am quite concerned about the time-complexity too. So if bulk load api gives better result with time I do not mind switching to it. However, my first preference is event-triggered lambda only. 

Thanking you. 
Apurva Lodha."
Amazon Neptune	"Re: Inserting data from s3 to Neptune via Lambda
Hi Apu,

Depending on the amount of data been inserted, comparison between the different methods are:

1. Using addV/addE via Gremlin will give you database level consistency, if somehow the process fails, it will either add all or none of the content of your file, but you will need to perform some parsing of data for files landing in S3 to construct the Gremlin traversal

2. Using the bulk loader will be easier, however, if you have a file of say 10 lines, depending on your failOnError setting, if you set it to true, it will aborted after detecting an error, which may mean that your file is partially loaded up until where the error occurred, or if you have failOnError set to false, it will proceed with the rest of the file and skip out on errorneous content. In either case, you'll have to work out what contents were missing after the process

In terms of timings, you will need to test and see which one is faster for your particular environment and the amount of data."
Amazon Neptune	"Re: Inserting data from s3 to Neptune via Lambda
Respected team, 

Can you provide a sample code or demo for the method 1 you are talking about. I wish to make an event triggered lambda and exclude all the EC2 and CLI overhead to do this part. 

Giving reference :
1. Using addV/addE via Gremlin will give you database level consistency, if somehow the process fails, it will either add all or none of the content of your file, but you will need to perform some parsing of data for files landing in S3 to construct the Gremlin traversal

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: Inserting data from s3 to Neptune via Lambda
Resolved via support case."
Amazon Neptune	"accessing the neptune db instance via AWS CLI
Respected Team, 

I am trying to hit the neptune db instance via the aws  cli however, it gives me this error:

curl: (6) Could not resolve host: november5thcluster.cluster-ro-csjhb1wvf1px.us-west-2.neptune.amazonaws.com

the code I run:
curl -G november5thcluster.cluster-ro-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/status

I am confused because this white paper states two such facts:
https://docs.aws.amazon.com/neptune/latest/userguide/get-started-prerequisites.html

1st fact: Access from the internet is allowed only to the EC2 instance. The EC2 instance is allowed access to the graph database.

2nd fact: If you plan on using the AWS CLI or SDK and not the AWS Management Console to access Neptune resources, you can use the NeptuneFullAccess IAM role, which grants less additional permissions.

My question to you is:
FIRST: Can we run the curl command and hit the neptune instance via AWS CLI ? If yes, how ?

SECOND: Why is it mentioned that access to Neptune instance via internet is only allowed through EC2 instance in the document ?

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
1. Its NOT recommended to give out your Neptune Cluster IDs in public
2. I do not have knowledge on AWS CLI, so cannot help much but based on your error it seems 

either your cluster id is wrong (or not running)
or you are NOT making the request from EC2 instance


for Neptune to work both Neptune and EC2 must be in the same security group, and you can invoke Neptune DNS only from that EC2 box.

Read:
https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-launch-ec2-instance.html
Access to Neptune is limited to within the virtual private cloud (VPC) that the Neptune DB instance is in."
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Hi, 

I completely agree with what you say. However, I wish to connect to my neptune db instance without any ec2 and only via CLI. My db instance link according to me is proper as I have verified it a couple of times. Nonetheless, my only major concern is to use the curl command via CLI excluding the EC2 part completely. 

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
If you wanted to send a curl to Neptune using Lambda functions (I believe form your other posts you are wanting to do everything from Lambda Functions) you could create a small Lambda function that sends a curl as shown below.

import json
from subprocess import check_output
 
def lambda_handler(event, context):
    res = check_output(['curl','http://<your endpoint>:8182/status'])
    return {
        'statusCode': 200,
        'body': json.dumps(str(res))
    }


This would be a way to do things such as query the cluster status and communicate with the bulk loader endpoint. However, for working with data in the graph you would not typically take this approach but rather use a client library such as Gremlin Python. Note that for this to work the Lambda function needs to have access to the VPC that Neptune is running in and the Neptune endpoint's port (by default 8182).

An alternative would be to configure a Load Balancer. That would allow you to communicate with Neptune from the command line using `curl` commands.

Cheers,
Kelvin

Edited by: Kelvin-AWS on Nov 12, 2018 7:58 AM"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Respected team,

I agree with what you say and totally understand your code which is quite helpful when a health check status is required. However, I am confused that how could it be suitable for the below code of data loading through lambda. This code returns:

Response:
0

Request ID:
""9029468b-e6a0-11e8-bf2d-cb6d81fbd71f""

Function Logs:
START RequestId: 9029468b-e6a0-11e8-bf2d-cb6d81fbd71f Version: $LATEST
END RequestId: 9029468b-e6a0-11e8-bf2d-cb6d81fbd71f
REPORT RequestId: 9029468b-e6a0-11e8-bf2d-cb6d81fbd71f	Duration: 229.85 ms	Billed Duration: 300 ms 	Memory Size: 128 MB	Max Memory Used: 22 MB	


THE CODE

import subprocess
def lambda_handler(event, context):


    cmd1='{ ""source"" : ""s3://testings3neptune/"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""TRUE""}'
   #result = subprocess.call(""curl - http://november5thcluster.cluster-ro-csjhb1wvf1px.us-west-2.neptune.amazonaws.com"", shell=True)
    result = subprocess.call(""curl -X POST \-H 'Content-Type: application/json' \
http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader -d cmd1"", shell=True)
    return result

My question to you is how to get the following output via lambda:
FIRST QUESTION
The Neptune loader returns a job id that allows you to check the status or cancel the loading process; for example:

{
    ""status"" : ""200 OK"",
    ""payload"" : {
        ""loadId"" : ""ef478d76-d9da-4d94-8ff1-08d9d4863aa5""
    }
}
Reference : https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-data.html

So that I can get the loadId and use it for further use. 

SECOND QUESTION: Also, I am not yet fully clear about how to use CLI for hitting the curl command. You had asked to start a load balancer for it which means I might require EC2 too. But, I wish to exclude the entire EC2 part. So my questions goes:
Is it possible to run the curl command via CLI without starting an EC2 instance ?

Thanking you. 
Apurva Lodha

Edited by: APU on Nov 12, 2018 9:37 AM"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Building on my earlier example, you can convert the bytes that come back from curl into JSON and then extract data from that JSON. You could use this approach to get the load ID. In my example I just get the status.

import json
from subprocess import check_output
 
def lambda_handler(event, context):
    res = check_output(['curl','http://<your Neptune instance>:8182/status'])
    d = json.JSONDecoder()
    j = d.decode(res.decode(""utf-8""))
   #Prints 'healthy' to the log.  
    print(j['status'])
    return {
        'statusCode': 200,
        'body': j
    }


The return result now looks like this:

{
  ""statusCode"": 200,
  ""body"": {
    ""status"": ""healthy""
  }
}


Edited by: Kelvin-AWS on Nov 12, 2018 10:45 AM"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Respected team, 

I used the code you had provided for finding all my loadIds nonetheless none returned. 

CODE

    res = check_output()
'''
The curl command used in the above check_output is working on this link:'http://november5thcluster.cluster-csjhb1wvf1px.us-west-\2.neptune.amazonaws.com:8182/loader'
'''
    return {
        'statusCode': 200,
        'body': json.dumps(str(res))
    }


RESULT

Response:
{
  ""statusCode"": 200,
  ""body"": ""\""b'{\\\\n    \\\""status\\\"" : \\\""200 OK\\\"",\\\\n    \\\""payload\\\"" : {\\\\n        \\\""loadIds\\\"" : [ ]\\\\n    }\\\\n}'\""""
}

Request ID:
""b22bef1a-e700-11e8-a533-efd6de2d439a""

Function Logs:
START RequestId: b22bef1a-e700-11e8-a533-efd6de2d439a Version: $LATEST
END RequestId: b22bef1a-e700-11e8-a533-efd6de2d439a
REPORT RequestId: b22bef1a-e700-11e8-a533-efd6de2d439a	Duration: 107.79 ms	Billed Duration: 200 ms 	Memory Size: 128 MB	Max Memory Used: 23 MB	

This simply means my lambda code for insertion of data from s3 to Neptune isn't working. However, that lambda function gives none such error during insertion. 

CODE
 result3 = subprocess.call('curl -X POST \-H ""Content-Type: application/json""  http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader -d { ""source"" : ""s3://testings3neptune"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""TRUE""}', shell=True)
    return result3 

RESULT
Response:
3

Request ID:
""ebda403b-e702-11e8-96b9-09bd5cbbf6e5""

Function Logs:
START RequestId: ebda403b-e702-11e8-96b9-09bd5cbbf6e5 Version: $LATEST
END RequestId: ebda403b-e702-11e8-96b9-09bd5cbbf6e5
REPORT RequestId: ebda403b-e702-11e8-96b9-09bd5cbbf6e5	Duration: 464.35 ms	Billed Duration: 500 ms 	Memory Size: 128 MB	Max Memory Used: 22 MB	

My question to you is : what should I change in my lambda function so that successful insertion of data takes place and I could thus get the loadId from it. 

(Also, I would like to mention the IAM role has full and read access of S3 and Neptune, the path of S3 folder is correct and the region us-west-2 also corresponds to the region where my Neptune instance is)

My 2nd question:  How to resolve the BadRequestException ? I checked the AWS documentation which said just rerun the code which isn't working for me. 

Question3

Finally, I tried running the below code but it gives me BadRequestException. Can you please recommend a solution to it? please.

CODE 
cmd1 = '{ ""source"" : ""s3://testings3neptune"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""TRUE""}'
    out = check_output()

    #res = check_output()
    #res = check_output()

    return {
        'statusCode': 200,
        'body': json.dumps(str(out))
    }

RESPONSE
Response:
{
  ""statusCode"": 200,
  ""body"": ""\""b'{\\\""requestId\\\"":\\\""c4b385ec-8138-0b89-0f0a-03d21fd386d5\\\"",\\\""code\\\"":\\\""BadRequestException\\\"",\\\""detailedMessage\\\"":\\\""Unexpected error reading the URL\\\""}'\""""
}

Request ID:
""d9d9c2da-e710-11e8-98c2-df65335d0e0b""

Function Logs:
START RequestId: d9d9c2da-e710-11e8-98c2-df65335d0e0b Version: $LATEST
END RequestId: d9d9c2da-e710-11e8-98c2-df65335d0e0b
REPORT RequestId: d9d9c2da-e710-11e8-98c2-df65335d0e0b	Duration: 513.08 ms	Billed Duration: 600 ms 	Memory Size: 128 MB	Max Memory Used: 27 MB

Thanking you. 
Apurva Lodha.

Edited by: APU on Nov 13, 2018 1:26 AM"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Hi again, so initially we have been discussing using curl as a way to get you going and to see if your instance has data in a way that can be run from a Lambda function. Longer term, you might want to consider using the urllib.request class from Python 3. Here is an example of querying the loader endpoint using that approach. You can submit the HTTP GET and POST requests that you would submit using curl in this way. Anyway, I wanted to give you an alternative to consider.

import urllib.request
from urllib.request import Request
 
url = ""http://<your Neptune instance>:8182/loader""
 
request = Request(url,method=""GET"")
response = urllib.request.urlopen(request)
print(response.read().decode(""utf-8""))


When run this code will return something like this:

{
    ""status"" : ""200 OK"",
    ""payload"" : {
        ""loadIds"" : [
            ""XXXXXXXX-YYYY-XXXX-YYYY-XXXXXXXXXXXX""
        ]
    }
}


To get at the IDs themselves you can just use the json class to read in the results from the HTTP request as follows.

jsonres = json.loads(response.read().decode(""utf-8""))
print(jsonres['payload']['loadIds'])


Cheers,
Kelvin

Edited by: Kelvin-AWS on Nov 13, 2018 2:59 PM"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Respected team, 

I wrote the following code however I am getting a timeout error. Also, I believe that my data is not loaded even though my code is getting successfully executed ( please refer previous post).
Can you help me out with that  (Question 1 - previous post)

CODE:
import json
import urllib.request
from urllib.request import Request

def lambda_handler(event, context):


    url = ""http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader""

    request = Request(url,method=""GET"")
    response = urllib.request.urlopen(request)
    print(response.read().decode(""utf-8""))
    # TODO implement
    jsonres = json.loads(response.read().decode(""utf-8""))
    print(jsonres)

    '''
    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }
    '''

RESPONSE:
Response:
{
  ""errorMessage"": ""<urlopen error https://forums.aws.amazon.com/ Connection timed out>"",
  ""errorType"": ""URLError"",
  ""stackTrace"": [
    [
      ""/var/task/lambda_function.py"",
      11,
      ""lambda_handler"",
      ""response = urllib.request.urlopen(request)""
    ],
    [
      ""/var/lang/lib/python3.6/urllib/request.py"",
      223,
      ""urlopen"",
      ""return opener.open(url, data, timeout)""
    ],
    [
      ""/var/lang/lib/python3.6/urllib/request.py"",
      526,
      ""open"",
      ""response = self._open(req, data)""
    ],
    [
      ""/var/lang/lib/python3.6/urllib/request.py"",
      544,
      ""_open"",
      ""'_open', req)""
    ],
    [
      ""/var/lang/lib/python3.6/urllib/request.py"",
      504,
      ""_call_chain"",
      ""result = func(*args)""
    ],
    [
      ""/var/lang/lib/python3.6/urllib/request.py"",
      1346,
      ""http_open"",
      ""return self.do_open(http.client.HTTPConnection, req)""
    ],
    [
      ""/var/lang/lib/python3.6/urllib/request.py"",
      1320,
      ""do_open"",
      ""raise URLError(err)""
    ]
  ]
}

Request ID:
""e8bb5511-e7c3-11e8-9dc6-3734cb8107e4""

Function Logs:
START RequestId: e8bb5511-e7c3-11e8-9dc6-3734cb8107e4 Version: $LATEST
<urlopen error https://forums.aws.amazon.com/ Connection timed out>: URLError
Traceback (most recent call last):
  File ""/var/task/lambda_function.py"", line 11, in lambda_handler
    response = urllib.request.urlopen(request)
  File ""/var/lang/lib/python3.6/urllib/request.py"", line 223, in urlopen
    return opener.open(url, data, timeout)
  File ""/var/lang/lib/python3.6/urllib/request.py"", line 526, in open
    response = self._open(req, data)
  File ""/var/lang/lib/python3.6/urllib/request.py"", line 544, in _open
    '_open', req)
  File ""/var/lang/lib/python3.6/urllib/request.py"", line 504, in _call_chain
    result = func(*args)
  File ""/var/lang/lib/python3.6/urllib/request.py"", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File ""/var/lang/lib/python3.6/urllib/request.py"", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error https://forums.aws.amazon.com/ Connection timed out>

END RequestId: e8bb5511-e7c3-11e8-9dc6-3734cb8107e4
REPORT RequestId: e8bb5511-e7c3-11e8-9dc6-3734cb8107e4	Duration: 131079.75 ms	Billed Duration: 131100 ms 	Memory Size: 128 MB	Max Memory Used: 22 MB	

Thanking you. 
Apurva Lodha

Edited by: APU on Nov 13, 2018 8:24 PM"
Amazon Neptune	"Re: accessing the neptune db instance via AWS CLI
Issue resolved via support case."
Amazon Neptune	"quandary about successful insertion of data
Resptected team, 

I have written the below code for performing BULK LOAD API. I donot get any error but I believe that the data is not getting inserted to Neptune. This is because when I try to retrieve all the loadIds I am getting none even after insertion. Can you help me to do successful insertion of data after which I can get the appropriate loadIds of it ?

CODE
#This code is related to the BULK LOAD API which transfers the data from s3 to neptune
import subprocess
def lambda_handler(event, context):


    result3 = subprocess.call('curl -X POST \-H ""Content-Type: application/json""  http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader -d { ""source"" : ""s3://testings3neptune"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""TRUE""}', shell=True)
    return result3    

RESPONSE 
Response:
3

Request ID:
""9c2c9770-e7cd-11e8-83b2-c72418796627""

Function Logs:
START RequestId: 9c2c9770-e7cd-11e8-83b2-c72418796627 Version: $LATEST
END RequestId: 9c2c9770-e7cd-11e8-83b2-c72418796627
REPORT RequestId: 9c2c9770-e7cd-11e8-83b2-c72418796627	Duration: 159.71 ms	Billed Duration: 200 ms 	Memory Size: 128 MB	Max Memory Used: 28 MB   

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: quandary about successful insertion of data
Hi Apurva,

Could you open a support ticket via AWS console so we can provide support over a secure communications channel?  This is a public forum and we'd advise against posting potentially sensitive info such as your cluster ID, s3 bucket name, arns, etc.

That being said, judging by the response code you're getting back (3) there seems to be some issue with your curl command itself (see https://curl.haxx.se/libcurl/c/libcurl-errors.html).  My guess is that quote-escaping your request body might help (the argument to -d).

Thanks,
Dan"
Amazon Neptune	"Re: quandary about successful insertion of data
Respected team, 

I totally agree with what you say but I prefer to use the forum over raising the ticke for 3 reasons. 
1) I am having a basic account so raising technical support query isn't permitted
2) I am using all these credentials temporarily and then will change anyway. 
3) Most importantly, the aws white papers have emphasized over the EC2 service to connect to neptune however I know that lambda can be used to load data to neptune. Making the entire process SERVERLESS. This aws forum thus can help many for finding the answer of going serverless. 

Having said that, I have one final query I believe. I am running the curl command to load the data which gives me a response(0) which means the curl command is getting executed. However, when I try to get the loadIds it is still returning me none. Can you help me to know why ?

CODE
#This code is related to the BULK LOAD API which transfers the data from s3 to neptune
import json
import subprocess
from subprocess import check_output

def lambda_handler(event, context):


    cmd1={ ""source"" : ""s3://testings3neptune"", ""format"" : ""csv"",""iamRoleArn"" : ""arn:aws:iam::540732236758:role/S3toNeptune"", ""region"" : ""us-west-2"", ""failOnError"" : ""TRUE""}
    result3 = subprocess.call(""curl -X POST \     -H 'Content-Type: application/csv' \     http://november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/loader -d ' { **cmd1 } '     "", shell=True)

print(result3)

    res = check_output()


    return {
        'statusCode': 200,
        'body': json.dumps(str(res))
    }

RESULT
Response:
{
  ""statusCode"": 200,
  ""body"": ""\""b'{\\\\n    \\\""status\\\"" : \\\""200 OK\\\"",\\\\n    \\\""payload\\\"" : {\\\\n        \\\""loadIds\\\"" : [ ]\\\\n    }\\\\n}'\""""
}

Request ID:
""71fac7af-e89d-11e8-8eb3-73b2ec7c6a6a""

Function Logs:
START RequestId: 71fac7af-e89d-11e8-8eb3-73b2ec7c6a6a Version: $LATEST
0
END RequestId: 71fac7af-e89d-11e8-8eb3-73b2ec7c6a6a
REPORT RequestId: 71fac7af-e89d-11e8-8eb3-73b2ec7c6a6a	Duration: 257.08 ms	Billed Duration: 300 ms 	Memory Size: 128 MB	Max Memory Used: 23 MB	


Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: quandary about successful insertion of data
Hi Apurva,

I'm going to mark this one as answered."
Amazon Neptune	"Re: quandary about successful insertion of data
This has been discussed and resolved through support case."
Amazon Neptune	"Dates confusing and seemingly inefficient
date is a supported type for Neptune and it stores it in milliseconds. There doesn't seem to be a good way to query by that value however. Querying vertices by the very values stored in the nodes returns nothing. for ex. g.V().hasLabel('dates').has('date', 1542690000000) returns nothing when that value clearly exists. We were able to query by converting date formatted text using the datetime function but it seems extremely inefficient. for ex.
g.V().hasLabel('structure').has('version', '7.1').outE('interpreted').has('is_valid',true).inV().count()

 returns 3338756
g.V().hasLabel('structure').has('version', '7.1').outE('interpreted').has('is_valid',true).inV().where(out('created_on').has('date', gte(datetime('2018-11-20T00:00:00')))).count()

times out

Is there a more efficient way to filter by date?"
Amazon Neptune	"Re: Dates confusing and seemingly inefficient
Hi there, it looks like you are sending queries as text strings. I will run some tests using that approach and post again.

In the meantime, I typically store timestamps as straight epoch offsets such as shown below from the Gremlin console. This is a fairly portable and programming language agnostic way of storing timestamps. I'll definitely look more into what you are seeing but in the meantime I thought you might find this useful

gremlin> System.currentTimeMillis()
==>1542829174936
gremlin> :> g.addV('test').property(single,'timestamp',1542829174936)
==>v[8eb39be4-bf65-5f23-4469-29c5585a6e32]
gremlin> :> g.V().has('timestamp',1542829174936)
==>v[8eb39be4-bf65-5f23-4469-29c5585a6e32]
gremlin> :> g.V().has('timestamp',gte(1542829174936))
==>v[8eb39be4-bf65-5f23-4469-29c5585a6e32]
gremlin>


Cheers,
Kelvin"
Amazon Neptune	"Re: Dates confusing and seemingly inefficient
Here is an example where I used datetime() to create and test the date property. In your use case how did you create the property initially?

gremlin> :> g.addV('test').property(single,'timestamp',datetime('2018-11-20T00:00:00'))
==>v[f4b39bea-3093-8d55-7013-b5395b08b4c2]
 
gremlin> :> g.V().hasLabel('test').valueMap(true)
==>{id=8eb39be4-bf65-5f23-4469-29c5585a6e32, timestamp=[1542829174936], label=test}
==>{id=f4b39bea-3093-8d55-7013-b5395b08b4c2, timestamp=[Tue Nov 20 00:00:00 UTC 2018], label=test}
 
gremlin> :> g.V().has('timestamp',gte(datetime('2018-11-20T00:00:00')))
==>v[f4b39bea-3093-8d55-7013-b5395b08b4c2]


So long as the date/time is created and tested using datetime() I see the results I was expecting in the test above.

As a sidenote there are a few more examples of using timestamps from various environments in this document https://docs.aws.amazon.com/neptune/latest/userguide/best-practices.html

Cheers,
Kelvin

Edited by: Kelvin-AWS on Nov 21, 2018 12:06 PM"
Amazon Neptune	"Re: Dates confusing and seemingly inefficient
Hi Kelvin, thanks for responding. 

We created the property initially using the datetime function. The vertex, once created, looks like the following:
""date"": [
                                {
                                    ""@type"": ""g:VertexProperty"",
                                    ""@value"": {
                                        ""id"": {
                                            ""@type"": ""g:Int32"",
                                            ""@value"": -303967776
                                        },
                                        ""label"": ""date"",
                                        ""value"": {
                                            ""@type"": ""g:Date"",
                                            ""@value"": 1542690000000
                                        }
                                    }
                                }
                            ]

The type is Date, the value is 1542690000000. Why cant I filter by 1542690000000? Why cant I filter by '11-20-2018'? Its strange that I cant filter by a specific date UNLESS I convert a string via the datetime function and then apply a gt function on top of that (as suggested in the best practices). It's a lot of extra overhead that causes our traversals to timeout. Doing the conversion to milliseconds before insertion was probably the better way to go for this database.

Out of curiousity, is your timestamp value stored as an int32?
Thanks again

Edited by: dwmoses on Nov 21, 2018 12:40 PM

Edited by: dwmoses on Nov 21, 2018 12:51 PM"
Amazon Neptune	"Re: Dates confusing and seemingly inefficient
For the two vertices I created above the valueMap() is as follows. The one I created as an explicit epoch offset is an Int64 and the other one is a Date. I am going to do some follow up with a colleague. Please look for another post soon.


""result"": {
    ""data"": {
      ""@type"": ""g:List"",
      ""@value"": [
        {
          ""@type"": ""g:Vertex"",
          ""@value"": {
            ""id"": ""8eb39be4-bf65-5f23-4469-29c5585a6e32"",
            ""label"": ""test"",
            ""properties"": {
              ""timestamp"": [
                {
                  ""@type"": ""g:VertexProperty"",
                  ""@value"": {
                    ""id"": {
                      ""@type"": ""g:Int32"",
                      ""@value"": -252238706
                    },
                    ""value"": {
                      ""@type"": ""g:Int64"",
                      ""@value"": 1542829174936
                    },
                    ""label"": ""timestamp""
                  }
                }
              ]
            }
          }
        },
        {
          ""@type"": ""g:Vertex"",
          ""@value"": {
            ""id"": ""f4b39bea-3093-8d55-7013-b5395b08b4c2"",
            ""label"": ""test"",
            ""properties"": {
              ""timestamp"": [
                {
                  ""@type"": ""g:VertexProperty"",
                  ""@value"": {
                    ""id"": {
                      ""@type"": ""g:Int32"",
                      ""@value"": 1614170459
                    },
                    ""value"": {
                      ""@type"": ""g:Date"",
                      ""@value"": 1542672000000
                    },
                    ""label"": ""timestamp""
                  }
                }
              ]
            }
          }
        }
      ]
    },"
Amazon Neptune	"sample code for accessing and manipulating data via lambda
Part1:
I am finding ways through which I can access the data and manipulate it once we get it via lambda from Neptune. Nonetheless, I am confused as to which way to approach. 

I went through this link:
https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-node-js.html

But it doesn't have any resource for one should do with data. Can you please shed some light on this.

Part2:
Boto3 doesn't have much functions for dealing and manipulating data once taken from Neptune unlike S3. Why is this the case ?

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: sample code for accessing and manipulating data via lambda
Hi Apurva,

Could you please say a bit more about what you are trying to do with respect to working with data so we can offer you some suggestions?

Neptune supports the SPARQL (for RDF graphs) and Gremlin (for property graphs) query languages for working with data. In the case of Gremlin you can use any of the Gremlin clients available as open source or send Gremlin requests over HTTP as text strings to the Neptune cluster endpoint.

You would use Boto3 for working with the configuration of the database itself but not for querying data.

If you are looking to write your code using Node.js and JavaScript then you can use the gremlin-javascript open source client as I believe you have already discovered.

Are there some specific data read/write operations that you need help with?

Cheers
Kelvin"
Amazon Neptune	"Re: sample code for accessing and manipulating data via lambda
Hi Apurva,

There's also a blog post that describes how to do a serverless query for Neptune.

https://aws.amazon.com/blogs/database/query-your-aws-database-from-your-serverless-application/

Thanks, --Brad"
Amazon Neptune	"Re: sample code for accessing and manipulating data via lambda
Respected Sir, 

QUESTION1
Can I execute the same thing written in the document: 
https://aws.amazon.com/blogs/database/query-your-aws-database-from-your-serverless-application/

with CLI and not EC2. I am wishing to exclude the entire EC2 part. Is it possible to do the entire thing via CLI ?

QUESTION2
Also, I tried running the curl command (after changing the values to appropriate endpoints, iamRole, etc) however, this is not running from CLI. Can this command be run from a CLI ?

curl -X POST \
    -H 'Content-Type: application/json' \
http://your-neptune-endpoint:8182/loader -d '
    { 
      ""source"" : ""s3://bucket-name/object-key-name"", 
      ""format"" : ""format"",  
      ""iamRoleArn"" : ""arn:aws:iam::account-id:role/role-name"", 
      ""region"" : ""region"", 
      ""failOnError"" : ""FALSE""
    }'

Thanking you. 
Apurva Lodha

Edited by: APU on Nov 12, 2018 10:45 PM"
Amazon Neptune	"Re: sample code for accessing and manipulating data via lambda
Hi again - I think we have probably discussed this in some of your other posts but I wanted to give you an answer here also.

The curl command needs to be run from a place that has access to the VPC that your Neptune instance is using. Some of the ways you could do this are:

  1. From an EC2 instance (I know this is not the way you want to do it).
  2. Set up a load balancer and then you can use curl from your command line.
  3. Run the curl command inside a Lambda function (you could also use the HTTP libraries of any of the programming languages that Lambda supports such as urllib.request in Python 3.

Cheers
Kelvin"
Amazon Neptune	"Re: sample code for accessing and manipulating data via lambda
Respected team, 

Thanks. This response does answer the question. 

Regards. 
Apurva Lodha."
Amazon Neptune	"Bulk Load API
Respected Team, 
Can you please provide me in-depth steps of how can one make an Bulk load api call ? I wish to use bulk load API call for inserting data from S3 to Neptune db. 

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: Bulk Load API
Hi Apu,

Documentation is here: https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-data.html

But I think from one of your other posts, you have made progress in this part at least."
Amazon Neptune	"Re: Bulk Load API
Respected team, 

I did went through this documentation however, I donot wish to use the aws CLI console nor EC2 server. So my questions is can you please provide the steps to perform BULK LOAD API via lambda service only. 

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: Bulk Load API
You can refer to the python script http://neptune-docs.aka.amazon.com/tempcreds/latest/userguide/iam-auth-connecting-python.html for IAM auth. It has examples for Bulkloads too.  Note this script is written for IAM auth enabled instances but should work for IAM Auth disabled instances too."
Amazon Neptune	"Re: Bulk Load API
Respected team, 

I wish to access your link which would surely solve my problem. However, when I am trying to access the link you provided I am getting the following error: 

Network Error (dns_unresolved_hostname) 

Your requested host ""neptune-docs.aka.amazon.com"" could not be resolved by DNS.

For assistance, contact your network support team.

Can you please revisit your link ? Please.

Thanking you. 
Apurva Lodha."
Amazon Neptune	"Re: Bulk Load API
Try this link instead.

https://docs.aws.amazon.com/neptune/latest/userguide/iam-auth.html

Cheers,
Kelvin"
Amazon Neptune	"Verifying if my neptune db instance has data
Respected team, 

I wish to know if there exist data in my Neptune DB instance via my lambda. I also prefer to exclude EC2 and AWS CLI for this thing. Can you provide a sample code or demo for this questions.

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: Verifying if my neptune db instance has data
Hello,

I believe from your other posts you are using Gremlin. If you just want to make sure that some data has made it into the graph from a Lambda you could just  issue a Gremlin query to retrieve a single vertex and print its value map. This output will get sent to the CloudWatch logs.

For example you could do (in Python using the gremlinpython library)

vmap = g.V().limit(1).valueMap().toList()
print(vmap)


You could also try counting the vertices and edges but if you have a large graph this can take a long time and you may need to increase the query time limit for your Neptune endpoint.

I hope this helps

Cheers,
Kelvin."
Amazon Neptune	"Re: Verifying if my neptune db instance has data
Respected Team, 

I am pasting the code written by me where I have appended the code given by you however my lambda is giving me empty graph as output. Can you please recommend me a way out of this ?

THE CODE

coding: utf-8



In[ ]:

'''
import boto3

import json
from gremlin_python import statics
from gremlin_python.structure.graph import Graph
from gremlin_python.process.graph_traversal import __
from gremlin_python.process.strategies import *
from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection

def lambda_handler(event, context):
    # TODO implement
    graph=Graph()


    g = graph.traversal().withRemote(DriverRemoteConnection('ws://demoonetwo.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/gremlin','g'))

    #print(g.V().limit(2).toList())
    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }

'''
from __future__  import print_function  # Python 2/3 compatibility
import boto3
#import os
from gremlin_python import statics
from gremlin_python.structure.graph import Graph
from gremlin_python.process.graph_traversal import __
from gremlin_python.process.strategies import *
from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection

CLUSTER_ENDPOINT = 'november5thcluster.cluster-ro-csjhb1wvf1px.us-west-2.neptune.amazonaws.com'
CLUSTER_PORT = 8182
#CLUSTER_IDENTIFIER = os.environ

def run_sample_gremlin_code():
    print('running sample gremlin code')
    graph = Graph()
    g = graph.traversal().withRemote(DriverRemoteConnection('ws://' + 'november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com' + "":"" + '8182' + '/gremlin','g'))#ws means web socket
    #print(g.V().limit(2).toList())
    ##print(g.V().toList())
    #print(g)
    vmap = g.V().limit(1).valueMap().toList()
    print(vmap)

def lambda_handler(event, context):
    print(event)
    #print('hello from lambda handler')

    ## run gremlin query
    if 'november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com' and 8182:
        run_sample_gremlin_code()
    else:
        print(""provide CLUSTER_ENDPOINT and CLUSTER_PORT environment variables"")

if __name__ == ""__main__"":
    event = { 'RequestType': 'test'}
    lambda_handler(event, None)

RESULT
Response:
null

Request ID:
""86d26362-e6a4-11e8-9a27-f1f7b257593f""

Function Logs:
START RequestId: 86d26362-e6a4-11e8-9a27-f1f7b257593f Version: $LATEST
{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}
running sample gremlin code
[]
END RequestId: 86d26362-e6a4-11e8-9a27-f1f7b257593f
REPORT RequestId: 86d26362-e6a4-11e8-9a27-f1f7b257593f	Duration: 152.65 ms	Billed Duration: 200 ms 	Memory Size: 128 MB	Max Memory Used: 45 MB	

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: Verifying if my neptune db instance has data
Perhaps the vertex has no properties so there was no result from valueMap? You could try using valueMap(True)
 That will include the vertex ID and label in any result you get back.

If you suspect there is no data in the graph you could try doing:

c = g.V().count().next()
print(c)


Cheers
Kelvin

Cheers
Kelvin

Edited by: Kelvin-AWS on Nov 12, 2018 10:08 AM"
Amazon Neptune	"Re: Verifying if my neptune db instance has data
Respected team, 

This did work. As I had no data loaded yet it returned a 0. However, thank you very much for your help. 

Thanking you. 
Apurva Lodha."
Amazon Neptune	"Can neptune be accessed & used via lambda excluding the ec2 part completely
I am trying to use lambda to connect to my neptune service. I donot wish to use ec2 instance at all not even for health checkups. However, whenever i try to execute the below code a network error(tcp_error) comes up and i can't resolve it further. 


coding: utf-8



In[ ]:

import boto3

import json
from gremlin_python import statics
from gremlin_python.structure.graph import Graph
from gremlin_python.process.graph_traversal import __
from gremlin_python.process.strategies import *
from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection

def lambda_handler(event, context):
    # TODO implement
    graph=Graph()


    g = graph.traversal().withRemote(DriverRemoteConnection('ws://demoonetwo.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com:8182/gremlin','g'))

    #print(g.V().limit(2).toList())


Can you help ?

Edited by: APU on Nov 5, 2018 9:43 PM"
Amazon Neptune	"Re: Can neptune be accessed & used via lambda excluding the ec2 part completely
Yes it is quite possible to access Neptune from Lambda functions. I have a demo I built that uses API Gateway and Lambda to access Neptune. In my case I used API Gateway as the Lambda functions are essentially providing a REST API interface.

To your issue, a couple of quick questions.

1. Is your Lambda function running in the same VPC as your Neptune DB instance?
2. Does the security group that your Lambda is running in allow access to the port used by the neptune instance? (the default port is 8182)

Also could you please share the error message that is in the logs from when you try and run the Lambda?

Cheers
Kelvin

Edited by: Kelvin-AWS on Nov 6, 2018 8:22 AM"
Amazon Neptune	"Re: Can neptune be accessed & used via lambda excluding the ec2 part completely
Currently I have no data in my neptune and I hope that is not the root of the problem. I am providing the logs below.

START RequestId: a74b1f87-e305-11e8-b1be-2799a8bbb041 Version: $LATEST

03:23:26
{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}

03:23:26
hello from lambda handler

03:23:26
HI

03:23:26
running sample gremlin code

03:23:48
HTTP 599: Timeout while connecting: HTTPError Traceback (most recent call last): File ""/var/task/lambda_function.py"", line 56, in lambda_handler run_sample_gremlin_code() File ""/var/task/lambda_function.py"", line 45, in run_sample_gremlin_code g = graph.traversal().withRemote(DriverRemoteConnection('ws://' + 'november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com' + "":
HTTP 599: Timeout while connecting: HTTPError
Traceback (most recent call last):
File ""/var/task/lambda_function.py"", line 56, in lambda_handler
run_sample_gremlin_code()
File ""/var/task/lambda_function.py"", line 45, in run_sample_gremlin_code
g = graph.traversal().withRemote(DriverRemoteConnection('ws://' + 'november5thcluster.cluster-csjhb1wvf1px.us-west-2.neptune.amazonaws.com' + "":"" + '8182' + '/gremlin','g'))
File ""/var/task/gremlin_python/driver/driver_remote_connection.py"", line 45, in __init__
password=password)
File ""/var/task/gremlin_python/driver/client.py"", line 76, in __init__
self._fill_pool()
File ""/var/task/gremlin_python/driver/client.py"", line 88, in _fill_pool
conn = self._get_connection()
File ""/var/task/gremlin_python/driver/client.py"", line 101, in _get_connection
self._transport_factory, self._executor, self._pool)
File ""/var/task/gremlin_python/driver/connection.py"", line 40, in __init__
self.connect()
File ""/var/task/gremlin_python/driver/connection.py"", line 46, in connect
self._transport.connect(self._url)
File ""/var/task/gremlin_python/driver/tornado/transport.py"", line 33, in connect
lambda: websocket.websocket_connect(url))
File ""/var/task/tornado/ioloop.py"", line 458, in run_sync
return future_cell[0].result()
File ""/var/task/tornado/concurrent.py"", line 238, in result
raise_exc_info(self._exc_info)
File ""<string>"", line 4, in raise_exc_info
File ""/var/task/tornado/stack_context.py"", line 316, in wrapped
ret = fn(*args, **kwargs)
File ""/var/task/tornado/simple_httpclient.py"", line 307, in _on_timeout
raise HTTPError(599, error_message)
tornado.httpclient.HTTPError: HTTP 599: Timeout while connecting


03:23:48
END RequestId: a74b1f87-e305-11e8-b1be-2799a8bbb041

03:23:48
REPORT RequestId: a74b1f87-e305-11e8-b1be-2799a8bbb041	Duration: 22233.74 ms	Billed Duration: 22300 ms Memory Size: 128 MB	Max Memory Used: 43"
Amazon Neptune	"Re: Can neptune be accessed & used via lambda excluding the ec2 part completely
If you are not able to connect to Neptune there are a few things to check.

1. Is your code running inside the same VPC as your Neptune instance or running in a way that it can access that VPC?
2. Is the Security Group configured to allow access to the Neptune port (the default is 8182)
3. Does your Neptune instance have IAM DB Authentication enabled?

You can specify the VPC and Security Group information from the console where you configure you Lambda function(s).

Cheers,
Kelvin"
Amazon Neptune	"Re: Can neptune be accessed & used via lambda excluding the ec2 part completely
Respected team, 

Answering your questions:
1. Is your code running inside the same VPC as your Neptune instance or running in a way that it can access that VPC?
*ANSWER:*Yes, both the lambda and the Neptune are configured in the same VPC. 

2. Is the Security Group configured to allow access to the Neptune port (the default is 8182)
*ANSWER:*I have set the inbound rule open to 8182 port. 

3. Does your Neptune instance have IAM DB Authentication enabled?
*ANSWER:*I had kept this part as no authentication required. Isn't that also fine ?

Thanking you. 
Apurva Lodha"
Amazon Neptune	"Re: Can neptune be accessed & used via lambda excluding the ec2 part completely
Que. I had kept this part as no authentication required. Isn't that also fine ?
Ans. IAM Auth is not required for connecting to AWS Neptune although it is recommended for building any secure prod application. You can skip if you just trying out Neptune. 

""HTTP 599: Timeout while connecting"" means connectivity issue. 
Few  suggestions: 

1. You should have assigned an IAM role to your Lambda function. Can you check whether it has ""AWSLambdaVPCAccessExecutionRole "" policy attached to it? If not, then please attach this policy and try again.  Also please double check you are following the Lambda's guideline by Lamba https://docs.aws.amazon.com/lambda/latest/dg/vpc.html

2. Double check you Lambda's Network settings. 
a. Lambda's VPC is same as NEptune.
b. All Subnets from VPC are added to Lambda's subnet
c. EC2 Security Group has a correct rule for inbound and outbound traffic (https://docs.aws.amazon.com/neptune/latest/userguide/get-started-prerequisites.html#get-started-vpc-security-group)

3. https://forums.aws.amazon.com/ You can double check that there is nothing wrong with your infrastructure via ec2 client. You can have ec2 host in same VPC and with same EC2 Security Group attached.  You can follow the steps here
https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-launch-ec2-instance.html
and try few curl commands to check the connectivity.
https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-rest.html

Then, can you confirm that you can connect to Neptune endpoint from ec2 host? That way you will know that there is nothing wrong with Security Group, VPC and Neptune Settings. If you cannot connect to Neptune from ec2 then it is your infrastructure settings which is causing the problem.

Edited by: AnkitGuptaAtAWS on Nov 12, 2018 11:58 AM

Edited by: AnkitGuptaAtAWS on Nov 12, 2018 11:59 AM"
Amazon Neptune	"Is Neptune Down?
I connected to Neptune via Gremlin Console.
Then entered `g.V().limit(1)` there is no error message nor there is any result. 

How can I debug this more? Neptune page says my instance is active.

Edited by: Srinath2 on Nov 1, 2018 3:49 AM"
Amazon Neptune	"Re: Is Neptune Down?
Hi, happy to try and help.

Please excuse a couple of very basic questions.

1. Did you connect to your graph using something like
:remote connect tinkerpop.server conf/neptune.yaml


2. And then do :remote console
 before issuing the query?

3. Can you get a response from your Neptune endpoint using curl as shown below?
$ curl -G ""http://<your endpoint name>:8182/status""


It should return

{""status"":""healthy""}


3. How did you get the data into your graph? Via the Bulk Loader perhaps? Have you been successfully able to connect before and it is now not working?

You could also try sending your query using curl just to see if the issue is with the console or elsewhere as follows:
curl -G ""http://<your gremlin endpoint>:8182/gremlin?gremlin=g.V().limit(1)""


Hopefully we can quickly figure out what is needed to get you going. I'll keep an eye on the forum for any responses.

Cheers
Kelvin

Edited by: Kelvin-AWS on Nov 1, 2018 6:41 AM

Edited by: Kelvin-AWS on Nov 1, 2018 6:45 AM"
Amazon Neptune	"Re: Is Neptune Down?
1. Did you connect to your graph using something like
:remote connect tinkerpop.server conf/neptune.yaml
-> Yes

2. And then do
:remote console
before issuing the query?
-> Yes

$ bin/gremlin.sh

         \,,,/
         (o o)
-----oOOo-(3)-oOOo-----
plugin activated: tinkerpop.server
plugin activated: tinkerpop.utilities
plugin activated: tinkerpop.tinkergraph
gremlin> :remote connect tinkerpop.server conf/remote.yaml
==>Configured xx.xx.us-east-2.neptune.amazonaws.com/xx.xx.xx.xx:8182
gremlin> :remote console
==>All scripts will now be sent to Gremlin Server - xx.xx.us-east-2.neptune.amazonaws.com/xx.xx.xx.xx:8182 - type ':remote console' to return to local mode

gremlin> 
gremlin> g.V().limit(1)
-- hangs


Wrong Query does not hang
$ curl -G ""http://xx.xx.us-east-2.neptune.amazonaws.com:8182/gremlin""
{""requestId"":""xx"",""code"":""MissingParameterException"",""detailedMessage"":""no gremlin script supplied""}


3. Can you get a response from your Neptune endpoint using curl as shown below?
$ curl -G ""http://<your endpoint name>:8182/status""
It should return
{""status"":""healthy""}
-> 
$ curl -G ""http://xx.xx.us-east-2.neptune.amazonaws.com:8182/status""
{""status"":""healthy""}


3. How did you get the data into your graph? Via the Bulk Loader perhaps? Have you been successfully able to connect before and it is now not working?
-> Programatically load data via Python code (all where working fine till a few days ago read/write)

You could also try sending your query using curl just to see if the issue is with the console or elsewhere as follows:
curl -G ""http://<your gremlin endpoint>:8182/gremlin?gremlin=g.V().limit(1)""

-> This just hangs, no error, no result. (writing wrong dns gives an error, correct end point just hangs)"
Amazon Neptune	"Re: Is Neptune Down?
Rebooting the Neptune Instance solved this problem, BUT now I need some logs of Neptune to figure out what was the  reason for this critical problem. How do I access the logs?"
Amazon Neptune	"Re: Is Neptune Down?
Hi,

Can you please create a support ticket and include the instance identifier? Today, we don't provide access to the internal service logs.

Thanks, --Brad"
Amazon Neptune	"Re: Is Neptune Down?
Ok thanks i'll try that out, not sure I can create tech support tickets"
Amazon Neptune	"Re: Is Neptune Down?
it says 
""Technical Support
Unavailable under the Basic Support Plan""

So any other way I can raise a ticket?"
Amazon Neptune	"Re: Is Neptune Down?
Hi again - I'll send you a PM so we can communicate on a private channel

Cheers
Kelvin"
Amazon Neptune	"Re: Is Neptune Down?
Hey I have responded to you and couple other AWS guys who sent me a PM. Currently my team is deciding whether we can go that route as suggested in pm."
Amazon Neptune	"Re: Is Neptune Down?
Thanks Srinath,

I also replied with another possible option.

Cheers
Kelvin"
Amazon Neptune	"Array property values (gremlinpython)
I'm trying to set some properties as an array of string, but I'm getting a type conversion error, indicating that ""ArrayList"" is not supported.

<div class=""jive-quote""><div class=""jive-quote""><div class=""jive-quote"">g.addV().property('foo', ['bar','baz']).toList()</div></div></div>
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/process/traversal.py"", line 52, in toList
    return list(iter(self))
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/process/traversal.py"", line 43, in __next__
    self.traversal_strategies.apply_strategies(self)
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/process/traversal.py"", line 346, in apply_strategies
    traversal_strategy.apply(traversal)
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/driver/remote_connection.py"", line 143, in apply
    remote_traversal = self.remote_connection.submit(traversal.bytecode)
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/driver/driver_remote_connection.py"", line 54, in submit
    results = result_set.all().result()
  File ""/usr/lib64/python3.6/concurrent/futures/_base.py"", line 432, in result
    return self.__get_result()
  File ""/usr/lib64/python3.6/concurrent/futures/_base.py"", line 384, in __get_result
    raise self._exception
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/driver/resultset.py"", line 81, in cb
    f.result()
  File ""/usr/lib64/python3.6/concurrent/futures/_base.py"", line 425, in result
    return self.__get_result()
  File ""/usr/lib64/python3.6/concurrent/futures/_base.py"", line 384, in __get_result
    raise self._exception
  File ""/usr/lib64/python3.6/concurrent/futures/thread.py"", line 56, in run
    result = self.fn(*self.args, **self.kwargs)
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/driver/connection.py"", line 77, in _receive
    self._protocol.data_received(data, self._results)
  File ""/home/ec2-user/neptune/.venv-neptune/local/lib/python3.6/site-packages/gremlin_python/driver/protocol.py"", line 98, in data_received
    ""{0}: {1}"".format(status_code, message[""status""][""message""]))
gremlin_python.driver.protocol.GremlinServerError: 499: {""requestId"":""4e0c4b10-6dac-48b1-9106-cd0cce887972"",""code"":""UnsupportedOperationException"",""detailedMessage"":""Unsupported property value type: java.util.ArrayList""}

Importing string arrays from CSV seems to work.  How can I get this to work with gremlin?"
Amazon Neptune	"Re: Array property values (gremlinpython)
Neptune doesn't support List values for vertex property. Instead Neptune only supports single or set cardinality for vertex properties. Multi valued properties in bulk loader use set cardinality to store the data. Looks like our bulk load documentation refers to this as array type which might be causing some confusion, I will try to get this fixed to correctly refer to that as a set instead.

See here for details on this: https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-differences.html (refer to section about ""Cardinality of Vertex Properties"")

For your query to add multiple properties using set cardinality, you can use a gremlin traversal as follows:
g.addV().property('foo', 'bar').property('foo', 'baz')


Let us know if you find any other issues with this. Thanks."
Amazon Neptune	"Re: Array property values (gremlinpython)
Hi, I am facing an issue regarding cardinality of property values of vertex in Neptune Graph (using Gremlin).I am able to load the data in Neptune using gremlin load format (CSV) successfully.When i query the data i get GraphSON response where each property value is a SET/ARRAY even though there is only one single value, where as ~id and ~label has single string value (I expect this for all the properties). 

As per documentation I have defined headers in my CSV  this way  ""propertyname:type"" without using ""[]"" , so i expected single value property in query response like this { Name : 'Tom' } but instead i get SET/Array value in response like this ""{ Name : }"".

 I want to load the data with single cardinality for all the properties of each Vertex. Is there a way to define single cardinality in property headers of CSV file ??

Edited by: raoManeesh on Nov 10, 2018 1:48 AM

Edited by: raoManeesh on Nov 10, 2018 1:48 AM

Edited by: raoManeesh on Nov 10, 2018 1:49 AM

Edited by: raoManeesh on Nov 10, 2018 1:49 AM"
Amazon Neptune	"Re: Array property values (gremlinpython)
Hi, 

Can you please provide documentation link for the below :
As per documentation I have defined headers in my CSV this way ""propertyname:type"" without using ""[]"" , so i expected single value property in query response like this { Name : 'Tom' } but instead i get SET/Array value in response like this ""{ Name : }"".

Thanking you. 
Apurva Lodha"
Amazon Neptune	"datetime() and gremlin
The docs mention we should store dates using datetime().

https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-differences.html

I can't find any corresponding function in gremlin-javascript. What is the recommendation for storing dates when using node to connect to Neptune? Is there a way to access this function?"
Amazon Neptune	"Re: datetime() and gremlin
Hi there, I also just answered this question on SO at [1] but will replicate what I wrote here for ease of reading.

So the datetime() method that Neptune provides is intended to be used when sending queries to the graph as text Strings. Here is an example from the Gremlin console attached to a running Neptune instance:

gremlin> g.addV('test').property('timestamp',datetime('2018-11-04T00:00:00')).property(id,'t1')
==>v[t1]
gremlin> g.V('t1').valueMap()
==>{timestamp=[Sun Nov 04 00:00:00 UTC 2018]}
gremlin> g.V().has('timestamp',gt(datetime('2018-11-03T00:00:00')))
==>v[t1]


Now, if you are using a GLV language such as Gremlin Python or Javascript, you can use the native date classes provided by the language. In the case of Python you can use the datetime class instead. As shown below. Note while the two examples share the name datetime they are completely different in everything but name. I ran this from a Jupyter Notebook using Gremlin Python but it works equally well in the Python console or as a standalone Python app.

import datetime
g.addV('test').\
    property(id,'x2').\
    property('timestamp',datetime.datetime.now()).next()
 
v[x2]
 
g.V('x2').valueMap(True).next()
 
{<T.label: 3>: 'test',
 <T.id: 1>: 'x2',
 'timestamp': [datetime.datetime(2018, 11, 5, 15, 3, 52, 29000)]}


Please forgive a Python example - I know you are using Javascript. I just happened to have a Python environment configured but the same principles should apply.

All of this said as I and others have mentioned in other posts, I prefer to store timestamps using epoch time. Typically I use 10 or 13 digit integer representations of time depending upon the precision I need. This is also a fairly portable way to store time information and easy to test using greater than/less than predicates etc.

Anyway, I hope this helps clarify your choices a little bit. Cheers, Kelvin.

[1] https://stackoverflow.com/questions/53147594/aws-neptune-datetime

Edited by: Kelvin-AWS on Nov 5, 2018 7:34 AM"
Amazon Neptune	"Gremlin Question about hasId()
Given the following two vertices:
{
    ""@type"": ""g:Vertex"",
    ""@value"": {
        ""id"": ""38b34677-79c5-1ef1-8ce1-ee28a55c6a9b"",
        ""label"": ""shape"",
        ""properties"": {
            ""name"": [
                {
                    ""@type"": ""g:VertexProperty"",
                    ""@value"": {
                        ""id"": {
                            ""@type"": ""g:Int32"",
                            ""@value"": -975946547
                        },
                        ""label"": ""name"",
                        ""value"": ""shapename1""
                    }
                }
            ]
        }
    }
}

and
{
    ""@type"": ""g:Vertex"",
    ""@value"": {
        ""id"": ""80b34677-79cd-8d47-540f-e7d641652326"",
        ""label"": ""shape"",
        ""properties"": {
            ""name"": [
                {
                    ""@type"": ""g:VertexProperty"",
                    ""@value"": {
                        ""id"": {
                            ""@type"": ""g:Int32"",
                            ""@value"": -797902741
                        },
                        ""label"": ""name"",
                        ""value"": ""shapename2""
                    }
                }
            ]
        }
    }
}

and the edge between them,
{
    ""@type"": ""g:Edge"",
    ""@value"": {
        ""id"": ""82b34677-79ce-f7ec-97f8-307647e35435"",
        ""inV"": ""80b34677-79cd-8d47-540f-e7d641652326"",
        ""inVLabel"": ""shape"",
        ""label"": ""child"",
        ""outV"": ""38b34677-79c5-1ef1-8ce1-ee28a55c6a9b"",
        ""outVLabel"": ""shape""
    }
}

why does the following query produce a result
g.V().hasLabel('shape').has('name', 'shapename1').aggregate('shapename1').V().hasLabel('shape').has('name', 'shapename2').aggregate('shapename2').select('shapename1').unfold().both().hasId('80b34677-79cd-8d47-540f-e7d641652326')

but the following query produces no result
g.V().hasLabel('shape').has('name', 'shapename1').aggregate('shapename1').V().hasLabel('shape').has('name', 'shapename2').aggregate('shapename2').select('shapename1').unfold().both().hasId(select('shapename2').unfold().id())

btw, 
g.V().hasLabel('shape').has('name', 'shapename1').aggregate('shapename1').V().hasLabel('shape').has('name', 'shapename2').aggregate('shapename2').select('shapename2').unfold().id()

produces
""data"": {
    ""@type"": ""g:List"",
    ""@value"": [
        ""80b34677-79cd-8d47-540f-e7d641652326""
    ]
}


Edited by: dmoses on Oct 24, 2018 11:53 AM"
Amazon Neptune	"Re: Gremlin Question about hasId()
Hi there, I made a small script to replicate you graph snippet as follows

g.addV('shape').property('name','shapename1').property(id,'38b34677-79c5-1ef1-8ce1-ee28a55c6a9b').as('a').
  addV('shape').property('name','shapename2').property(id,'80b34677-79cd-8d47-540f-e7d641652326').
  addE('child').to('a').iterate()  


I then changed your query slightly as shown below. Rather than expand the bulk set and compare IDs you can just look to see if the vertex is in the set.

gremlin> g.V().hasLabel('shape').has('name', 'shapename1').aggregate('shapename1').V().hasLabel('shape').has('name', 'shapename2').aggregate('shapename2').select('shapename1').unfold().both().where(within('shapename2'))
==>v[80b34677-79cd-8d47-540f-e7d641652326]


If you really wanted to compare the IDs here is one way that you can do it

gremlin> g.V().hasLabel('shape').has('name', 'shapename1').aggregate('shapename1').V().hasLabel('shape').has('name', 'shapename2').aggregate('shapename2').select('shapename1').unfold().both().id().as('a').select('shapename2').unfold().id().where(eq('a'))
==>80b34677-79cd-8d47-540f-e7d641652326


I hope this helps,
Cheers,
Kelvin

Edited by: Kelvin-AWS on Oct 29, 2018 12:55 PM"
Amazon Neptune	"Re: Gremlin Question about hasId()
Hi again, I meant to add this link to the TinkerPop documentation [1]

You will notice that hasId() expects an arbitrary list of objects or a basic predicate. It does not expect a traversal. The net result is that your query was essentially comparing the ID to an object representing the traversal and not the ID itself. I hope that makes sense. If you look at the documentation for the 'where' step in that same file you can see an example of a step that can take a traversal as input.

HTH

[1] http://tinkerpop.apache.org/javadocs/3.3.4/full/org/apache/tinkerpop/gremlin/process/traversal/dsl/graph/GraphTraversal.html#hasId-java.lang.Object...-

Edited by: Kelvin-AWS on Oct 29, 2018 11:58 AM"
Amazon Neptune	"Neptune Performance
Hi, I'm evaluating Neptune for replacing my existing triple store. But I'm finding simple queries really not performant. I'm using a single db.r4.xlarge instance and loaded 1.3GB TTL file containing 41 million triples (around 1.8 million unique subjects) and I ran the following queries:

SELECT (count(*) as ?c)
WHERE {
    ?i ?p ?v.
}


This took 2 minutes to complete. My existing triple store behaves in a similar way - I imagine there's no optimisation around this so it's doing a full scan.

SELECT (count(distinct ?i) as ?c)
WHERE {
    ?i ?p ?v.
}


This threw a MemoryLimitExceededException. This is surprising to me since it is supposed to have 30GB of memory. Any ideas why it behaves like that?"
Amazon Neptune	"Re: Neptune Performance
Hi,

Thanks for reaching out Neptune team.

What version of Neptune are you running on?

From version 237 this issue should be fixed: https://docs.aws.amazon.com/neptune/latest/userguide/engine-releases-1.0.1.0.200237.0.html

Let us know whether you are still facing the issue, if so we will investigate further.

Thanks
Simone"
Amazon Neptune	"Re: Neptune Performance
Hi,

I don't know how to check the precise engine release. On the AWS Console it says I'm on Neptune 1.0.1.0. I currently have ""Auto minor version upgrade"" enabled. If I click ""Modify"" and select Neptune-1.0.1.0.200237.0 as the DB engine version, then click Continue, the summary of modifications is empty. So I guess I'm on the latest version.

And yes despite that I still get the MemoryLimitExceededException for the count distinct query."
Amazon Neptune	"Re: Neptune Performance
Hello

Regarding query#2, we would like to analyze your instance. Please file a ticket using AWS support so that we can have get your instance ID and other details in a secure manner. 

Query#1 is a full scan query. Neptune only supports exact counts at this stage and such a query reads everything from the database. We are working towards optimizing it but at the end of the day a count-all query is going to be slow. As an aside, would approximate counts fulfill your use case or does your use case require exact count?"
Amazon Neptune	"Re: Neptune Performance
Hi,

Thanks for the advice. I'll submit a ticket.

For a full count like that (including count distinct), with no constraint on the pattern, an estimate is fine for me. But if I specify any patterns, filters, my typical use cases for these require them to be accurate. Hope that helps?"
Amazon Neptune	"Personalized PageRank on Neptune
I'm looking to run Personalized Page Rank on my Neptune instance.  It initially seemed that this could be accomplished via TinkerPop's `PageRankVertexProgram,`but this doesn't appear to be supported out-of-the-box due to its reliance on the VertexProgram bindings.  Does anyone have experience with running PPR on a Neptune graph?"
Amazon Neptune	"Re: Personalized PageRank on Neptune
Neptune does not support VertexPrograms at this time.  You'll need to actually implement the PR algorithm using the standard non-GraphComputer Gremlin API."
Amazon Neptune	"How to increase the AWS Neptune's database performance?
Hi all,

My objective is to evaluate AWS Neptune versus other popular RDF databases. I selected the BSBM benchmark (see [1]) because it has simple functional requirements backed by a good scientific methodology.

My test setup is fairly basic:


Setup AWS Neptune instance of type db.r4.large without replicas or scheduled maintenance and default parameters
Load the BSBM 100M file from an S3 bucket as it's described in [2]
Run the BSBM client from an EC2 server hosted in the same region like the Neptune database


The initial bulk load of the 100M RDF triples took 12'149 seconds. Once all data was ready, I started the simplest test - a single read client executes a sequence of pseudo-random query mixes composed of 12 SPARQL read queries (BSBM Explore use case). The final benchmark score was barely 2'679.15 QMpH.

What are all possible options to speed up the Neptune's performance?

Cheer,

[1] http://wifo5-03.informatik.uni-mannheim.de/bizer/berlinsparqlbenchmark/
[2] https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-data.html"
Amazon Neptune	"Re: How to increase the AWS Neptune's database performance?
Hi vmom,

There is a couple of brute force ways to get better throughput. 

I am assuming that you are running your experiment with 1 client thread, so you are likely to be underutilizing your db.r4.large . For this instance type running the BSBM workload you are likely to get best throughput with 4 client threads.

There is also the possibility of using more powerful hardware. Neptune scales up, at least on BSBM, almost ""linearly"", so upgrading to db.r4.xlarge, with 8 client threads  correspondingly, is expected to double the throughput. 

Anyways, I am curious about the benchmark config you used in your test. Can you provide more details? 
(1) Are you using the standard BSBM query mix bsbmtools-0.2/queries/explore/querymix.txt (1 2 2 3 2 2 4 2 2 5 7 7 5 7 7 8 9 9 8 9 9 10 10 11 12) without any queries ignored via bsbmtools-0.2/queries/explore/ignoreQueries.txt ? 
(2) Can you confirm that you run the client with 1 thread?

Cheers,"
Amazon Neptune	"Problem with '{ }' in the node value. Escaping does not work.
This simple query fails
g.addV(""Test 2"").property(single, ""title"", 'a {')


ValueError: unexpected '{' in field name"
Amazon Neptune	"Re: Problem with '{ }' in the node value. Escaping does not work.
Hi Srinath2,

To help reproduce this issue, could you provide some details to the following questions?


WebSocket or Http?
Gremlin Console or Gremlin Driver (If driver please specify which language)?


Thanks,
Dan"
Amazon Neptune	"Re: Problem with '{ }' in the node value. Escaping does not work.
Apologies, I faced it in Python, but unable to re-create it. might be something wrong on my end."
Amazon Neptune	"Stuck on LOAD_NOT_STARTED for hours
I successfully ingested ~10,000 csv files containing vertices. After that finished, I tried to kick off a job with around ~60,000 csv files containing edges.

The format of the files is seemingly fine, as this had worked fine with a subset of the data.

However, the job was stuck with ""feedCount"": { ""LOAD_NOT_STARTED"":  ~60,000 } for hours, I cancelled and tried with a smaller number (around 3000), and the same situation occurred. 

The cluster doesn't seem to be busy, so I'm not sure what's going on."
Amazon Neptune	"Re: Stuck on LOAD_NOT_STARTED for hours
Hello,

Could you please cut us a support ticket through the AWS console?  That way we can get more details on your situation and have correspondence over a secure channel.

Thanks,
Dan"
Amazon Neptune	"Connect neptune using Node
Hi, i'm trying to connect to a neptune cluster using node, following the steps defined here:

https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-node-js.html

Unfortunately I'm getting this error:

Error: socket hang up
    at createHangUpError (_http_client.js:331:15)
    at Socket.socketOnEnd (_http_client.js:423:23)
    at emitNone (events.js:111:20)
    at Socket.emit (events.js:208:7)
    at endReadableNT (_stream_readable.js:1064:12)
    at _combinedTickCallback (internal/process/next_tick.js:138:11)
    at process._tickCallback (internal/process/next_tick.js:180:9)

I've checked the connection is ok by using gremlin console, following these steps
https://docs.aws.amazon.com/neptune/latest/userguide/iam-auth-connecting-gremlin-console.html

Do i need to set the aws credentials in my node example to connect to the cluster?"
Amazon Neptune	"Re: Connect neptune using Node
Hi javier-garcia-garcia,  

Yes, you would need to use the AWS credentials to sign the requests in your Node.js code. The example you are using from https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-node-js.html would only work when IAM Authentication is not enabled on the DB cluster.

Please follow the instructions here - https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html. There is also a specific example documention for Node.js as well - https://docs.aws.amazon.com/general/latest/gr/signature-v4-examples.html#signature-v4-examples-javascript.

Please let us know if you have any further questions."
Amazon Neptune	"Re: Connect neptune using Node
Hi there

Maybe my question wasn't clear, but i'm trying to connect by websocket, not http
Looking at the examples, seems that Signature Version 4 is used to update the http request, but I'm not sure how to apply that to websocket connections"
Amazon Neptune	"Re: Connect neptune using Node
Hello there,

Any update on this? I agree that the answer provided is useful for HTTP, but not valid for WebSocket.
Could an example be provided for authenticating via web socket?

Thanks!"
Amazon Neptune	"Re: Connect neptune using Node
Hi javier-garcia-garcia, carlos-moreno -

SigV4 over web socket works very similar to SigV4 over HTTP. The web socket handshake is a normal HTTP request, with a 'Connection: Upgrade', that negotiates an upgrade to web socket. You would need to sign that handshake request with SigV4 to establish the connection, if IAM Auth is enabled on your cluster. Post connection establishment, future web socket messages do not need to be signed. 

Feel free to take a look at our Java module (https://github.com/aws/amazon-neptune-gremlin-java-sigv4) for this. It uses a custom WebsocketHandshaker, which signs the request using SigV4. Here are some references:

Channelizer: https://github.com/aws/amazon-neptune-gremlin-java-sigv4/blob/master/src/main/java/org/apache/tinkerpop/gremlin/driver/SigV4WebSocketChannelizer.java#L204-L211 

Handshaker: https://github.com/aws/amazon-neptune-gremlin-java-sigv4/blob/master/src/main/java/com/amazon/neptune/gremlin/driver/sigv4/AwsSigV4ClientHandshaker.java#L88-L90

You would need to do something similar on the JS Gremlin client.

Hope this helps. Let us know if you have other questions.
Karthik"
Amazon Neptune	"Re: Connect neptune using Node
Hi there

I've managed to sign the websocket connection, by passing the authorization header and the X-Amz-Date header, but i'm still getting the same issue

I'm generating the headers in the same way that i do when i connect by http, using the library aws4.
For http is working correctly, but with websocket no

Shall i sign in a different way?"
Amazon Neptune	"Poor subgraph/spanning tree performance (gremlinpython)
Using gremlinpython, we're seeing slowdowns as the number of selected vertices increases up to about 20, after which the Neptune backend starts emitting internal server errors.

Calculating a spanning tree for 4-5 nodes is fine, takes several seconds for 10, and becomes unusable beyond 20.  Our test dataset is about 600k nodes and 1.4MM edges, using a r4.large instance.

vin_names = [...]
tree = g.V( vin_names ).bothE().where( otherV().has( T.id, P.within(vin_names) )).toList()
subgraph = g.V( vin_names ).bothE().subgraph('sub_g').bothV().cap('sub_g').next()

Am I poorly expressing the gremlin query?  What limits am I running into?

Edited by: technomage on Sep 10, 2018 11:54 AM"
Amazon Neptune	"Re: Poor subgraph/spanning tree performance (gremlinpython)
Hello, I believe there is a limitation in the Python implementation of the subgraph step in that it will return the entire subgraph to you as JSON data rather than just create a new traversal source object. You could try using SubgraphStrategy instead.

Here is a simple example of creating a SubgraphStrategy:

g2 = g.withStrategies(SubgraphStrategy(__.has(""region"",""Texas"")))

This would create a subgraph only containing vertices (and the connecting edges) that have a ""region"" property of ""Texas""

Cheers
Kelvin

Edited by: Kelvin-AWS on Sep 10, 2018 6:43 PM"
Amazon Neptune	"Export data
I can find no documentation on how to export data from Neptune. I am especially interested in exporting sub-graphs of potentially large size. How would one go about doing that in Neptune?"
Amazon Neptune	"Re: Export data
Hi,

As of today, there is no inbuilt support for data export in Neptune. We do have this feature in our product backlog, though we don't yet have a firm timeline. Only way you can export data is storing query result from gremlin/sparql query. 

We would like to know more about your use case for exporting data from database instance.

Edited by: AnkitGuptaAtAWS on Sep 6, 2018 9:41 PM"
Amazon Neptune	"SSL support for Gremlin?
Hello,

We've attempted to connect via Java/Gremlin using SSL.  It appears that Neptune's Gremlin server does not have SSL enabled?  Is this correct and if so, is there an ETA for SSL?  We found it a bit surprising that the traffic wasn't encrypted on the wire.

Thanks."
Amazon Neptune	"Re: SSL support for Gremlin?
Hi,

We plan to provide an update to enable support for TLS-based encryption-in-transit NLT Q4. This will provide support for both Gremlin, SPARQL, and the REST API for managing Neptune.

Thanks, --Brad"
Amazon Neptune	"Re: SSL support for Gremlin?
Excellent.  Thanks for the quick response."
Amazon Neptune	"HIPAA Compliance w/ Neptune
I'm very interested in utilizing Neptune for healthcare related use cases, and I was curious if there are plans to make Neptune available as a HIPAA Eligible Service https://aws.amazon.com/compliance/hipaa-eligible-services-reference/?"
Amazon Neptune	"Re: HIPAA Compliance w/ Neptune
Hi Steve,

Neptune is not yet achieved HIPAA eligibility, but we do have it on our roadmap as a priority. We're working to finalize the date.

Thanks, --Brad"
Amazon Neptune	"Re: HIPAA Compliance w/ Neptune
Hi Steve,

Neptune is now is listed on the AWS BAA as a HIPAA Eligible Service: https://aws.amazon.com/compliance/hipaa-eligible-services-reference/.

Thanks, --Brad"
Amazon Neptune	"Regex support in neptune
Does neptune support regex for traversal, something like JanusGraph supports.
http://kelvinlawrence.net/book/Gremlin-Graph-Guide.html#_regular_expression_predicates"
Amazon Neptune	"Re: Regex support in neptune
Hi Amit,

No, today, we don't support regex operations in Neptune. For SPARQL users, we do support the full set of SPARQL 1.1 Query string functions."
Amazon Neptune	"Re: Regex support in neptune
Is regex support in the backlog?  If not, is this something that might be considered.  This could be a significant issue for us and also we'd be much more likely to use Neptune if we could search properties via regex.  Thanks."
Amazon Neptune	"Re: Regex support in neptune
Hi,

Yes, we do have this in our product backlog, though we don't yet have a firm timeline.

Thanks, --Brad"
Amazon Neptune	"Neptune simple traversals performance
Hi, we're assessing the introduction of Neptune as a backend for a service, so far we're creating a very simple graph: (offers)-->(contents)<--(assets), we've preloaded a bunch of Vertices and Edges to start getting familiar with the Gremlin Traversals queries.

In total we've loaded ~200K Vertices and ~200K Edges distributed like:
Vertex:
==>{offers=30015, assets=60017, contents=100024}

Edge:
==>{SCOPED_TO=60005, CHILD_OF=60001, ASSET_FOR=60014, DESCRIBED_BY=30009}


This doesn't seem to be a huge amount of data just to be representative of the high volume we're expecting to include but it helps us to understand the baselines of each cluster type.

We've run the following set of queries on a db.r4.large cluster, also on a dedicated read replica with similar results

Query: {""gremlin"":""g.V().count()""} [statusCode: 200]
responseTime: 0.840627908706665 ms
 
Query: {""gremlin"":""g.V().label().groupCount()""} [statusCode: 200]
responseTime: 8.131423711776733 ms
 
Query: {""gremlin"":""g.E().count()""} [statusCode: 200]
responseTime: 0.31768083572387695 ms
 
Query: {""gremlin"":""g.E().label().groupCount()""} [statusCode: 200]
responseTime: 3.4964730739593506 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').count()""} [statusCode: 200]
responseTime: 0.3855419158935547 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').limit(100).valueMap()""} [statusCode: 200]
responseTime: 0.26479101181030273 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').skip(100).limit(100).valueMap()""} [statusCode: 200]
responseTime: 0.2595646381378174 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').skip(10000).limit(100).valueMap()""} [statusCode: 200]
responseTime: 0.278397798538208 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').has('type','episode').limit(100).valueMap()""} [statusCode: 200]
responseTime: 0.31923508644104004 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').not(__.has('type','episode')).limit(100).valueMap()""} [statusCode: 200]
responseTime: 0.28130197525024414 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').order().by(id).limit(100).valueMap()""} [statusCode: 200]
responseTime: 2.0613651275634766 ms
 
Query: {""gremlin"":""g.V().hasLabel('contents').order().by('ref').limit(100).valueMap()""} [statusCode: 500]
responseTime: 1.7741460800170898 ms


In summary:

the groupCounts for all Vertex/Edge take consistently a few seconds with no benefit on subsequent requests.
order().by(id) works well considering the amount of data but when using a different property, it fails with a 500 error.


Are we doing something wrong? is there anything we can make in the traversals to improve the performance? 

We can definitely scale up and add more read replicas, but for now we want to understand what are the KPIS of each instance so we can decide how to partition the data across multiple clusters if required. Do you have any extra information about current expected limits per instance type?

Neptune's FAQs mention that indexing is not required, is it happening ""automagically"" based on request patterns? can we enforce that somehow?

Many thanks in advance,
Caye"
Amazon Neptune	"Re: Neptune simple traversals performance
In addition to the above, we also observe a degradation in the time it takes to add an edge between two vertices as the graph size grows.

Using the traversal:

g.V().has(id, ""v2"").as(""to"").V().has(id, ""v1"").addE(""relates_to"").to(""to"").next()


When there are a couple of hundred each of vertices and edges the time to add the edge is negligible compared to the round-trip time for the request (~50ms total).  

Once we hit ~10000 each of vertices and edges this has degraded to ~80ms.  

Once we hit the size of the graph described above adding an edge between two vertices takes 3s.

It's worth noting the lookup of the vertices by id remains constant (as you'd hope), it seems to be the addE
 operation that suffers.

Any insights would be appreciated."
Amazon Neptune	"Re: Neptune simple traversals performance
Apologies for late reply on this.

We are actively working on optimizing groupCount step's performance and fix will be available in future release (will share ETA soon). 
When you tried the order with a different property other than id, are you seeing timeouts from the server?

Regarding indexing, there is no need to explicitly specify that. Neptune automatically creates indices for all properties in the graph. 

And lastly, we do not expect the performance to degrade dramatically when you are adding an edge between two vertices. There is a performance drop as your graph grows larger than the working set of process, it will take longer to fetch pages to memory. I will reach out to you privately to get more information on this so we can investigate further.

Edited by: sainathm-aws on Aug 23, 2018 4:26 PM"
Amazon Neptune	"Re: Neptune simple traversals performance
sainathm-aws wrote:
Apologies for late reply on this.

We are actively working on optimizing groupCount step's performance and fix will be available in future release (will share ETA soon). 
When you tried the order with a different property other than id, are you seeing timeouts from the server?


Hi, not a timeout, it returns a failure like:
{
  ""code"": ""InternalFailureException"",
  ""detailedMessage"": ""An unexpected error has occurred in Neptune."",
  ""requestId"": ""e8b2c2a0-65e3-710d-fbb7-3e828cb3fdb4""
}"
Amazon Neptune	"Re: Neptune simple traversals performance
Hi Caye,

Thanks for providing further information about the 500 error. I suggest you open a support case with us such that we can look further into the error.

You can create a support ticket by visiting the support center (https://console.aws.amazon.com/support/home) from your AWS account.

Thanks,
Kunal."
Amazon Neptune	"timestamp via gremlin tinkerpop
Hello,

I'd like to set a property to a current millisecond epoch-type timestamp.

In gremlin, System.currentTimeMillis() is available locally, but when I'm sending commands to my remote Neptune instance, this then doesn't work.  Is there a way to have Neptune set a property to the current epoch time, something like this:

g.addV(""MyThing"").property(""currtime"",<someFunctionHereForTime>)

Edited by: Libhart on Aug 30, 2018 5:11 AM"
Amazon Neptune	"Re: timestamp via gremlin tinkerpop
I'm sorry but Neptune does not accept function calls or lambdas within traversals due to security concerns.  We will can however add your request for a custom ""currentTime()"" operator as a Neptune language extension to our backlog.

Thanks,
Mike"
Amazon Neptune	"Feature Request: Native Neptune Client for Lambda
Something like the dynamo api...

const { Neptune } = require('aws-sdk');
const Client = Neptune.gremlin.Client;
const Graph = Neptune.gremlin.structure.Graph;
 
exports.handler = (event, context, callback) => {
  db = new Client({clusterName: 'my_cluster'});
  ...
}"
Amazon Neptune	"Re: Feature Request: Native Neptune Client for Lambda
Here's an example for a lambda that accesses Neptune in python:

from __future__  import print_function  # Python 2/3 compatibility
import boto3
import os
from gremlin_python import statics
from gremlin_python.structure.graph import Graph
from gremlin_python.process.graph_traversal import __
from gremlin_python.process.strategies import *
from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection
 
CLUSTER_ENDPOINT = os.environ['CLUSTER_ENDPOINT']
CLUSTER_PORT = os.environ['CLUSTER_PORT']
CLUSTER_IDENTIFIER = os.environ['CLUSTER_IDENTIFIER']
 
def run_sample_gremlin_code():
    print('running sample gremlin code')
    graph = Graph()
    g = graph.traversal().withRemote(DriverRemoteConnection('ws://' + CLUSTER_ENDPOINT + "":"" + CLUSTER_PORT + '/gremlin','g'))
    print(g.V().limit(2).toList())
 
 
def lambda_handler(event, context):
    print(event)
    print('hello from lambda handler')
 
    ## run gremlin query
    if CLUSTER_ENDPOINT and CLUSTER_PORT:
        run_sample_gremlin_code()
    else:
        print(""provide CLUSTER_ENDPOINT and CLUSTER_PORT environment variables"")
 
if __name__ == ""__main__"":
    event = { 'RequestType': 'test'}
    lambda_handler(event, None)


Best,
Michael"
Amazon Neptune	"Lambda Example to access Neptune - getting timed out
I have a lambda function gremlin-neptune-test which uses the handler function example in the below link to access the neptune cluster
https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin-node-js.html 

It is getting timed out with the error 
{
  ""errorMessage"": ""2018-06-21T15:03:01.060Z 2efb4aa1-7564-11e8-85a2-6df375420349 Task timed out after 3.00 seconds""
}

The lambda is in the same VPC with same subnet and security group (has inbound traffic opened for port 8182) as that of the neptune cluster. Also, I added an inline policy ""neptune-db:*"" to the role being used by lambda.

Please let me know what am I missing

Edited by: muralikr on Jun 21, 2018 8:08 AM"
Amazon Neptune	"Re: Lambda Example to access Neptune - getting timed out
Hi muralikr,

Could you verify whether that error message came from the Neptune call you made within your Lambda function or directly from Lambda?  On a cursory look it actually looks like that message is coming from Lambda after reaching the execution timeout (default being 3 seconds).  Your Lambda function may actually have no problem establishing a connection to Neptune but just couldn't finish its logic within the allotted time.  Could you try extending the execution timeout and see what response you're getting back from Neptune?

Thanks,
Dan"
Amazon Neptune	"Re: Lambda Example to access Neptune - getting timed out
Hi Dan, 

Thank for the reply. I did try increasing but still it's showing the same error

{
  ""errorMessage"": ""2018-06-21T23:47:00.849Z 17d77c8a-75ad-11e8-88bb-135a867b4be3 Task timed out after 120.10 seconds""
}"
Amazon Neptune	"Re: Lambda Example to access Neptune - getting timed out
Thank you, it was the issue with the security group.. inbound traffic was opened to the public SG instead of the private SG (was assigned to neptune cluster)"
Amazon Neptune	"Re: Lambda Example to access Neptune - getting timed out
."
Amazon Neptune	"Server continually restarting
While loading data and performing some queries, the neptune server crashed.  
Aside from the following events, I can't see any way to get more information on the cause of the failure or any way to remedy it.  The resource is arn:aws:rds:us-east-1:443155816678:cluster:neptune-poc.

Mon Aug 20 16:06:47 GMT-400 2018	Error restarting database: Unable to write config file: my.cnf
Mon Aug 20 16:05:36 GMT-400 2018	Error restarting database: Unable to write config file: my.cnf
Mon Aug 20 16:04:36 GMT-400 2018	Error restarting database: Unable to write config file: my.cnf
Mon Aug 20 16:03:39 GMT-400 2018	Error restarting database: Engine bootstrap failed with no database process running...
Mon Aug 20 16:03:25 GMT-400 2018	Error restarting database: Waited 60000 for graphdb plugin to start, but it is still working...
Mon Aug 20 16:02:19 GMT-400 2018	DB instance restarted
Mon Aug 20 16:02:01 GMT-400 2018	Error restarting database: Waited 60000 for graphdb plugin to start, but it is still working...
Mon Aug 20 16:00:56 GMT-400 2018	DB instance restarted
Mon Aug 20 16:00:34 GMT-400 2018	Error restarting database: Waited 60000 for graphdb plugin to start, but it is still working...
Mon Aug 20 15:58:58 GMT-400 2018	DB instance restarted


Edited by: technomage on Aug 20, 2018 1:52 PM"
Amazon Neptune	"Re: Server continually restarting
Hi,

Thanks for reporting this issue.

The root cause has been detected and fixed. Your instance is now healthy.

Sorry for the inconvenience.

Thanks
Simone"
Amazon Neptune	"Re: Server continually restarting
Do you have any information about what caused the issue or how I might avoid it in the future?"
Amazon Neptune	"Re: Server continually restarting
Hi technomage,

The repeated crashes were caused by excessive logging that was filling up the logging partition. Specifically, the logging was caused by malformed data sent to the bulk-loader.

We identified the root cause which will be fixed in the next Neptune release.

Thanks
Simone"
Amazon Neptune	"MemoryLimitExceededException when I a big query
When I run a big query that runs for like 5mins in Neptune, I get `MemoryLimitExceededException`.

I am using the most basic Neptune package. So what are the performance Benchmarks for Neptune? ie. for basic plan after what kind of usage will query fail?"
Amazon Neptune	"Re: MemoryLimitExceededException when I a big query
Hello, could you please post a sample query that shows what you were trying to do when you ran out of memory. Also could you please describe in high level terms how big your graph is, for example how many vertices, edges and properties (rough approximation).

I assume from your post that you are using a db.r4.large instance type?

Kind regards,
Kelvin."
Amazon Neptune	"How do we escape single quotes for use with gremlin post endpoint
How can I send a query through the endpoint for data that includes a single quote? The following attempts failed.
Two single quotes
{""gremlin"":""g.V().hasLabel('map').has('name', 'big garbage data''s')""}
 
""detailedMessage"":""Query parsing failed at line 1, character position at 52, error message : no viable alternative at input 'g.V().hasLabel('map').has('name','big garbage data''s''"",""code"":""MalformedQueryException""


Just a single quote
{""gremlin"":""g.V().hasLabel('map').has('name', 'big garbage data's')""}
 
""detailedMessage"":""Exception processing a script on request [g.V().hasLabel('map').has('name', 'big garbage data's')]."",""code"":""InternalFailureException""


Escape with a backslash
{""gremlin"":""g.V().hasLabel('map').has('name', 'big garbage data\'s')""}
 
""detailedMessage"":""body could not be parsed"",""code"":""InvalidParameterException""


Three single quotes
{""gremlin"":""g.V().hasLabel('map').has('name', 'big garbage data'''s')""}
 
""detailedMessage"":""Exception processing a script on request [g.V().hasLabel('map').has('name', 'big garbage data'''s')]."",""code"":""InternalFailureException""


No single quotes
{""gremlin"":""g.V().hasLabel('map').has('name', 'big garbage datas')""}
 
""status"":{""message"":"""",""code"":200,""attributes"":{""@type"":""g:Map"",""@value"":[]}},""result"":{""data"":{""@type"":""g:List"",""@value"":[]},""meta"":{""@type"":""g:Map"",""@value"":[]}"
Amazon Neptune	"Re: How do we escape single quotes for use with gremlin post endpoint
Try this:
{""gremlin"":""g.V().hasLabel('map').has('name', 'big garbage data\\'\\'s')""}


Explanation:
The server parses the query string as per the groovy syntax and hence, expects the single quote to be escaped in the string. The second slash escapes the first slash which lets the shell know that it should escape the slash and send the slash to the server."
Amazon Neptune	"Re: How do we escape single quotes for use with gremlin post endpoint
Thank you!
{""gremlin"":""g.addV('dougnode').property('name','big al\\'s').property('hash_id','randomhashid')""}

produced
""value"": ""big al's"",
""label"": ""name"""
Amazon Neptune	"Setting custom ID/label with gremlin
I've done some bulk imports setting ~id using CSV files.
Is there any way to set ~id using gremlin (I'm using gremlinpython)?
The optional `g.addV(https://forums.aws.amazon.com/)` only sets an optional label, not the ID, and results in a generated UUID.  I'd like to continue setting custom IDs but would prefer not to rely on the bulk loader whenever I want to create an edge or vertex."
Amazon Neptune	"Re: Setting custom ID/label with gremlin
You can use the enum T to specify a custom id (See here: http://tinkerpop.apache.org/docs/current/reference/#_static_enums_and_methods).
g.addV('https://forums.aws.amazon.com/').property(T.id, 'forums')

Let us know if you notice any other issues with this."
Amazon Neptune	"Re: Setting custom ID/label with gremlin
Thank you.  I couldn't find that in the Neptune documentation."
Amazon Neptune	"Re: Setting custom ID/label with gremlin
While this sets the ~id property, and enables vertex lookup by ~id (`V('foo')`), the default string representation for the node still shows a generated UUID.  Is there any way around that other than to do a CSV import?"
Amazon Neptune	"Re: Setting custom ID/label with gremlin
Never mind, I was trying to update an existing node.  Custom ID works fine."
Amazon Neptune	"How to escape $ symbol?
Tried to add a property that contains $

gremlin> g.V('some-node-id').property(""money"", ""10 $"")
groovysh_parse: 1: illegal string body character after dollar sign;
   solution: either escape a literal dollar sign ""\$5"" or bracket the value expression ""${5}"" @ line 1, column 72.
   ').property(""money"", ""10 $"")



So I escaped the $ symbol

gremlin> g.V('some-node-id').property(""money"", ""10\$"")
{""requestId"":""xyz"",""code"":""MalformedQueryException"",""detailedMessage"":""Query parsing failed at line 1, character position at X, error message : token recognition error at: '$'""}
Type ':help' or ':h' for help.


Try a basic escaping, that worked fine

gremlin> g.V('some-node-id').property(""money"", ""10\"""")
==>v[some-node-id]



Double the escape $ since Neptune has gone crazy

gremlin> g.V('some-node-id').property(""money"", ""10\\$"")
groovysh_parse: 1: illegal string body character after dollar sign;
   solution: either escape a literal dollar sign ""\$5"" or bracket the value expression ""${5}"" @ line 1, column 72.
   ').property(""money"", ""10\\$"")
                                 ^



Whats wrong in my query?"
Amazon Neptune	"Re: How to escape $ symbol?
Hi

Thanks for reporting this issue. 

The workaround for this problem is to use single quotes around the string where you are adding the $ sign. For example:

gremlin> g.addV(""Animal"").property(id,""simba"")
==>v[simba]
gremlin> g.V('simba').property('money','$123')
==>v[simba]
gremlin> g.V().has('money','$123')
==>v[simba]
gremlin> g.V('simba').property('new_money','123 $10')
==>v[simba]


However, I do understand that it should work with the double quotes as well after you escape the $ sign. This is a bug in our parser and we are actively working on a fix.

Further I should note that the bug only impacts the clients written in groovy language which send queries as strings e.g. gremlin console. GLVs (Java/Python/DotNet/JS) and other string-based clients where the '$' character is not a reserved character will work just fine.

Regards,
Divij

Edited by: divijaws on Aug 10, 2018 3:26 PM"
Amazon Neptune	"Re: How to escape $ symbol?
Do you guys have a timeline for when is this fix going to be live? Is there any bug tracker to keep track of the status?"
Amazon Neptune	"Re: How to escape $ symbol?
We do not have a timeline right now. Most of our bug fixes are reflected in the  release notes:https://docs.aws.amazon.com/neptune/latest/userguide/engine-releases.html we publish with every release.

Meanwhile, you can use the workaround using single quotes to solve the issue."
Amazon Neptune	"Does Neptune Support Multi-tenant Graphs ?
Hi,

We are looking for support of multi-tenant graphs within the Neptune database. We have been unable to find any documentation related to the same with Neptune.
Gremlin supports the same with ""Partition Strategy"" (http://tinkerpop.apache.org/javadocs/3.1.3/full/org/apache/tinkerpop/gremlin/process/traversal/strategy/decoration/PartitionStrategy.html ) .we tired the same with Neptune. However, while the write succeeds and the reads fail to get back any result.

The use case that we are trying to support is we are a company which has multiple customers and we want to store data for multiple customers but with a  logical separation. Since spawning multiple Neptune instances is infeasible from cost and maintenance perspective.

Regards
Shyamal"
Amazon Neptune	"Re: Does Neptune Support Multi-tenant Graphs ?
Hello,

You can create only one graph in the property graph data model for Neptune. One potential option would be to use RDF data model for your use case. It provides the functionality to have named graphs as part of your data model. 

Regarding Partition Strategy, let me get back to you in a couple of days."
Amazon Neptune	"Re: Does Neptune Support Multi-tenant Graphs ?
+1 for the multitenant feature request"
Amazon Neptune	"Re: Does Neptune Support Multi-tenant Graphs ?
Already answered:

Multiple graphs in single Neptune cluster / instances
https://forums.aws.amazon.com/thread.jspa?threadID=283542&tstart=25

Different TinkerPop TraversalStrategy support in Neptune.
https://forums.aws.amazon.com/thread.jspa?threadID=284846&tstart=0"
Amazon Neptune	"Neptune loader seems to give inaccurate ""totalRecords"" value
I generated 4 csv files that contained a total of 15 million rows. I ran the loader and loaded them into Neptune. Loader status showed that there were 45 million rows loaded which was both confusing and concerning.
awscurl http://dev-rsx-shapes-neptuneinstance-01.c6ysfbkulnjt.us-east-1.neptune.amazonaws.com:8182/loader/24868d74-195f-4311-a717-79d76cafd42d --service neptune-db
{
    ""status"" : ""200 OK"",
    ""payload"" : {
        ""feedCount"" : [
            {
                ""LOAD_COMPLETED"" : 5
            }
        ],
        ""overallStatus"" : {
            ""fullUri"" : ""s3://dev-rsx-shapes-us-east-1-056684691971/prod/shapes/graph/vertices/"",
            ""runNumber"" : 1,
            ""retryNumber"" : 0,
            ""status"" : ""LOAD_COMPLETED"",
            ""totalTimeSpent"" : 5714,
            ""totalRecords"" : 45000000,
            ""totalDuplicates"" : 189506,
            ""parsingErrors"" : 0,
            ""datatypeMismatchErrors"" : 0,
            ""insertErrors"" : 0
        }
    }
}
 
""gremlin"":""g.V().hasLabel('shape').count()""
 
{""requestId"":""10b27b71-8812-fe26-d3d4-dbb54ce8ec36"",""status"":{""message"":"""",""code"":200,""attributes"":{""@type"":""g:Map"",""@value"":[]}},""result"":{""data"":{""@type"":""g:List"",""@value"":{""@type"":""g:Int64"",""@value"":15000000}},""meta"":{""@type"":""g:Map"",""@value"":[]}}}


Edited by: dwmoses on Aug 1, 2018 2:06 PM"
Amazon Neptune	"Re: Neptune loader seems to give inaccurate ""totalRecords"" value
Hi,

The output of the bulk loader reports total number of labels and properties that have been loaded for the nodes and edges in the bulk load. In the example above, the Gremlin count() reports the number of vertices that have the label ""shape"". 

We have heard from customers that this difference can be confusing, and we are working on improving the output of the bulk loader.

Thanks, --Brad

Edited by: bradbataws on Aug 7, 2018 9:20 AM"
Amazon Neptune	"Different TinkerPop TraversalStrategy support in Neptune.
Hello,
Can you pleas give us list of different TraveralStrategy (Link 1) per TinkerPop specification that are supported by Neptune? e.g. I'm interested in EventStrategy, PartitionStrategy and SubgraphStrategy and would be great if we can simple examples using Netpune for these.

I tried following using Gremline Console with remote commands and getting errors as it's using variables. But are there are ways to use these strategies without variable on remote console?

gremlin> g = TinkerGraph.open().traversal()
==>graphtraversalsource[tinkergraphhttps://forums.aws.amazon.com/
gremlin> g.addE('link').
......1>     from(addV('parent')).
......2>     to(addV('child')).
......3>   V().valueMap(true)
==>https://forums.aws.amazon.com/
==>https://forums.aws.amazon.com/

2 vertices, no properties. Now let's say we want to propagate changes of a 'shared' property from any parent to its children. For that, we need a MutationListener and an EventStrategy:

gremlin> l = new org.apache.tinkerpop.gremlin.process.traversal.step.util.event.MutationListener() {
void edgeAdded(Edge edge) { }
void edgePropertyChanged(Edge element, Property oldValue, Object setValue) { }
void edgePropertyRemoved(Edge element, Property property) { }
void edgeRemoved(Edge edge) { }
void vertexAdded(Vertex vertex) { }
void vertexPropertyPropertyChanged(VertexProperty element, Property oldValue, Object setValue) { }
void vertexPropertyPropertyRemoved(VertexProperty element, Property property) { }
void vertexPropertyRemoved(VertexProperty vertexProperty) { }
void vertexRemoved(Vertex vertex) { }
void vertexPropertyChanged(final Vertex element, final Property oldValue, final Object setValue, final Object... vertexPropertyKeyValues) {
   if (oldValue.key().equals(""shared"")) {
        g.V(element).out(""link"").property(""shared"", setValue).iterate()
   }
 }
}

==>groovysh_evaluate$1@27b000f7
gremlin> s = EventStrategy.build().addListener(l).create()
==>EventStrategy

The MutationListener will only care about vertex-property change events. Whenever a 'shared' property is set or mutated, it will propagate the same value to all children.

gremlin> g.withStrategies(s).V().hasLabel('parent').property('shared', 2).iterate()
gremlin> g.V().valueMap(true)
==>[id:0,shared:https://forums.aws.amazon.com/
==>[id:1,shared:https://forums.aws.amazon.com/

Link 1: http://tinkerpop.apache.org/docs/current/reference/#traversalstrategy"
Amazon Neptune	"Re: Different TinkerPop TraversalStrategy support in Neptune.
Hi,

I am looking into this and will get back to you in a couple of days.

Thanks for your patience."
Amazon Neptune	"Re: Different TinkerPop TraversalStrategy support in Neptune.
Hi,
Do you have any update on this thread?
Also it will be nice if you can list different traversal strategies that are supported by Neptune.

Many thanks.
Shahid"
Amazon Neptune	"Re: Different TinkerPop TraversalStrategy support in Neptune.
I'm very interested in this as well. I currently use SubgraphStrategy extensively to not have to manually add `has` steps that apply to all of my edges. I can work around this at the application level but this would be a very useful feature."
Amazon Neptune	"Re: Different TinkerPop TraversalStrategy support in Neptune.
Hi All,

Yes, we've been testing the strategies with Neptune. Below are psuedo-code examples for the subgraph strategy using Kelvin Lawrence's Air Routes data set from the Gremlin Book: http://kelvinlawrence.net/book/Gremlin-Graph-Guide.html and the readonly strategy.

The EventStrategy is not applicable when working with a graph service like Neptune as it is designed to be used within a single process and does not support tracking mutation events across multiple processes.

SubGraphStrategy
    // Create a new traversal source object
    GraphTraversalSource g2;
 
    // Create a strategy that filters out anything without
    // a region code of 'US-TX'
    g2 = g.withStrategies(
             SubgraphStrategy.build().
               vertices(has(""region"",""US-TX"")).create());
 
    // See how many vertices are in that subgraph
    System.out.println(g2.V().count().next());
 


ReadOnlyStrategy
      g2 = g.withStrategies(ReadOnlyStrategy.instance());
      try
      {
        g2.addV(""shouldfail"").iterate();
      }
      catch(Exception e)
      {
        System.out.println(""Unable to add vertex"");
       System.exit(1);
 }


Edited by: bradbataws on Jul 26, 2018 3:29 PM

Edited by: Kelvin-AWS on Aug 1, 2018 1:24 PM"
Amazon Neptune	"Procedures for Neptune
Major functionality missing compared to your competitors
NEO4J supports APOC https://github.com/neo4j-contrib/neo4j-apoc-procedures, thats speeds up the processing a lot.

Neptune does not support similar libraries that speed up the processing."
Amazon Neptune	"Re: Procedures for Neptune
Hello,

Neptune currently doesn't support custom procedures but we are interested in learning further about your use cases that require custom procedures. Could you provide more details on use cases and requirements where you are planning to use custom procedures?"
