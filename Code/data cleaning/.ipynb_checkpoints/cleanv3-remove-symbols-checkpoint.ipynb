{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version retains close to nil non-alphanumeric data. The accuracy is significantly lower than if the data had been cleaned while retaining symbols. Some context (eg. HTTP links) may have been lost during cleaning, hence resulting in a lower accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to clean the data file-by-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aruna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\Aruna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('names')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import names\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A) Read the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5829.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>CloudFront Chunked Encoding and Resumable Downloads S3 supports this. Does CloudFront? If not, is this something that is coming soon? Thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5829.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>Hi keith4pluralsight,CloudFront supports resumable downloads, but not chunked encoding. At this time we have no plans to add support for chunked e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5829.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>Chunked encoding would be especially usedul for Lambda@Edge as low latency is critical and we want to flush the HTML to the client as soon as poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5828.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>Debug 403 error when accessing S3 resources through CloudFront Is there a simple means for debugging a CloudFront configuration that is supposed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5828.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>Have you tried using AWS CloudTrail? It contains all sorts of cloud events. You can search for events by username, access key, bucket name, etc. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5827.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>Feature request: Custom headers (e.g. set HSTS, CSP, X-Frame-Options...) I'd love to see an ability to add custom headers inside CloudFront, e.g.:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5827.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>I agree. To prevent many of the hacking attempts going on today, it is important to support these headers. I would love to be able to set the foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5827.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>Yes I just ran owasp zap against my site and the security warnings were all about the lack of secure headers on assets being served from cloudfron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5827.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>+1 for all the headers listed. It is fun to get security researcher reports and you cannot fix this issue because the required headers are not sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5827.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>+1 for X-Frame-Options. I too ran OWASP ZAP and got warnings.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id              label  \\\n",
       "0  5829.0  Amazon CloudFront   \n",
       "1  5829.0  Amazon CloudFront   \n",
       "2  5829.0  Amazon CloudFront   \n",
       "3  5828.0  Amazon CloudFront   \n",
       "4  5828.0  Amazon CloudFront   \n",
       "5  5827.0  Amazon CloudFront   \n",
       "6  5827.0  Amazon CloudFront   \n",
       "7  5827.0  Amazon CloudFront   \n",
       "8  5827.0  Amazon CloudFront   \n",
       "9  5827.0  Amazon CloudFront   \n",
       "\n",
       "                                                                                                                                             description  \n",
       "0          CloudFront Chunked Encoding and Resumable Downloads S3 supports this. Does CloudFront? If not, is this something that is coming soon? Thanks!  \n",
       "1  Hi keith4pluralsight,CloudFront supports resumable downloads, but not chunked encoding. At this time we have no plans to add support for chunked e...  \n",
       "2  Chunked encoding would be especially usedul for Lambda@Edge as low latency is critical and we want to flush the HTML to the client as soon as poss...  \n",
       "3  Debug 403 error when accessing S3 resources through CloudFront Is there a simple means for debugging a CloudFront configuration that is supposed t...  \n",
       "4  Have you tried using AWS CloudTrail? It contains all sorts of cloud events. You can search for events by username, access key, bucket name, etc. I...  \n",
       "5  Feature request: Custom headers (e.g. set HSTS, CSP, X-Frame-Options...) I'd love to see an ability to add custom headers inside CloudFront, e.g.:...  \n",
       "6  I agree. To prevent many of the hacking attempts going on today, it is important to support these headers. I would love to be able to set the foll...  \n",
       "7  Yes I just ran owasp zap against my site and the security warnings were all about the lack of secure headers on assets being served from cloudfron...  \n",
       "8  +1 for all the headers listed. It is fun to get security researcher reports and you cannot fix this issue because the required headers are not sup...  \n",
       "9                                                                                          +1 for X-Frame-Options. I too ran OWASP ZAP and got warnings.  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Aruna\\\\Documents\\\\input\\\\Amazon CloudFront.csv\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x: \" \".join(x for x in str(x).split())) # converting to string\n",
    " \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19189 entries, 0 to 19188\n",
      "Data columns (total 3 columns):\n",
      "id             19188 non-null float64\n",
      "label          19189 non-null object\n",
      "description    19189 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 449.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out one sample post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e82bf109ff96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "p = 5\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 30 words + frequency of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the           66012\n",
       "to            49656\n",
       "I             27906\n",
       "a             27772\n",
       "and           22943\n",
       "is            21610\n",
       "for           17510\n",
       "in            16773\n",
       "that          16238\n",
       "of            15579\n",
       "you           15346\n",
       "on            12817\n",
       "this          12458\n",
       "it            12259\n",
       "CloudFront    11646\n",
       "ms            11574\n",
       "have          11098\n",
       "from          11075\n",
       "with          10629\n",
       "be             9714\n",
       "not            9274\n",
       "your           9026\n",
       "are            8618\n",
       "can            8221\n",
       "my             7431\n",
       "as             7328\n",
       "but            6552\n",
       "an             6275\n",
       "or             5967\n",
       "-              5732\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(df['description']).split()).value_counts()[:30]\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.title(\"Top 30 words with frequencies\")\n",
    "plt.ylabel(\"Number of times\")\n",
    "\n",
    "freq.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 1689274 words before cleaning.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are totally\", df['description'].apply(lambda x: len(x.split(' '))).sum(), \"words before cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B) Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "my_stop_words = [\"hi\", \"hello\", \"regards\", \"thank\", \"thanks\", \"regard\", \"best\", \"wishes\", \"hey\", \"amazon\", \"aws\", \"s3\",\n",
    "\"elastic\", \"beanstalk\", \"rds\", \"ec2\", \"lambda\", \"cloudfront\", \"cloud\", \"front\", \"vpc\", \"sns\", \"me\",\n",
    "\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \n",
    "\"november\", \"december\", \"jan\", \"feb\", \"mar\", \"apr\", \"jun\", \"jul\", \"aug\", \"sep\", \"sept\", \"oct\", \"nov\",\n",
    "\"dec\", \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\", \"mon\", \"tue\",\n",
    "\"wed\", \"thu\", \"fri\", \"sat\", \"sun\", \"ain't\", \"aren't\", \"can't\", \"can't've\", \"'cause\", \"could've\", \"couldn't\",\n",
    "\"couldn't've\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hadn't've\", \"hasn't\", \"haven't\", \"he'd\", \"he'd've\",\n",
    "\"he'll\", \"he'll've\", \"he's\", \"how'd\", \"how'd'y\", \"how'll\", \"how's\", \"i'd\", \"i'd've\", \"i'll\", \"i'll've\", \"i'm\",\n",
    "\"i've\", \"isn't\", \"it'd\", \"it'd've\", \"it'll\", \"it'll've\", \"it's\", \"let's\", \"mayn't\", \"might've\", \"mightn't\",\n",
    "\"mightn't've\", \"must've\", \"mustn't\", \"mustn't've\", \"needn't\", \"needn't've\", \"oughtn't\", \"oughtn't've\", \"shan't\",\n",
    "\"sha'n't\", \"shan't've\", \"she'd\", \"she'd've\", \"she'll\", \"she'll've\", \"she's\", \"should've\", \"shouldn't\", \"shouldn't've\",\n",
    "\"so've\", \"so's\", \"that'd\", \"that'd've\", \"that's\", \"there'd\", \"there'd've\", \"there's\", \"they'd\", \"they'd've\", \"they'll\",\n",
    "\"they'll've\", \"they're\", \"they've\", \"to've\", \"wasn't\", \"we'd\", \"we'd've\", \"we'll\", \"we'll've\", \"we're\", \"we've\",\n",
    "\"weren't\", \"what'll\", \"what'll've\", \"what're\", \"what's\", \"what've\", \"when's\", \"when've\", \"where'd\", \"where's\",\n",
    "\"where've\", \"who'll\", \"who'll've\", \"who's\", \"who've\", \"why's\", \"why've\", \"will've\", \"won't\", \"won't've\", \"would've\",\n",
    "\"wouldn't\", \"wouldn't've\", \"yall\", \"yalld\", \"yalldve\", \"yallre\", \"yallve\", \"youd\", \"youdve\", \"youll\",\n",
    "\"youllve\", \"youre\", \"youve\", \"do\", \"did\", \"does\", \"had\", \"have\", \"has\", \"could\", \"can\", \"as\", \"is\",\n",
    "\"shall\", \"should\", \"would\", \"will\", \"you\", \"me\", \"please\", \"know\", \"who\", \"we\", \"was\", \"were\", \"edited\", \"by\", \"pm\"]\n",
    "\n",
    "name = names.words()\n",
    "STOPWORDS.extend(my_stop_words)\n",
    "STOPWORDS.extend(name)\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,:;#+?]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z - _.]+')\n",
    "REMOVE_HTML_RE = re.compile(r'<.*?>')\n",
    "REMOVE_HTTP_RE = re.compile(r'http\\S+')\n",
    "\n",
    "STOPWORDS = [BAD_SYMBOLS_RE.sub('', x) for x in STOPWORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"feature request: custom headers (e.g. set hsts, csp, x-frame-options...) i'd love to see an ability to add custom headers inside cloudfront, e.g.: - strict-transport-security - content-security-policy - x-frame-options etc. we serve a lot of content from s3, where we can't set those headers (for good reason, since that content can be served by https://s3.amazonaws.com/bucket/key). i'd be great to be able to add those headers inside cloudfront -- when the origin itself can't or doesn't set them.\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(x.lower() for x in str(x).split(\" \")))\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"feature request: custom headers (e.g. set hsts, csp, x-frame-options...) i'd love to see an ability to add custom headers inside cloudfront, e.g.: - strict-transport-security - content-security-policy - x-frame-options etc. we serve a lot of content from s3, where we can't set those headers (for good reason, since that content can be served by https://s3.amazonaws.com/bucket/key). i'd be great to be able to add those headers inside cloudfront -- when the origin itself can't or doesn't set them.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(REMOVE_HTML_RE.sub(' ', x) for x in str(x).split()))\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove HTTP links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"feature request: custom headers (e.g. set hsts, csp, x-frame-options...) i'd love to see an ability to add custom headers inside cloudfront, e.g.: - strict-transport-security - content-security-policy - x-frame-options etc. we serve a lot of content from s3, where we can't set those headers (for good reason, since that content can be served by   i'd be great to be able to add those headers inside cloudfront -- when the origin itself can't or doesn't set them.\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(REMOVE_HTTP_RE.sub(' ', x) for x in str(x).split()))\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace certain characters by space (quotation marks, parantheses etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"feature request  custom headers  e.g. set hsts  csp  x-frame-options...  i'd love to see an ability to add custom headers inside cloudfront  e.g.  - strict-transport-security - content-security-policy - x-frame-options etc. we serve a lot of content from s3  where we can't set those headers  for good reason  since that content can be served by i'd be great to be able to add those headers inside cloudfront -- when the origin itself can't or doesn't set them.\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(REPLACE_BY_SPACE_RE.sub(' ', x) for x in str(x).split()))\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any unwanted symbols (like $, @ etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature request custom headers e.g. set hsts csp xframeoptions... id love to see an ability to add custom headers inside cloudfront e.g.  stricttransportsecurity  contentsecuritypolicy  xframeoptions etc. we serve a lot of content from s3 where we cant set those headers for good reason since that content can be served by id be great to be able to add those headers inside cloudfront  when the origin itself cant or doesnt set them.'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(BAD_SYMBOLS_RE.sub('', x) for x in str(x).split()))\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove trailing punctuation marks and any symbol patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature request custom headers e.g set hsts csp xframeoptions id love to see an ability to add custom headers inside cloudfront e.g stricttransportsecurity contentsecuritypolicy xframeoptions etc we serve a lot of content from s3 where we cant set those headers for good reason since that content can be served by id be great to be able to add those headers inside cloudfront when the origin itself cant or doesnt set them'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(x.strip('.') for x in x.split()))\n",
    "df['description'] = df['description'].apply(lambda x: \" \".join(x.strip('-') for x in x.split()))\n",
    "df['description'] = df['description'].apply(lambda x: \" \".join(x.strip('_') for x in x.split()))\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove any numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature request custom headers e.g set hsts csp xframeoptions id love to see an ability to add custom headers inside cloudfront e.g stricttransportsecurity contentsecuritypolicy xframeoptions etc we serve a lot of content from s3 where we cant set those headers for good reason since that content can be served by id be great to be able to add those headers inside cloudfront when the origin itself cant or doesnt set them'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
    "\n",
    "df['description'][p]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature request custom headers e.g set hsts csp xframeoptions love see ability custom headers inside e.g stricttransportsecurity contentsecuritypolicy xframeoptions etc serve lot content set headers good reason since content served great headers inside origin set'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in STOPWORDS\n",
    "                                                               and len(x) > 1))\n",
    "\n",
    "df['description'][p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results after cleaning data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5829.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>chunked encoding resumable downloads supports something coming soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5829.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>keith4pluralsight supports resumable downloads chunked encoding time plans support chunked encoding certainly interested community opinion.thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5829.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>chunked encoding especially usedul edge low latency critical want flush html client soon possible allow start parsing prefetching critical resourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5828.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>debug error accessing resources simple means debugging configuration supposed provide access contents bucket trying find consistent means creating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5828.0</td>\n",
       "      <td>Amazon CloudFront</td>\n",
       "      <td>tried using cloudtrail contains sorts events search events username access bucket name etc seeing specific events try setting logging relevant buc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id              label  \\\n",
       "0  5829.0  Amazon CloudFront   \n",
       "1  5829.0  Amazon CloudFront   \n",
       "2  5829.0  Amazon CloudFront   \n",
       "3  5828.0  Amazon CloudFront   \n",
       "4  5828.0  Amazon CloudFront   \n",
       "\n",
       "                                                                                                                                             description  \n",
       "0                                                                                    chunked encoding resumable downloads supports something coming soon  \n",
       "1  keith4pluralsight supports resumable downloads chunked encoding time plans support chunked encoding certainly interested community opinion.thanks ...  \n",
       "2  chunked encoding especially usedul edge low latency critical want flush html client soon possible allow start parsing prefetching critical resourc...  \n",
       "3  debug error accessing resources simple means debugging configuration supposed provide access contents bucket trying find consistent means creating...  \n",
       "4  tried using cloudtrail contains sorts events search events username access bucket name etc seeing specific events try setting logging relevant buc...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 30 words + frequency of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ms              11627\n",
       "origin           6276\n",
       "distribution     5979\n",
       "using            5970\n",
       "server           5625\n",
       "file             5418\n",
       "get              5190\n",
       "use              4891\n",
       "request          4874\n",
       "bucket           4539\n",
       "files            4227\n",
       "content          4041\n",
       "like             3749\n",
       "time             3608\n",
       "error            3527\n",
       "access           3437\n",
       "see              3307\n",
       "one              3285\n",
       "issue            3271\n",
       "set              3076\n",
       "video            3010\n",
       "problem          2970\n",
       "streaming        2940\n",
       "also             2889\n",
       "cache            2830\n",
       "edge             2827\n",
       "new              2704\n",
       "object           2602\n",
       "need             2566\n",
       "help             2550\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(df['description']).split()).value_counts()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 825876 words after cleaning.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are totally\", df['description'].apply(lambda x: len(x.split(' '))).sum(), \"words after cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) Write to CleanText.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Aruna\\\\Documents\\\\ACMS-IID\\\\input\\\\CleanCloudFront.csv', 'a', encoding='utf-8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['id', 'label', 'description'])\n",
    "    for i in range(0, len(df['description'])):\n",
    "        if len(df['description'][i]) > 1:\n",
    "            writer.writerow([df['id'][i], df['label'][i], df['description'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open('C:\\\\Users\\\\Aruna\\\\Documents\\\\ACMS-IID\\\\input\\\\CleanText.csv', 'a', encoding='utf-8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # writer.writerow(['id', 'label', 'description'])\n",
    "    for i in range(0, 100000):\n",
    "        if len(df['description'][i]) > 1:\n",
    "            writer.writerow([df['id'][i], df['label'][i], df['description'][i]])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (D) Generate the word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = \" \".join(str(msg) for msg in df['description'])\n",
    "fig, ax = plt.subplots(1, 1, figsize  = (100,100))\n",
    "wordcloud = WordCloud(max_font_size = 20, max_words = 20, background_color = \"white\").generate(msgs)\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = \" \".join(str(msg) for msg in df['description'])\n",
    "fig, ax = plt.subplots(1, 1, figsize  = (100,100))\n",
    "wordcloud = WordCloud(max_font_size = 20, max_words = 50, background_color = \"white\").generate(msgs)\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = \" \".join(str(msg) for msg in df['description'])\n",
    "fig, ax = plt.subplots(1, 1, figsize  = (100,100))\n",
    "wordcloud = WordCloud(max_font_size = 20, max_words = 100, background_color = \"white\").generate(msgs)\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = \" \".join(str(msg) for msg in df['description'])\n",
    "fig, ax = plt.subplots(1, 1, figsize  = (100,100))\n",
    "wordcloud = WordCloud(max_font_size = 20, max_words = 500, background_color = \"white\").generate(msgs)\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = \" \".join(str(msg) for msg in df['description'])\n",
    "fig, ax = plt.subplots(1, 1, figsize  = (100,100))\n",
    "wordcloud = WordCloud(max_font_size = 20, max_words = 1000, background_color = \"white\").generate(msgs)\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
